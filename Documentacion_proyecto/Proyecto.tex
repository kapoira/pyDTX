\documentclass[a4paper,11pt,oneside]{book}

\usepackage[a4paper,left=2.5cm,right=2cm]{geometry}
\usepackage[utf8]{inputenc}%%%Este paquete permite poner acentos directamente%%%
\usepackage[spanish]{babel}
\usepackage{eurosym}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fancyvrb}
\usepackage{hyperref}
\usepackage{amsmath,amssymb,amsthm,amscd}
\usepackage[nonumberlist, toc]{glossaries}
\usepackage[pdftex]{color,graphicx}
\usepackage{float}
\usepackage{listingsutf8}

\lstset{language=Python, basicstyle=\footnotesize, breaklines=true, extendedchars=true, texcl=true}

\lstset{literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1
}



\definecolor{rojo}{rgb}{1,0,0}
\definecolor{negro}{rgb}{0,0,0}

\newglossaryentry{Guitar Hero}{name=Guitar Hero, description={Juego lanzado en 2005, por Harmonix que se basa con el controlador en forma de guitarra simula a una guitarra verdadera.}}

\newglossaryentry{Rock Band}{name=Rock Band, description={Juego lanzado en 2007, que se basa en simular una banda de rock, con sus diferentes partes vocales, guitarra y bajo, batería y piano.}}

\newglossaryentry{Pads}{name=Pads, description={Parte de una batería-MIDI donde se ha de golpear para que imite el sonido de ese instrumento, normalmente cada pad solo emite una nota, variando su potencia dependiendo del golpe, la excepción suele ser el charles que tiene posición abierto y cerrado, en las baterías profesionales hay pads que tienen varias zonas de golpeo y emiten un sonido dependiendo de la zona y la potencia}}

\newglossaryentry{Lanes}{name=Lanes, description={Siempre que empleamos la palabra lane nos referimos a las columnas visuales del juego musical}}

\newglossaryentry{Chips}{name=Chips, description={Nota visual que va bajando por los lanes para indicarnos cuando se ha de tocar}}


\makeindex
\makenoidxglossaries


\begin{document}
 
\title{Reproductor de canciones DTXMANIA para entornos libres}
\author{Guillermo Eduardo Cabezas Castillo}
\date{\today}

\maketitle 

\tableofcontents
\listoffigures
\chapter*{Agradecimientos}
\begin{flushright}
\textit{Dedicado a \\
mi familia}
\end{flushright}

\chapter{Introducción}
\section{Idea General}

	 El objetivo de este proyecto es un reproductor de canciones DTXMANIA, en entornos de código abierto. Para ello se tendrá que desarrollar la idea de como es este formato, y que es necesario hacer para poder reproducirlo con algunos de sus añadidos.

  Como primera toma de contacto se puede decir que el formato DTXMANIA, es un formato musical, especializado en baterías.

\section{Estado del arte e idea del proyecto}
  
    Como una primera introducción comentar que el formato DTXMANIA, viene de unos juegos de tipo musical creados en japón, que cuando los baterías los probaron, se dieron cuenta que con algunas modificaciones se podían emplear para mejorar en su practica habitual.
    Debido al auge de estos tipos de juegos a partir del famoso \gls{Guitar Hero}, tendremos que repasar los principales juegos de tipo musical que si que tienen un componente físico para simular instrumentos.
    
    También se hará un pequeño repaso a los formatos musicales digitales ya que van a estar muy integrados en el proyecto. 
     

\subsection{Historia de los principales juegos musicales}
	Cuando se piensa en un juego/simulador principal lo que primero puede venir a la mente, por ser lo más conocido es el caso del \Gls{Guitar Hero}

\subsubsection{Guitar Hero}
\gls{Guitar Hero} es una popular franquicia de videojuegos musicales.

La serie \gls{Guitar Hero} es conocida por el uso de un dispositivo con forma de guitarra que se utiliza como control de juego para simular y hacer música con ella, representando notas de colores en la pantalla que corresponde a cada uno de los botones del controlador. Los juegos de la serie permiten tanto partidas individuales como multijugador, pudiendo estas últimas ser cooperativas o competitivas. La serie ha utilizado una amplia gama de canciones de rock de diversas épocas, tanto licenciadas como independientes, hechas desde los años 60 hasta el presente, muchas de ellas son de bandas muy exitosas.

La serie ha vendido alrededor de 15 millones de juegos, ganando aproximadamente 1000 millones de dólares.



\gls{Guitar Hero} es un juego inusual debido a que viene con un control que recrea a una Gibson les paul en lugar de los controles comunes. Jugar con el controlador en forma de guitarra simula a una guitarra verdadera, a excepción de los ``Botones Traste'' y la ``Barra de Sonido'' en lugar de los Trastes y las seis cuerdas. El desarrollo de Guitar Hero fue inspirado en el juego Guitar Freaks de Konami, que en esos tiempos no era muy popular en Estados Unidos.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=2.0]{Imagenes/Guitar_Hero_3_controller.jpg}
% Ponemos Leyenda al gráfico
\caption{Controlador del Guitar Hero}
\label{Controlador del Guitar Hero}
\end{center}
\end{figure}


Su control básicamente son unos \gls{Chips}  que van bajando por la pantalla y se tiene que sincronizar el pulsar el botón de la guitarra simulada cuando llegan a la parte baja.


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.3]{Imagenes/guitar-hero-3.jpg}
% Ponemos Leyenda al gráfico
\caption{Interfaz del Guitar Hero}
\label{Interfaz del Guitar Hero}
\end{center}
\end{figure}

Comentar que hay una barra de vida y esta puede bajar o subir según vamos dando a las notas correctamente. Si la vida bajara mucho se para la canción y se va de nuevo al menú.



\subsubsection{Rock Band}
La productora después de varios \gls{Guitar Hero} se dio cuenta que para continuar vendiendo juegos musicales tenia que aportar algo más a la saga de \gls{Guitar Hero} es entonces cuando nace \gls{Rock Band}.

\gls{Rock Band} es una serie de videojuegos de música en los cuales permite que hasta cuatro jugadores puedan jugar a tocar algunas de las canciones más populares de música Rock, jugando con los instrumentos de la empresa(o también con los instrumentos de \gls{Guitar Hero}). Los jugadores pueden jugar con una guitarra, un bajo, una batería y cantando con un micrófono, además de el teclado (desde el Rock Band 3)

Exceptuando el control de micrófono, la idea básica continua siendo la misma, simular en mejor o peor medida los instrumentos antes citados, con el sistema ya creado en el \gls{Guitar Hero}.


Aquí ya apareció la batería en principio solamente con 4 \gls{Pads} y un pedal, y luego más adelante con el Rock Band Pro, ya salio la posibilidad de una batería con 7 \gls{Pads} y un pedal.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.3]{Imagenes/Drum-Controller-for-Rock-Band.jpg}
% Ponemos Leyenda al grafico
\caption{Batería de Rock Band}
\label{Batería de Rock Band}
\end{center}
\end{figure}

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.2]{Imagenes/rb3-drums.jpg}
% Ponemos Leyenda al grafico
\caption{Batería de Rock Band Pro}
\label{Batería de Rock Band Pro}
\end{center}
\end{figure}

\subsubsection{Frets on fire}
Debido al auge de estos juegos musicales no se tardo en sacar una versión libre de estos, el más famoso de ellos fue el Frets on fire, que copiaba el juego \gls{Guitar Hero}.
De modo que el jugador simula el acto de tocar una guitarra. Las notas aparecen en la pantalla sincronizadas con la canción, y son tocadas manteniendo presionadas las teclas correctas y marcándolas pulsando Enter en el momento preciso. El punteo en las notas correctas incrementa el coeficiente por el que se multiplican los puntos ganados al tocar (x2, x3 y hasta x4), pero una sola nota incorrecta hace que este coeficiente vuelva a x1. Si bien no hay ningún objetivo establecido para las canciones, la puntuación obtenida puede ser comparada con la del resto de jugadores en la web oficial.

El carácter más distintivo del juego es la forma de controlarlo: el teclado se coge con ambas manos como si de una guitarra se tratase, con la mano izquierda en los botones F1-F5 y la derecha en el botón Enter. Debido que algunos teclados no reconocen la pulsación simultánea de algunas de estas teclas, el juego permite cambiarlas para evitar este problema.

Su fecha de salida fue el 3 de agosto de 2006. Un detalle muy importante es que de inicio ya incorporaba el poder agregar ``mods'' para maximizar su funcionalidad y modificar su apariencia física según los gustos del jugador.

\subsubsection{FoFiX}
Un mod muy famoso del Frets on Fire fue el FoFix fue una versión libre del \gls{Rock Band}.

Estos juegos tienen de bueno que al ser libres todo su código se puede mirar y modificar. Aunque mayoritariamente fueron detrás de sus originales en cuanto a modificaciones que se programaban. Si el \gls{Guitar Hero} insertaba un modo donde las canciones eran más difíciles al cabo de un tiempo en el Frets on fire se programaba un mod para ello. 
Un punto a favor de estos juegos es que si se tenía el juego original se podía copiar las canciones de estos juegos y además disponer de las propias que la comunidad creaba para ellos.

\subsubsection{Dance Dance Revolution}
Dance Dance Revolution es la serie pionera del género de simuladores de ritmo/baile en los vídeo juegos. Los jugadores se colocan sobre una ``plataforma de baile'', también llamada ``pista'' y presionan con los pies las flechas dispuestas en forma de cruz sobre esta pista, siguiendo el ritmo de la música y el patrón visual que aparece en la pantalla. De acuerdo a la sincronización que los jugadores muestren con el ritmo y lo bien que sigan el patrón de flechas, se les otorgara una puntuación (que varía de acuerdo a la versión del juego). Su primer lanzamiento, en forma de árcade, fue realizado en Japón en 1998. Desde su creación han sido producidas múltiples variaciones, incluyendo algunas para uso casero. Es clasificado como un juego Bemani (Bemani es una abreviación japonesa de la palabra Beat Mania, el nombre del primer juego musical de Konami), cuyo creador es Yoshihiko Ota, que también participó en otras series como ``pop'n music''.

En la composición de canciones para el juego participan varios artistas, incluyendo los que aparecen en la serie de discos Dance Mania, otros de Konami, como Yasuhiro Taguchi, principal compositor musical para esta serie de juegos desde DDR X y pocos, como Naoki Maeda, fundador de la serie, que se retiraron de Konami. Algunos artistas han dado letras de sus canciones como es el caso de Aerosmith que donó la canción I Don't Want to Miss a Thing para el Dance Dance Revolution Extra Mix que también está disponible en versión para PlayStation.


Durante un juego normal, 4 flechas direccionales (u 8 en Double) permanecen estáticas en la parte superior de la pantalla. Otras flechas se desplazan desde la parte inferior de la pantalla hasta las flechas estáticas en la parte superior (se cambia de posición en caso de que el jugador opte por Reversa). Un jugador debe bailar con la canción, pisando la superficie correspondiente a las flechas marcadas en la pantalla en una plataforma de baile de metal y acrílico. En algunas ocasiones dos o más flechas deben ser pulsadas al mismo tiempo, lo que obliga al jugador a saltar para pulsar 2 flechas a la vez o agacharse para pulsarlas con las manos o rodillas, en caso de 3 o 4 flechas consecutivas, estas últimas aparecen en los edits. De esta manera, el juego invita al jugador a bailar según la coreografía pre-establecida para cada canción. Por otro lado se encuentran las Freeze Arrow (implementadas desde DDRMAX) que aparecen flechas en las que hay que mantener presionado el botón correspondiente durante el tiempo establecido. A veces, ciertas canciones tienen pausas de tiempo, sobre todo, antes de la flecha o al empezar el frezze arrow, el jugador debe estar más atento a la secuencia. En algunas ocasiones dos o más Frezze Arrows deben ser pulsadas y mantenidas al mismo tiempo, ya que levantando el pie durante el Frezze Arrow cuenta como una flecha perdida. Y finalmente, las Shock Arrows (implementadas desde DDR X) que solo aparecen en unas determinadas canciones, generalmente en Challenge, y consisten en que aparecen las 4 u 8 flechas al mismo tiempo, en un color metalizado y con unos relámpagos por dentro. La misión del jugador es esquivarlas, ya que de pulsarlas, cuenta como flecha perdida, frena el combo y desaparece las flechas por una fracción de segundo. Este tipo de paso recuerda y mucho a las populares Minas de la serie de juegos musicales ``In the Groove'', de la cual Konami tiene los derechos tras su juicio con Roxor Games. Si fallas repetidamente las flechas (o pisando una Shock Arrow), la barra de vida se vé drásticamente reducida y se puede llegar a fallar la canción.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.3]{Imagenes/DanceDanceScreen1.jpeg}
% Ponemos Leyenda al gráfico
\caption{Interfaz del DDR}
\label{Interfaz del DDR}
\end{center}
\end{figure}


Dependiendo del tiempo en cada paso, el paso se marca como ``Marvelous'', ``Perfect'', ``Great'', ``Good'', ``Almost'' o ``Miss'' En la parte superior de la pantalla hay una barra de vida, y empieza a la mitad al comienzo de la canción. Los pasos Great o más incrementan la barra de vida hasta que se llena. Mientras que los pasos ``Almost'' y ``Miss'' la disminuyen. Los pasos ``Good'' no tienen efecto positivo o negativo. Si a un jugador reduce su barra de vida totalmente por fallar muchas veces, falla la canción y, solo en Versus, cuando los 2 jugadores fallan, o si uno de los 2 logra llegar al final de una canción.
 El jugador recibe una puntuación final que puede ir de una ``AAA+'' Jugabilidad 4 a una ``E'' (donde ``AAA+'' la mejor calificación obtenida, ``D'' la peor y ``E'' cuando falla la canción), basado en la cantidad de pasos correctos que haya realizado y en la sincronía con el juego y el conteo de calorías quemadas (vista en la evaluación desde Supernova2 y en versiones caseras), y cuando ambos ven una ``E'' o si ha terminado todas las canciones o el curso, se termina el juego. Normalmente, si falla la canción en curso, aparece ``FAILED'' en rojo antes de la evaluación, lo mismo ocurre si termina la canción con la palabra ``CLEARED'' en verde.

En una canción, existen factores que determinan su dificultad de baile, los cuales están marcados en pies, desde 4thMIX, los beats por minuto (BPM) y desde el DDRMAX, el Groove radar (desactivado al jugar en modo Happy en X2 y X3). Originalmente, las canciones usaban fondos con gráficos o videos aleatorios, pero desde DDR Supernova, fueron remplazados por videos exclusivos o escenarios, ya que antes no sabían que canción se estaba jugando y desde DDR Supernova 2 apareció el visor de canciones en vez de fondos. Ciertas canciones con video desde DDR X2 aparecen en pantallas del escenario.

\subsubsection{Stepmania}

Stepmania es un video juego de baile y ritmo, entra en la categoría de simulación inspirado en Dance Dance Revolution. Es un software libre y totalmente gratuito, disponible para sistemas como Linux, Windows o Mac OS X, como también su código fuente es utilizado para ``In The Groove'' y ``Pump It Up Pro''.

Es idéntico a Dance Dance Revolution con la diferencia de que el usuario puede interactuar libremente con el programa, pudiendo soportar las canciones de DDR PC e incorporar canciones a su gusto, caratulas, estilos visuales, etc. Las 3 primeras versiones usaban la interfaz de DDRMAX. Desarrolladores crearon SM4 en sus 2 versiones. La versión CVS estaba basado en la construcción del 2006, llamándose Stepmania 3.95. Chris Danford, creador de Stepmania, bifurcó la otra versión CVS y lo llamó SM 4 Beta. Después del anuncio del 4 beta, varias versiones CVS y SVN no oficiales fueron creadas por la comunidad de Stepmania como una versión 5.

Es totalmente accesible y se puede modificar al gusto de la persona pero siempre manteniendo el estilo clásico de su núcleo.

\subsubsection{Drum Mania}
Drum Mania es un juego musical producido por Bemani, la división musical de Konami.

La fecha de salida de Drum Mania fue en 1999 como un juego arcade, después se porto a la PlayStation 2 en Japon en el año 2000 como un título de salida. Siguientes versiones del juego han salido aproximadamente una al año.

El juego puede ser enlazado a su versión de guitarra Guitar Freaks, permitiendo el juego cooperativo mientras los dos juegos fueran de la misma versión, versiones anteriores también se podían enlazar con Keyboard Mania. Desde el 7th mix hacia adelante, se pudo conectar al sistema de Konami e-Amusement para el juego competitivo on-line.

Drum Mania simula el hecho de tocar una batería real. Se juega usando un controlador que imita a una batería. Seis \gls{Lanes} colocadas de derecha a izquierda como el hi-hat, caja , tom alto , tom de piso , platillos y además un pedal para simular el bombo. Durante el juego, el jugador tiene que tocar los \gls{Pads} y el pedal en sincronía con los \gls{Chips} que van cayendo verticalmente desde arriba, y en sincronía con la música.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.3]{Imagenes/Drum_Mania_interface.jpeg}
% Ponemos Leyenda al gráfico
\caption{Interfaz del Drum Mania}
\label{Interfaz del Drum Mania}
\end{center}
\end{figure}

La exactitud del jugador es juzgada en cada nota, y aunque el sistema de medir esta exactitud se ha cambiado a través de las versiones, actualmente el sistema emplea Perfect, Great, Good, Poor y Miss para evaluar el sincronismo de cada nota. Las categorías de Poor y Miss vaciaran el ``Excite Gauge'' del jugador mientras que mantener el sincronismo lo aumentara. Si el ``Excite Gauge'' se vaciá completamente el juego acaba. Los jugadores podrán jugar de tres a cinco canciones dependiendo de la configuración y según sus puntuaciones podrán jugar dos canciones adicionales. Cuando se completa una canción a los jugadores se les otorga una puntuación que va desde E hasta A, también incluyendo S y SS dependiendo de lo bien que hayan tocado la canción y la configuración de la puntuación en esa versión.

Drum Mania usa una batería electrónica modificada de Yamaha de la gama DTXPRESS. Esta batería es usada para navegar por los menús y pantallas de selección, también se puede navegar mediante los botones Select y Start en los laterales de la máquina. 


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.5]{Imagenes/cabinet-drummania.jpg}
% Ponemos Leyenda al gráfico
\caption{Mueble arcade del Drum Mania}
\label{Mueble arcade del Drum Mania}
\end{center}
\end{figure}

\subsubsection{Drum Mania XG / Gitadora}

En el año 2010 la serie se cambio de nombre a Drum Mania XG, aquí se introdujo el cambio en los controles de añadir un tom de suelo, un cymbal izquierdo y un pedal izquierdo a la maquina original, y para que hubiera más desarrollo en este nuevo juego se paro el desarrollo en la saga Drum Mania.

Más adelante en el año 2012 se cambio el nombre de Drum ManiaXG a Gitadora, dejando los controles iguales, añadiendo cambios y limpiando mucho la interfaz del Drum ManiaXG y modificando los modos de conexión a Internet.


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.5]{Imagenes/cabinet-gitadora.jpg}
% Ponemos Leyenda al gráfico
\caption{Mueble arcade del Gitadora}
\label{Mueble arcade del Gitadora}
\end{center}
\end{figure}


\subsubsection{DTXMania}
El DTXMania es un juego musical basado en el Drum Mania, su programador lo llego a liberar en el año 2000 bajo la licencia MIT. Su idea original era coger el Drum Mania y poder ejecutarlo en un ordenador, al principio pensado para las baterías electrónicas Yamaha y poco a poco se fue modificando para poder conectar cualquier batería electrónica MIDI, que al final se ha convertido en su principal objetivo.

Ya desde el inicio se fue separando del proyecto Drum Mania para acercarse más a un simulador real, antes que a un juego.

Fue el primero en implementar el hihat abierto y cerrado, de esta manera y si la batería MIDI tenia esta posibilidad tener que usar el pedal izquierdo, para tocar el hihat tal y como se tendría que hacer en una batería real. Siempre dejando la posibilidad de estas opciones que programaba se podían quitar por si tu batería no era tan potente o por si querías acercarte más a un juego antes que a un simulador.

La puntuación aunque ha variado en diferentes versiones exponemos la clásica:

     (Porcentaje de notas en Perfect x .85) + (Porcentaje de notas en Great x .35) + (Porcentaje de Max Combo x .15)

Basado en este ratio, se asignan las siguientes letras:

\begin{itemize}
  \item SS = 95.00+ 
  \item S = 80.00 - 94.99
  \item A = 73.00 - 79.99
  \item B = 63.00 - 72.99
  \item C = 53.00 - 62.99
  \item D = 45.00 - 52.99 
  \item E = 0 - 44.99 
\end{itemize}
    

Detalle a tener en cuenta se puede tocar una canción sin ningún miss y sí se ha cometido algún fallo de sincronismo no tener la canción al 100\%.

Muchos baterías vieron en este programa una gran ayuda para sus sesiones de practica gracias principalmente a dos puntos.

\begin{itemize}
\item   1. Poder detallar a que nivel querían el sincronismo.
\item   2. Con la inclusión de poder tocar con la batería electrónica podían entrenar ritmos tal y como se han de tocar en la batería acústica.
\end{itemize}

Poco a poco se fue haciendo una gran comunidad que creaba canciones para el DTXMania y aportaban ideas para cada vez convertirlo en una ayuda para sus sesiones de entrenamiento.


\subsubsection{DTXManiaHD}
Cuando salio el Drum Mania XG en el año 2010, el programador de DTXMania añadió los cambios que se habían realizado para poder importar las canciones del Drum Mania XG al DTXManiaHD, los cambios fueron el pedal izquierdo (él ya se había adelantado con el tema del hihat), ya que en Drum Mania XG se puede usar el pedal izquierdo para hihat o para doble bombo, mientras que el todavía tenia más libertad ya que podía funcionar de esta manera y además si la batería eléctrica tenia doble pedal izquierdo se podía separar estas funciones y tenerlos independientes. 

También se hizo un gran cambio en la interfaz y se actualizo a gráficos en alta calidad.

Para no complicar dejo dos programas independientes y era el batería que debía escoger donde poner las canciones para que se ejecutaran como DTXManiaHD o DTXMania simple.

\subsection{Historia composición musical mediante ordenador}
Ahora haremos un pequeño resumen sobre la historia de la composición musical mediante ordenador para poder entender mejor las relaciones que tendremos entre baterías musicales MIDI y el reproductor de DTXMania.

En 1878, Thomas A. Edison patentó el fonógrafo, que utilizaba cilindros para grabar sonidos y poder reproducirlos de nuevos. Aunque se siguieron utilizando los cilindros durante algún tiempo, este invento revoluciono el concepto de la música.

Se suele considerar como el primer instrumento electrónico el Theremin, inventado por el profesor Léon Theremin alrededor de 1919–1920

La grabación de sonidos dio un salto en 1927, cuando el inventor estadounidense J. A. O'Neill desarrolló un dispositivo para la grabación que utilizaba un tipo de cinta recubierta magnéticamente.

En 1942, AEG ya estaba realizando pruebas de grabación en estéreo.No obstante, estos dispositivos y técnicas fueron un secreto fuera de Alemania hasta el final de la Guerra, cuando varios de estos aparatos fueron capturados y llevados a Estados Unidos por Jack Mullin y otros. Estos grabadores capturados sirvieron de base para los primeros grabadores de cinta profesionales que fueron comercializados en Estados Unidos, el Model 200 producido por la empresa Ampex.

La cinta de audio magnética abrió un vasto campo de posibilidades sonoras para músicos, compositores, productores e ingenieros. La cinta de audio era relativamente barata y muy confiable, y su fidelidad en la reproducción mejor que cualquier otro medio de audio conocido hasta la fecha. Más importantemente, y a diferencia de los discos, ofrecía la misma plasticidad que la película: puede ser ralentizada, acelerada o incluso reproducirse al revés. Puede editarse también físicamente, incluso sólo segmentos de la cinta. O unirse diferentes trozos de cinta en loops infinitos que reproducen continuamente determinados patrones de material pregrabado. La amplificación de audio y el equipo de mezcla expandieron todavía más allá las posibilidades de la cinta como medio de producción, permitiendo que múltiples grabaciones fueran grabadas a la vez en otra cinta diferente. Otra posibilidad de la cinta era su capacidad de ser modificada fácilmente para convertirse en máquinas de eco para producir de modo complejo, controlable y con gran calidad efectos de eco y reverberación (lo que es prácticamente imposible de conseguir por medios mecánicos).

La banda sonora de Forbidden Planet, de Louis y Bebe Barron, fue compuesta completamente mediante circuitos caseros y magnetófonos en 1956.

El primer ordenador del mundo en reproducir música fue el CSIRAC, que fue diseñado y construido por Trevor Pearcey y Maston Beard. El matemático Geoff Hill programó el CSIRAC para tocar melodías de música popular. No obstante, el CSIRAC reproducía un repertorio estándar y no fue utilizado para ampliar el pensamiento musical o para tocar composiciones más elaboradas.

El impacto de los ordenadores continuó en 1956. Lejaren Hiller y Leonard Isaacson compusieron Iliac Suite para un cuarteto de cuerda, la primera obra completa en ser compuesta con la asistencia de un computador utilizando un algoritmo en la composición. Posteriores desarrollos incluyeron el trabajo de Max Mathews en Bell Laboratories, quien desarrolló el influyente programa MUSIC I. La tecnología de vocoder fue otro importante desarrollo de esta época.

A inicios de la década de los ochentas, compañías estaban vendiendo versiones compactas y de bajo precio de los sintetizadores para el público. Esto, junto con el desarrollo de el protocolo Musical Instrument Digital Interface (MIDI), hizo más fácil integrar y sincronizar sintetizadores y otros instrumentos electrónicos para su uso en la composición musical. En los noventas, los emuladores de sintetizadores comenzaron a aparecer para computadoras, conocidos como sintetizadores de software. Posteriormente, VST's y otros plugins eran capaces de emular el hardware de sintetizadores clásicos hasta cierto punto.

En 1980, un grupo de músicos y fabricantes se pusieron de acuerdo para estandarizar una interfaz a través del que diferentes instrumentos pudieran comunicarse entre ellos y el ordenador principal. El estándar se denominó MIDI (Musical Instrument Digital Interface). En agosto de 1983, la especificación 1.0 de MIDI fue finalizada.

La llegada de la tecnología MIDI permitió que con el simple acto de presionar una tecla, controlar una rueda, mover un pedal o dar una orden en un micro ordenador se pudieran activar todos y cada uno de los dispositivos del estudio remotamente y de forma sincronizada, respondiendo cada dispositivo de acuerdo a las condiciones prefijadas por el compositor.

Como el tema de composición y edición musical se escapa de los objetivos de este proyecto nos centraremos en los formatos de reproducción.

\subsubsection{Formatos sin comprimir WAV}
La manera general de almacenar audio digital es muestreando el voltaje de audio, que al reproducirlo, corresponde a un nivel de señal en un canal individual con una cierta resolución -el número de bits por muestreo en intervalos regulares (creando la frecuencia de muestreo). Estos datos después pueden ser almacenados sin comprimir o comprimidos para reducir el tamaño del formato.

Evidentemente los formatos sin comprimir son los primeros que se crearon y los más usados a la hora de una necesidad de inmediatez a costa de tener que tenerlos en memoria.

WAV (o WAVE), apócope de WAVE form audio file format, es un formato de audio digital normalmente sin compresión de datos desarrollado y propiedad de Microsoft y de IBM que se utiliza para almacenar sonidos en el PC, admite archivos mono y estéreo a diversas resoluciones y velocidades de muestreo, su extensión es .wav.

Es una variante del formato RIFF (Resource Interchange File Format, formato de fichero para intercambio de recursos), método para almacenamiento en ``paquetes'', y relativamente parecido al IFF y al formato AIFF usado por Macintosh. El formato toma en cuenta algunas peculiaridades de la CPU Intel, y es el formato principal usado por Windows.

A pesar de que el formato WAV es compatible con casi cualquier códec de audio, se utiliza principalmente con el formato PCM (no comprimido) y, al no tener pérdida de calidad, es adecuado para uso profesional. Para tener calidad CD de audio se necesita que el sonido se grabe a 44100 Hz y a 16 bits. Por cada minuto de grabación de sonido se consumen unos 10 megabytes de espacio en disco. Una de sus grandes limitaciones es que solo se pueden grabar archivos de 4 gigabytes como máximo, lo cual equivale aproximadamente a 6,6 horas en calidad de CD de audio. Es una limitación propia del formato, independientemente de que el sistema operativo donde se utilice sea MS Windows u otro distinto, y se debe a que en la cabecera del fichero se indica la longitud del mismo con un número entero de 32 bits, lo que limita el tamaño del fichero a un máximo de 4294967295 bytes (o 4 gigabytes)

En Internet no es popular, fundamentalmente porque los archivos sin compresión son muy grandes. Son más frecuentes los formatos comprimidos con pérdida, como el MP3 o el Ogg Vorbis. Como éstos son más pequeños, la transferencia a través de Internet es mucho más rápida. Además, existen códecs de compresión sin pérdida más eficaces, como FLAC.


\subsubsection{Formato con compresión Mp3}

MPEG-1 Audio Layer III o MPEG-2 Audio Layer III, más comúnmente conocido como MP3 es un formato de compresión de audio digital patentado que usa un algoritmo con pérdida para conseguir un menor tamaño de archivo. Es un formato de audio común usado para música tanto en ordenadores como en reproductores de audio portátil.

Los archivos MPEG-1 corresponden a las velocidades de muestreo de 32, 44.1 y 48 kHz.

Los archivos MPEG-2 corresponden a las velocidades de muestreo de 16, 22.05 y 24 kHz.

MP3 fue desarrollado por el Moving Picture Experts Group (MPEG) para formar parte del estándar MPEG-1 y del posterior y más extendido MPEG-2. Un MP3 creado usando una compresión de 128kbit/s tendrá un tamaño de aproximadamente unas 11 veces menor que su homónimo en CD. Un MP3 también puede comprimirse usando una mayor o menor tasa de bits por segundo, resultando directamente en su mayor o menor calidad de audio final, así como en el tamaño del archivo resultante.

Este formato fue desarrollado principalmente por Karlheinz Brandenburg, director de tecnologías de medios electrónicos del Instituto Fraunhofer IIS, perteneciente al Fraunhofer-Gesellschaft-Schultagen - red de centros de investigación alemanes - que junto con Thomson Multimedia controla el grueso de las patentes relacionadas con el MP3. La primera de ellas fue registrada en 1987, en ese año en el laboratorio de tecnologías de medios electrónicos, los alemanes intentaban resolver un dilema, como difundir el sonido digital.Los archivos en CD, eran pesados y engorrosos, las lectoras de CD, eran novedad, también instalarlas en una PC, no así empezaban, a subir los primeros archivos en CD al disco duro de la computadora, todo esto ocurría en 1987, también registraron varias patentes más en 1991. Pero no fue hasta julio de 1995 cuando Brandenburg usó por primera vez la extensión .mp3 para los archivos relacionados con el MP3 que guardaba en su ordenador, en el proceso de desarrollo del formato participó también el ingeniero Leonardo Chiariglione quien tuvo la idea de los estándares que podrían ser útiles para este fin. Un año después su instituto ingresaba en concepto de patentes 1,2 millones de euros. Diez años más tarde esta cantidad ha alcanzado los 26,1 millones.

Tras el desarrollo de reproductores portátiles, y su integración en reproductores para automóviles y minisistemas de sonido hogareños, el formato MP3 en 2002 llega más allá del mundo de la informática.

El formato MP3 se convirtió en el estándar utilizado para streaming de audio y compresión de audio con pérdida de mediana fidelidad gracias a la posibilidad de ajustar la calidad de la compresión, proporcional al tamaño por segundo (bitrate), y por tanto el tamaño final del archivo, que podía llegar a ocupar 12 e incluso 15 veces menos que el archivo original sin comprimir.

Fue el primer formato de compresión de audio popularizado gracias a Internet, ya que hizo posible el intercambio de ficheros musicales. Los procesos judiciales contra empresas como Napster y AudioGalaxy son resultado de la facilidad con que se comparten este tipo de ficheros.

A principios de la década de los 2000 otros formatos de audio comprimido como Windows Media Audio, ATRAC, AAC y Ogg Vorbis empiezan a ser masivamente incluidos en programas de audio para computación, dispositivos, sistemas operativos, teléfonos y reproductores portátiles, lo que hizo prever que el MP3 fuera paulatinamente cayendo en desuso, en favor de otros formatos, como los mencionados, de mucha mejor calidad. Una de las desventajas del formato MP3 es que tiene patente. Técnicamente, el tener una patente no significa que su calidad sea inferior ni superior, pero impide que la comunidad pueda seguir mejorándolo y puede obligar a pagar por la utilización del códec; lo cual ocurre en el caso de los dispositivos que lo usan como los teléfonos y las tabletas. Aun así, hoy día, el formato mp3 continúa siendo el más usado y el que goza de más éxito con una presencia cada vez mayor. Algunas tiendas en línea como Amazon venden su música en este formato por cuestiones de compatibilidad.


Un fichero MP3 se constituye de diferentes tramas que a su vez se componen de una cabecera y los datos en sí. Esta secuencia de datos es la denominada ``stream elemental''. Cada una de las tramas es independiente, es decir, pueden ser cortadas las tramas de un fichero MP3 y después reproducirlos en cualquier reproductor MP3 del Mercado. La cabecera consta de una palabra de sincronismo que es utilizada para indicar el principio de una trama válida. A continuación siguen una serie de bits que indican que el fichero analizado es un fichero Standard MPEG y si usa o no la capa 3. Después de todo esto, los valores difieren dependiendo del tipo de archivo MP3. Los rangos de valores quedan definidos en la norma ISO/IEC 11172-3.

\subsubsection{Formato MIDI}

MIDI (abreviatura de Musical Instrument Digital Interface) es un estándar tecnológico que describe un protocolo, una interface digital y conectores que permiten que varios instrumentos musicales electrónicos, ordenadores y otros dispositivos relacionados se conecten y comuniquen entre sí. Una simple conexión MIDI puede transmitir hasta dieciséis canales de información que pueden ser conectados a diferentes dispositivos cada uno.

El sistema MIDI lleva mensajes de eventos que especifican notación musical, tono y velocidad; señales de control para parámetros musicales como lo son la dinámica, el vibrato, paneo, cues y señales de reloj que establecen y sincronizan el tempo entre varios dispositivos. Estos mensajes son enviados mediante un cable MIDI a otros dispositivos que controlan la generación de sonidos u otras características. Estos datos también pueden ser grabados en un hardware o software llamado secuenciador, el cual permite editar la información y reproduciría posteriormente.

La tecnología MIDI fue estandarizada en 1983 por un grupo de representativos de la industria de la música llamado MIDI Manufacturers Association (MMA). Todos los estándar MIDI son desarrollados y publicados en conjunto por la MMA en Los Angeles, California, en Estados Unidos; y para Japón, el comité MIDI de la Association of Musical Electronics Industry (AMEI) en Tokio.

Las ventajas del uso de MIDI incluyen su tamaño (una canción completa puede ser codificada en unos cientos de líneas, por ejemplo en algunos kilobytes) y la fácil manipulación, modificación y selección de los instrumentos.

\paragraph{El desarrollo del MIDI}



Para finales de los setenta, los dispositivos electrónicos musicales se volvieron más comunes y menos costosos en América del Norte, Europa y Japón. Los primeros sintetizadores analógicos eran usualmente monofónicos y controlados mediante el voltaje producido por sus teclados. Los fabricantes usaron este voltaje para conectar instrumentos en conjunto y así un solo dispositivo podría controlar uno u otros más, sin embargo este sistema no era adecuado para los sintetizadores polifónicos y digitales. Algunos fabricantes crearon sistemas que permitían que su propio equipo fuera interconectado, pero los sistemas no eran compatibles, así que los sistemas de otros fabricantes podrían no ser sincronizados con otros.

En junio de 1981, el fundador de Roland, Ikutaro Kakehashi, propuso la idea de una estandarización al fundador de Oberheim Electronics, Tom Oberheim, que en ese entonces habló con el presidente de Sequential Circuits, Dave Smith. En octubre de 1981, Kakehashi, Oberheim y Smith discutieron la idea con los representantes de Yamaha, Korg y Kawai.

Los ingenieros y diseñadores de sintetizadores de Sequential Circuits, Dave Smith y Chet Wood, concibieron la idea de una interface para sintetizadores universal que permitiera una comunicación directa entre el equipo de varios fabricantes. Smith propuso este estándar en noviembre de 1981 a Audio Engineering Society. Por los siguientes dos años, el estándar fue discutido y modificado por representativos de compañías como Roland, Yamaha, Korg, Kawai, Oberheim y Sequential Circuits, renombrado como Musical Instrument Digital Interface. El desarrollo del MIDI fue presentado al público por Robert Moog en octubre de 1982 en la revista Keyboard.

En la exhibición NAMM de enero de 1983, Smith logró presentar la conexión MIDI entre el sintetizador analógico Prophet 600 y el Jupiter-6. El protocolo MIDI 1.0 fue publicado en agosto de 1983 El estándar MIDI fue revelado por Ikutaro Kakehashi y Dave Smith, quienes después recibieron el Grammy técnico en 2013 por su papel en el desarrollo del MIDI.

\paragraph{El impacto del MIDI en la industria de la música}



El uso del MIDI estaba originalmente limitado a aquellos que quisieran hacer uso de instrumentos electrónicos en la producción musical. El estándar permitió que diferentes instrumentos pudieran comunicarse con otros y con los ordenadores. Esto causó una rápida expansión en las ventas y en la producción de instrumentos electrónicos y software musical. Esta intercompatibilidad permitió que un dispositivo pudiera ser controlado desde otro, lo que ayudó a músicos que tuvieran la necesidad de utilizar distintos tipos de hardware. La introducción del MIDI coincidió con la llegada de los ordenadores personales, los primeros samplers (los cuales permitían reproducir sonidos pre-grabados en presentaciones en vivo para incluir efectos que previamente no eran posibles fuera de los estudios) y los sintetizadores digitales, los cuales permitían almacenar sonidos preprogramados y posteriormente ser utilizados mediante un botón. Las posibilidades creativas que permitió la tecnología MIDI ayudaron a revivir la industria de la música durante los ochenta.

El MIDI introdujo muchas capacidades, las cuales transformaron la manera en que los músicos trabajaban. La secuenciación MIDI hizo posible que un usuario sin habilidad para la escritura musical pudiera desarrollar arreglos complejos. Un acto musical con uno o dos miembros, ambos operando múltiples dispositivos MIDI, puede ser una presentación con un sonido similar a grupos con mayor número de músicos. El costo de contratar músicos para un proyecto podría ser reducido o eliminado, y producciones complejas pueden ser realizadas en un sistema pequeño como una estación de trabajo MIDI, un sintetizador con un teclado integrado y un secuenciador. Músicos profesionales pueden realizar esto en un espacio llamado home recording, sin la necesidad de alquilar un estudio de grabación profesional con personal. Trabajando la preproducción en tal entorno, una artista puede reducir los costos de grabación llegando al estudio con un trabajo que está parcialmente completo. Las partes rítmica y de fondo pueden ser secuenciadas y posteriormente reproducidas en el escenario. Las presentaciones requieren menor transportación y tiempo de preparación del equipo debido a las diferentes y reducidas conexiones necesarias para reproducir varios sonidos. La tecnología educativa compatible con MIDI ha transformado la educación musical.

En 2012, Ikutaro Kakehashi y Dave Smith ganaron el Grammy técnico por el desarrollo del MIDI en 1983.

\paragraph{Control de instrumentos}



El MIDI fue inventado para que los instrumentos musicales se pudieran comunicar unos con otros y que un instrumento pudiera controlar a otro. Los sintetizadores analógicos que no tenían un componente digital y que fueron construidos antes del desarrollo del MIDI pueden ser ajustados con kits que convierten los mensajes MIDI a voltajes de control analógicos. Cuando una nota es tocada en un instrumento MIDI, ésta genera una señal digital que puede ser usada para activar la nota en otro instrumento. La capacidad de un control remoto permite que instrumentos de gran tamaño sean remplazados con pequeños módulos de sonido. Esto permite a los músicos combinar instrumentos para alcanzar un sonido pleno o para crear combinaciones como un piano acústico y cuerdas. MIDI también permite que otros parámetros de los instrumentos sean controlados de manera remota. Los sintetizadores y los samplers tienen varias herramientas para el modelado de un sonido. La frecuencia de un filtro y el ataque de una envolvente, o el tiempo que tarda un sonido en llegar a su valor máximo son ejemplos de los parámetros de los sintetizadores, y pueden ser controlados de manera remota a través de MIDI. Dispositivos de efectos tienen diferentes parámetros, como el tiempo de reverberación o delay. Cuando el número de un controlador MIDI es asignado a unos parámetros, el dispositivo responderá a los mensajes que reciba de dicho controlador. Controles como perillas, switches y pedales pueden ser utilizados para enviar estos mensajes. Un conjunto de parámetros establecidos puede ser guardado en la memoria de un dispositivo como un patch. Estos pueden ser seleccionados de manera remota a través de cambios de programa MIDI. El MIDI estándar permite una selección de 128 programas diferentes, pero los dispositivos pueden permitir más ajustando sus patches en bancos con 128 programas cada uno y combinando el mensaje de cambio de programa para la selección de un banco.

\paragraph{Composición}



Los eventos MIDI pueden ser secuenciados a través de un editor MIDI o una estación de trabajo especializada. Varias DAW están específicamente diseñadas para trabajar MIDI como componente integral. Las secuencias MIDI han sido desarrolladas en varios DAW para que los mensajes MIDI puedan ser modificados. Estas herramientas permiten a los compositores probar y editar su trabajo con una mayor rapidez y eficiencia que otras soluciones como la grabación multipista, mejorar la eficiencia de compositores y permitir crear arreglos complejos.

Debido a que el MIDI es un conjunto de comandos que crean sonidos, las secuencias MIDI pueden ser manipuladas de diferentes maneras en comparación con el audio pregrabado. Es posible cambiar la tonalidad, la instrumentación o el tempo de un arreglo MIDI y re-acomodar sucesiones de manera individual. La habilidad de componer ideas y escucharlas de manera inmediata permite a los compositores experimentar. Programas de composición algorítmica permiten que ejecuciones generadas por computadora puedan ser utilizadas como ideas para canciones o acompañamiento.

Algunos compositores tomaron ventaja de la tecnología MIDI 1.0 y el General MIDI (GM) que permitía transferir datos musicales entre varios instrumentos utilizando un set de comandos y parámetros estandarizado. Los datos compuestos a través de una secuencia MIDI pueden ser guardados como Standard MIDI File (SMF), distribuidos de manera digital y reproducidos por cualquier computadora o instrumento electrónico que esté adherido al mismo estándar MIDI, GM, y SMF. Los datos MIDI son mucho más pequeños que las grabaciones de archivos de audio.

\paragraph{MIDI y los ordenadores}



En la época en que el MIDI fue introducido la industria de la computación estaba enfocada en ordenadores mainframe.Los ordenadores personales no eran muy comunes. El mercado de los ordenadores personales se estabilizó al mismo tiempo en que el MIDI apareció, con ellos los ordenadores se convirtieron en una opción viable para la producción musical. En los años posteriores a la ratificación de la especificación MIDI, las características MIDI fueron adaptadas a varias de las primeras plataformas, incluyendo Apple II Plus, IIe y Macintosh, Commodore 64 y Amiga, Atari ST, Acorn Archimedes, y PC DOS.
Machintosh fue la favorita entre los músicos estadounidenses.
Se encontraba a un precio competitivo, y sería años después que la eficiencia y su interfaz gráfica sería igualada por las PC's. El Atari ST fue el favorito de Europa, donde las Machintosh eran más caras. Las computadoras Apple incluían un hardware de audio que era más avanzado que el de sus competidores. La Apple IIGS usaba un chip de sonido digital diseñado para el sintetizador Ensoniq Mirage. En posteriores modelos se empleó un sistema especializado de audio con procesadores mejorados, los cuales llevaron a las demás compañías a mejorar sus productos. El Atari ST era preferido debido a que los conectores MIDI estaban integrados directamente en la computadora. La mayoría del software musical de la primera década de publicación del MIDI fue para la Apple o el Atari. Para el lanzamiento del Windows 3.0 en 1990, las PC's habían mejorado su interfaz gráfica junto con sus procesadores, por lo que diferentes softwares comenzaron a aparecer en diferentes plataformas.


\textbf{Archivos MIDI estándar}


El formato estándar MIDI permite una manera estandarizada para almacenar, transportar y abrir secuencias en otros sistemas. El compacto tamaño de estos archivos ha permitido que sean implementados de manera numerosa en ordenadores, teléfonos y páginas de Internet. Fueron creados para su uso universal e incluir información como el valor de las notas, tiempo y nombre de las pistas. La lírica puede ser incluida como metadata, que puede ser visualizada en máquinas de karaoke. La especificación SMF fue desarrollada y mantenida por MMA. Los SMF's son creados como formato para exportar información a secuenciadores software o estaciones musicales de trabajo. Organizan los mensajes MIDI en una o más pistas y en marcas temporales para volver a reproducir las secuencias. Una cabecera contiene la información del número de pistas, tempo y en cuál de los tres formatos SMF esta el archivo. Un archivo del tipo 0 contiene la información de una presentación completa en una sola pista, mientras que las de tipo I contienen la información de cada una de las pistas ejecutadas de manera sincronizada. Los archivos de tipo II raramente son utilizados y guardan múltiples arreglos, cada uno tiene su propia pista para ser reproducida en secuencia. Microsoft Windows empaqueta el SMF con Downloadable Sounds (DLS) en un archivo informático para el intercambio de recursos (RIFF), con archivos RMID con extensión .rmi. RIFF-RMID ha sido depreciado a favor de Extensible Music Files (XMF).


\textbf{Intercambio de archivos}


Un archivo MIDI no es una grabación de la música. En cambio, es una secuencia de instrucciones, que puede ocupar 1000 veces menos espacio en disco que una grabación. Esto hizo que los arreglos hechos en archivos MIDI se convirtieran en una manera más atractiva de compartir música, antes de la llegada del Internet y dispositivos con un almacenamiento superior. Los archivos MIDI licenciados se encontraban disponibles en formato de disquete en tiendas de Europa y Japón durante los noventas. La mayor desventaja de esto era la gran variedad que existía ente las tarjetas de audio de los usuarios y las muestras de audio o sonidos sintetizados en la tarjeta que el MIDI retomaba de manera simbólica. Aun una tarjeta de sonidos con samples de alta calidad puede tener inconsistencias entre la calidad de un instrumento a otro, mientras que diferentes modelos de tarjetas no garantizaban un consistencia en el sonido de un mismo instrumento. Las primeras tarjetas económicas, como AdLib y Sound Blaster, utilizaban una versión simplificada de la tecnología de síntesis por modulación de frecuencias de Yamaha reproducida a través de convertidores digitales-analógicos de baja calidad. La baja calidad de reproducción de estas tarjetas ubicuas se asumía que de algún modo era debido al MIDI. Esto creo la percepción del MIDI como audio de bajo calidad, mientras que en realidad el MIDI no tiene un sonido  y la calidad de su reproducción depende totalmente de la calidad el dispositivo que lo reproduzca (y los samples del dispositivo).


\textbf{Software MIDI}


La principal ventaja de los ordenadores personales en un sistema MIDI es que puede ser utilizado con diferentes propósitos, dependiendo del software utilizado.La capacidad multitarea de los sistemas operativos permite la operación de varios programas de manera simultánea que puedan compartir los datos unos con otros.


\textbf{Secuenciadores}


Un software para secuenciar permite ciertos beneficios para un compositor u arreglista. Permite que el MIDI grabado sea manipulado utilizando a través de las características de edición básicas de un ordenador como cortar, copiar y pegar o arrastrar y soltar. Los atajos de teclado pueden ser utilizados para agilizar el ritmo de trabajo y las herramientas de edición MIDI pueden ser seleccionadas a través de comandos. El secuenciador permite que cada canal sea reproducido por un sonido diferente además de mostrar una pre-visualización gráfica del arreglo. Existen distintas herramientas de edición, incluyendo una visualización en notación musical. Herramientas como loops, cuantización, aleatoriedad y transposición simplifican el proceso de creación de arreglos. La creación de beats es simplificada y el groove puede ser duplicado en la sensación rítmica de otra pista. La expresión realista puede ser agregada a través de la manipulación de controladores en tiempo real. Una mezcla puede ser llevada a cabo y el MIDI puede ser sincronizado con pistas de audio o video grabadas. Los avances pueden ser guardados y llevados a otra computadora o estudio

Los secuenciadores pueden tomar diferentes formas como editores de ritmos de batería que permiten al usuario crear ritmos a través de clics en rejillas de patrones y hacer loops con secuencias, por ejemplo el ACID Pro, que permite al MIDI ser combinado con audios pre-grabados cuyos tiempos y notas son empatados. La secuencia de cúes es utilizada para activar diálogos, efectos de sonido y segmentos musicales en transmisiones.

Existen programas que de manera dinámica pueden generar pistas de acompañamientos llamadas programas de ``auto-acompañamiento''. Estos crean el arreglo de una banda completa a partir del estilo que usuario seleccione, los resultados son enviados a un dispositivo de sonido MIDI para generar los sonidos. Las pistas generadas pueden ser utilizadas como herramientas de practica o educativas, también como acompañamiento para presentaciones en vivo o ayuda para la composición de canciones.

\paragraph{Dispositivos MIDI}



\textbf{Conectores}


Los cables terminan en un conector DIN de 180º. Las aplicaciones estándar emplean solo tres de los cinco conductores: tierra y un par de cables balanceados que llevan un señal de 5v. Esta configuración del conector solo puede llevar mensajes en una dirección, así que es necesario un cable para una comunicación de dos vías. Algunas aplicaciones prioritarias como la alimentación phantom para algunos controladores utilizan los pines sobrantes para la transmisión de corriente directa (DC).


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.2]{Imagenes/MIDI_connector2.png}
% Ponemos Leyenda al gráfico
\caption{Conector clásico MIDI}
\label{Conector clásico MIDI}
\end{center}
\end{figure}

Optoacopladores mantienen los dispositivos MIDI eléctricamente separados de otros conectores, lo cual previene bucles de masa y protege al equipo de picos de voltage.No hay manera de detectar errores en MIDI, así que el tamaño máximo del cable es de 15 metros para limitar interferencias destructivas.

La mayoría de los dispositivos no copian los mensajes de la entrada a su puerto de salida. Un tercer tipo de puerto, el puerto ``thru'', emite una copia de todo lo que es recibido en el puerto de entrada, permitiendo que los datos sean transmitidos a otro instrumento en una ``Daisy chain''.No todos los dispositivos cuentan con un puerto thru y dispositivos que carecen de la característica de generar datos MIDI, como unidades de efectos o módulos de sonido, pueden no incluir un puerto de salida.


\textbf{Interfaces}


La función principal de una interfaz MIDI para ordenador es sincronizar los relees entre un dispositivo MIDI y el ordenador. Algunas tarjetas de sonido de ordenador incluyen un conector MIDI estándar, mientras que en otras se conecta a través de D-sub, USB, Firewire o Ethernet. El creciente uso de conectores USB en los 2000's ha llevado a una disponibilidad de interfaces MIDI a USB que puedan transferir canales MIDI a computadoras con USB incluido. Algunos controladores MIDI están equipados con conectores USB y pueden ser conectados en ordenadores que empleen software musical.

La transmisión serial MIDI lleva a problemas de sincronización. Músicos experimentados pueden detectar diferencias de 1/3 de milisegundos (ms) (es el tiempo que tarda el sonido en viajar 4 pulgadas) y un mensaje MIDI de 3 bytes requiere 1ms para transmitirse. Debido a que el MIDI es serial, solo puede ser enviado un evento a la vez. Si un evento es enviado a dos canales a la vez, el evento con número de canal mayor no podrá ser transmitido hasta que el primero haya acabado y será retrasado 1ms. Si un evento es enviado a todos los canales al mismo tiempo, el evento con un número de canal mayor será retrasado por mucho 16ms. Esto ha contribuido a el surgimiento de interfaces MIDI con múltiples entradas y salidas debido a que la sincronización mejora cuando los eventos son enviados en diferentes puertos a diferencia de varios canales en un mismo puerto. El término ``tropiezo MIDI'' se refiere a los errores audibles resultantes de una transmisión retrasada.

\paragraph{Controladores}

Existen dos tipos de controladores MIDI: controladores para performance que generan notas y son utilizados para ejecutar música, y controladores que pueden no transmitir notas pero pueden transmitir otros tipos de eventos en tiempo real. Varios dispositivos son la combinación de los dos tipos.


\textbf{Controladores para performance}


El MIDI fue diseñado con los teclados en mente y cualquier otro controlador que no posea un teclado es considerado como un controlador ``alternativo''. Esto ha sido visto como una limitación para los compositores que no están interesados la música que emplea teclados, la flexibilidad y compatibilidad MIDI fue introducida a otros tipos de controladores incluyendo guitarras, instrumentos de viento y cajas de ritmo.


\textbf{Teclados}


Los teclados musicales son el tipo de controlador MIDI más común. Pueden ser encontrados en diferentes tamaños desde 25 teclas, modelos de dos octava, hasta instrumentos de 88 teclas. Algunos solo incluyen el teclado, aunque existen otros controladores en tiempo real como perillas, sliders y palancas. Usualmente existen conexiones para pedales de sustain y de expresión. La mayoría de los controladores con teclado permiten dividir el área de piano en zonas, las cuales pueden ser de diferentes tamaños y sobreponerse. Cada zona corresponde a un canal MIDI diferente y un set diferente de controladores, pueden ser usados para tocar cualquier rango de notas seleccionado. Esto permite a un solo instrumento tocar varios sonidos. Las capacidades MIDI también pueden ser encontradas en instrumentos de teclado tradicionales como pianos y pianos Rhodes. Pedaleros pueden controlar los tonos de un órgano MIDI o pueden tocar un sintetizador como el Moog Taurus.


\textbf{Baterías y controladores de percusión}


Los teclados pueden ser utilizados para accionar sonidos de baterías pero no son prácticos para tocar patrones repetitivos como redobles debido a las dimensiones de las teclas. Después de los teclados, los pads de batería son los controladores para performance MIDI más significantes. Los controladores de percusión pueden estar integrados en cajas de ritmo, pueden ser superficies de control independientes o emular y sentirse como instrumentos de percusión. Los pads integrados en cajas de ritmos usualmente son muy pequeños y frágiles para ser tocados con baquetas, por lo que son tocados con los dedos. Drum pads especializados como el Roland Octapad o el DrumKAT son tocados con las manos o baquetas, están construidos como un set de batería. Existen otros controladores de percusión con el MalletKAT, parecido al vibráfono, y el Marimba Lumina de Don Buchla. Accionadores MIDI pueden ser instalados en una batería acústica e instrumentos de percusión. Los \gls{Pads} pueden accionar un dispositivo MIDI que puede ser casero a partir de un sensor piezoeléctrico o un pad de practica.

\paragraph{Instrumentos}

Un instrumento MIDI tiene puertos para enviar y recibir señales MIDI, un CPU para procesar dichas señales, una interfaz que permita al usuario programarlo, un circuito de audio que genere sonidos y controladores. El sistema operativo y los sonidos de fábrica usualmente están almacenados en una memoria de solo lectura (ROM).

Un instrumento MIDI también puede ser un modulo independiente (sin la necesidad de un teclado) conformado por una tarjeta de sonido General MIDI (GM, GS y /XG) editable dentro de la misma, incluyendo cambios de transport/tono, cambios de instrumento MIDI, ajuste de volumen, panel, niveles de reverberación y otros controladores MIDI. Normalmente, el modulo MIDI incluye una pantalla grande, permitiendo al usuario visualizar la información dependiendo de la función seleccionada. Otras funciones incluyen el visualizar la lírica, usualmente incluida en un archivo MIDI o Karaoke MIDI, listas de pistas, librería de canciones y pantallas de edición. Algunos módulos MIDI incluyen un armonizador y la capacidad de reproducir y reajustar archivos MP3.


\textbf{Sintetizadores}


Los sintetizadores pueden emplear cualquier variedad de técnicas para generar sonido. Estos normalmente incluyen un teclado integrado, o pueden existir como ``módulos de sonido'' que generan sonidos a partir de un controlador externo. Los módulos de sonidos están típicamente diseñados para ser colocados en un rack de 19 pulgadas. Los fabricantes producen comúnmente un sintetizador en versiones independiente y para rack, usualmente la versión con teclado varia de tamaño.


\textbf{Samplers}


Un sampler puede grabar y digitalizar audio, almacenarlo en una memoria de acceso aleatorio (RAM) y reproducirlo posteriormente. Los samplers normalmente permiten al usuario editar un sample y guardarlo en un disco duro, aplicarle efectos y modificar su sonido a través de las mismas herramientas usadas en los sintetizadores. También pueden tener un teclado o estar montados en un rack. Los instrumentos que generan sonidos a través de su reproducción pero que no tienen capacidades de grabación son conocidos como ``ROMplers''.

Los samplers no se convirtieron en instrumentos MIDI viables tan rápido como lo hicieron los sintetizadores debido al costo de la memoria y el poder de procesamiento en este entonces. El primer sampler MIDI de bajo costo fue el Ensoniq Mirage, lanzado en 1984. Los samplers MIDI normalmente están limitados debido a sus pequeñas pantallas empleadas para editar las formas de onda sampleadas, aunque algunos pueden ser conectados a un monitor de computadora.


\textbf{Cajas de ritmos}


Las cajas de ritmos normalmente son dispositivos especializados que reproducen samples de batería y sonidos de percusión. Usualmente tienen un secuenciador que permite la creación de patrones ritmos para incorporarlos en el arreglo de alguna canción. Comúnmente tienen múltiples salidas que permiten que cada uno de los sonidos sea asignado a cada una. Los sonidos individuales de las baterías pueden ser reproducidos desde otro instrumento MIDI o desde un secuenciador.

\paragraph{Especificaciones técnicas}

Los mensajes MIDI están conformados de una ``palabra'' de 8 bits (llamados bytes) que son transmitidos de manera serial a 31.25 kbit/s. Esta tasa fue escogida debido a que es una división exacta de 1 MHz, la velocidad en la que varios de los primeros microprocesadores operan. El primer bit de cada palabra identifica si la palabra es un byte de estatus o de datos, los siguientes siete bits son la información. Un bit de inicio y otro de pausa son agregados a cada byte por cuestiones de sincronización, así que un mensaje MIDI requiere de diez bits para transmitirse.

Una conexión MIDI puede llevar dieciséis canales independiente de información. Los canales son numerados del 1 al 16 pero en realidad corresponden al orden del código binario del 0 al 15. Un dispositivo puede ser configurado para solo escuchar canales específicos e ignorar los mensajes enviados de otros o puede escuchar a todos los canales sin importar su dirección. Un dispositivo puede ser monofónico (el inicio de una nueva señal de ``note-on'' MIDI implica el final de la nota previa) o polifónico (múltiples notas pueden sonar al mismo tiempo, hasta que el límite de la polifonía del instrumento se haya alcanzado, las notas hayan terminado su envolvente o el comando ``note-off'' haya sido recibido. Los dispositivos que reciben los mensajes normalmente tienen cuatro combinaciones de los modos ``omni off/on'' vs. ``mono/poly''.

En la especificación técnica hay 128 Instrumentos General MIDI para el proyecto el que nos interesa es el número 10 - Caja de música.

La flexibilidad del MIDI y su gran aceptación ha llevado a varios refinamientos del estándar, además ha permitido que se aplique a propósitos más allá de los que se tenían planeados. Para ello se han diseñado extensiones al general MIDI.

\paragraph{Hardwares alternativos de transporte}

Además de la tasa de transmisión 31.25 kbit/s en un conector DIN de cinco pines, otros conectores comunes han sido usados para la misma información eléctrica y la transmisión de señales MIDI en diferentes formas a través de USB, IEEE 1394 o FireWire y Ethernet .


\textbf{USB y FireWire}


Los miembros de USB-IF en 1999 desarrollaron un estándar para MIDI a través de USB, el ``Universal Serial Bus Device Class Definition for MIDI Devices'' El MIDI sobre el USB ha sido más común que otras interfaces que ha sido empleadas para las conexiones MIDI (serial, joystick, etc.) han desaparecido de las computadoras personales. Los sistemas operativos Microsoft Windows, Macintosh OS X y Apple iOS han incluido drivers para compatibilidad con ``Universal Serial Bus Device Class Definition for MIDI Devices''. Los drivers también están disponibles para Linux. Algunos fabricantes decidieron implementar una interface MIDI sobre el USB que está diseñado para operar diferente de la especificación, usando drivers personalizados.

Apple Computer desarrollo la interface FireWire durante los noventas. Comenzó a aparecer en cámaras de video digitales hacia finales de la década y en modelos de la G3 Macintosh en 1999. Fue creado para aplicaciones multimedia. A diferencia del USB, FireWire usa controladores inteligentes que pueden manejar su propia transmisión sin la atención de un CPU principal.

\textbf{Ethernet}

La implementación del MIDI en la red de computadoras permite nuevas capacidades de conexiones y permite un canal con gran ancho de banda que las primeras alternativas de MIDI, como ZIPI, trataron de crear. Las implementaciones propietarias han existido desde los ochentas, como lo es el uso de cables fibra óptica para la transmisión.La especificación abierta RTP MIDI del Grupo de trabajo de ingeniería de Internet está adquiriendo el apoyo de la industria debido a que los protocolos propietarios MIDI/IP requieren costos altos de licencias o no ofrecen ninguna ventaja además de la velocidad sobre el protocolo MIDI original. Apple ha apoyado este protocolo desde Mac OS X 10.4 y un driver de Windows basado en la implementación de Apple existe desde Windows XP y para las nuevas versiones.

\paragraph{Versiones de MIDI}

Una nueva versión de MIDI, llamada de manera tentativa ``Protocolo HD'' o ``High-Definition Protocol'', fue anunciada como ``HD-MIDI''. Este nuevo estándar ofrece retrocompatibilidad con el MIDI 1.0 y está planeado que soporte grandes velocidades de transmisión, permitir la detección de dispositivos con solo conectarlos, enumerarlos y ofrecer un gran rango de datos y resolución. Los números de los canales y los controladores aumentaran, nuevos tipos de eventos serán agregados y los mensajes serán simplificados. Nuevo eventos serán soportados como Note Update y Direct Pitch que están enfocados a controladores de guitarra. Las capas físicas propuestas incluyen protocolos basados en Ethernet como RTP MIDI y Audio Video Bridging. El protocolo HD y un protocolo de transporte basado en User Datagram Protocol (UDP) están bajo la revisión de High-Definition Protocol Working Group (HDWG) de MMA, el cual incluye a los representantes varias compañías.Prototipos de dispositivos basados en las primeras fases del protocolo han sido mostrados de manera privada en NAMM usando tanto conexiones alambicas como inalámbricas, sin embargo es incierto si el protocolo será retomado por la industria. En 2015, las especificaciones del protocolo HD están cerca de su finalización y MMA desarrolla las políticas de licencias y certificaciones de productos. Debido a que el costo de almacenamiento de datos ha disminuido, la música MIDI se ha visto remplazada por audio comprimido en productos comerciales, haciendo nuevamente del MIDI una herramienta para la producción musical. La conectividad MIDI y un sintetizador de software aún se incluye en Windows, OS X y iOS pero no en Android.


\subsection{Baterias-MIDI y proyectos en entornos libre}

Ahora detallaremos la idea de una batería MIDI simple y de su comparación con las profesionales.


\subsubsection{Arduino}


Para crear una batería simple, lo más fácil en la actualidad seria coger un microcontrolador como las placas de electrónica de Arduino. 

La primera idea más básica es coger una entrada digital de 1 bit por simplicidad y si se activa hacer que el Arduino reproduzca un sonido.

De esta manera podemos decir que tenemos una batería de 1 pad.


El primer detalle que se observaría  es que como se ha escogido una entrada digital de 1 bit nuestra batería electrónica siempre sonaría con la misma intensidad, independientemente de la intensidad que se toque al pad.

Para solucionar esto desde los años 80 se han usado unos componentes electromecánicos conocidos como sensor piezoeléctrico que es un dispositivo que utiliza el efecto piezoeléctrico para medir presión, aceleración, tensión o fuerza; transformando las lecturas en señales eléctricas.


Por tanto pasando de 1 señal digital de 1 bit , a una entrada analógica ya se tiene la posibilidad de saber la intensidad con que se ha tocado el pad.

Poniendo sensores piezoeléctricos y conectando lo correctamente a entradas analógica  ya comenzamos a tener lo que seria un pad de una batería electrónica muy básica, pero funcional.

 

El añadido siguiente es pasar a ``n'' entradas. Aquí ya vemos el primer detalle a tener en cuenta si la programación esta realizada para que todo sea secuencial, (que es la manera básica de programar el Arduino)  si los sonidos a reproducir son un poquito largos observaríamos que esta batería no puede hacer sonar dos \gls{Pads} al mismo tiempo.



Para resolver el problema del paralelismo a obtener en los sonidos, hay varias soluciones:
\begin{itemize}
  \item Ir a una ejecución en paralelo de nuestra idea básica de comprobar las entradas y reproducir un sonido si hay una activa.
  \item Ir a micro-controladores más potentes, para que sea más rápido a la hora de comprobar las entradas y reproducir el sonido.
  \item Separar nuestra idea de batería en dos partes un Arduino que recoge las señales de los \gls{Pads}, pero que no reproduce nada, y al tener una gran velocidad de muestreo nos podría parecer que si que esta comprobando las entradas en paralelo.
\end{itemize}

Para continuar nuestra idea de batería electrónica simple separamos la parte de las entradas de la tarea de reproducir un sonido en concreto. De esta manera se ha obtenido una de las grandes ventajas de las baterías MIDI, al ser electrónicas se puede cambiar el sonido que generan.


\subsubsection{Baterías-MIDI}

Ahora para continuar mejorando esta batería electrónica, lo que se debería hacer es coger un Arduino, con la posibilidad de programar una salida MIDI. 

Si se escoge un Arduino de tipo más bajo se nos daría el siguiente problema, como solo tienen un usb que se emplea para programar, o ponemos un conector extra para que haga de salida MIDI, o perdemos la opción de programar en ese usb, mientras se esta usando como salida MIDI.

Para evitar esta problemática, lo más sencillo es coger un Arduino que si que tenga la opción tener un usb para comunicarse con un ordenador sin perder el usb para programar el Arduino.

Por lo que tenemos es una batería con ``n'' \gls{Pads} con intensidad y conectándola a un sintentizador ya tenemos lo que seria una batería electrónica básica.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=1.0]{Imagenes/drum-arduino.jpg}
% Ponemos Leyenda al gráfico
\caption{Ejemplo de batería electrónica de 4 pads basada en Arduino}
\label{Ejemplo de batería electrónica de 4 pads basada en Arduino}
\end{center}
\end{figure}


Aquí ya podemos establecer las diferencias con las baterías profesionales.
 

\subsubsection{Baterías-MIDI profesionales}

Evidentemente el mundo de las baterías electrónicas profesionales es muy amplio, para los objetivos de este expediente nos centraremos en las grandes diferencias que hay de esta batería electrónica, con las baterías profesionales.

\paragraph{Baterías de entrada}

Para representar las baterías electrónicas de entrada escogemos a la Yamaha DD-65.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.3]{Imagenes/dd-65.jpg}
% Ponemos Leyenda al gráfico
\caption{Yamaha DD-65}
\label{Yamaha DD-65}
\end{center}
\end{figure}

Como se puede observar la mayor diferencia a simple vista con la batería que se ha creado con Arduino solo es el número de \gls{Pads}, que esto hemos visto que tiene fácil solución, pero se puede observar ya otra diferencia tiene dos pedales, se podría pensar en la misma solución poner 2 \gls{Pads} más y ponerlos en el suelo para activarlos con los pies.

Aquí tendríamos que recordar el aspecto de que el hihat suena distinto según su pedal ,por lo que en nuestra batería tendríamos que actuar en consecuencia. 

He aquí una de las mayores problemática que existe a la hora de afrontar que es una batería electrónica. Yamaha con esta batería lo que quiere hacer es una batería electrónica que se aproxima por un precio mínimo igual que una batería acústica. Yamaha indica que esta batería es independiente por lo que se puede tocar sin tener que conectar a un ordenador.

En esta batería se pueden conectar otros pedales para hihat y bombo que se asemejen más a unos reales.

Esta batería tiene 254 sonidos y 50 baterías predefinidas con ellos, de todas manera se puede configurar 3 baterías con cualquiera de esos 254 sonidos.

\paragraph{Baterías semiprofesionales}

 A mayor precio ya tenemos la gama de Roland V-Drums Lite
 
\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.2]{Imagenes/V-Drums_Lite_HD-3.jpg}
% Ponemos Leyenda al gráfico
\caption{Roland V-Drums Lite HD-3}
\label{Roland V-Drums Lite HD-3}
\end{center}
\end{figure}

Se puede observar en esta batería es la misma idea que la anterior pero físicamente más parecida a una batería real para que si alguien se acostumbra a tocar en esta batería, el cambio a una batería acústica sera mucho menor.

En esta batería tiene 20 baterías predefinidas y no da la posibilidad de modificarlas en su propio sintetizador, Roland supone que si se quiere modificar la batería se hará a través del canal MIDI-out en otro sintetizador(u ordenador).

En esta batería físicamente no se pueden modificar los \gls{Pads} ni los pedales ya que están soldados los cables que van al sintetizador.


\paragraph{Baterías profesionales}

 A mayor precio ya tenemos la gama de Roland V-Drums T, ponemos por ejemplo la TD-30.
 
\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.7]{Imagenes/td-30.jpg}
% Ponemos Leyenda al gráfico
\caption{Roland TD-30}
\label{Roland TD-30}
\end{center}
\end{figure}

Aquí a simple vista lo único que se observa seria que han aumentado el número de platillos, el hihat es más parecido a uno real e incluso tiene 3 pedales para tener el doble bombo y el hihat, separados e independientes.

Pero evidentemente hay mucho más, internamente la calidad del sonido se ha ido aumentado.

Aunque los \gls{Pads} que hacen de platillos parecen igual que los segundos y podríamos pensar que es la misma idea que nuestra batería construida con el Arduino. En esta batería los platillos tienen varios piezos para poder configurarlos de varias maneras la más simple es que según se detecte el piezo más superior o el del borde sonara un sample distinto,siendo más cercano a lo que sonaría en una batería acústica, otra manera de configurar estos platillos es que si se toca el piezo más cercano al borde para el sonido, imitando lo que pasa si se cogiera un platillo real con las manos.

Todo en esta batería se puede modificar. Samples, cambiar pads o pedales.


\paragraph{Conclusiones}
Hemos observado las características principales de las baterías-MIDI que se pueden comprar en el mercado que se podrían resumir en:

\begin{itemize}
  \item Se ha de aproximar en la medida de lo posible a una batería acústica. 
  \item Todas tienen salida MIDI.
\end{itemize}

Las principales diferencias son:
\begin{itemize}
  \item Número de \gls{Pads} y colocación de estos.
  \item Número de entradas dedicadas a los pedales.
  \item La capacidad de modificar los samples internos que tienen.
  \item La capacidad de modificar su funcionamiento interno.
\end{itemize}

\subsection{Reproductores DTXMania en entornos libres}

Ahora ya podemos ver actualmente el estado de estos juegos musicales y otros para baterías-MIDI en entornos libres.

Actualmente existen los programas DTXMANIA,DTXMANIA HD y Gitadora.

Todos estos programas están programados para PC, pero entendiendo PC, por Windows evidentemente plataforma x86 y como es un japones el que los esta programando usando características de Windows en Japón.

Desde hace bastante tiempo dejo el programa como software libre, se puede consultar todo en :

\url{https://osdn.jp/projects/dtxmania/} Eso si la gran mayoría de la documentación estando en perfecto japones.

Las opciones de usarlo en entornos libres, se nos quedan cortas ya que en entornos con plataformas basadas en x86, se podría usar WINE, pero aunque se ponga las opciones de lenguaje en japones, parece que no llega a crear bien o acceder a los archivos por problemas codificación japones y sistema de ficheros y no se llega ni acceder al menú inicial, de cualquiera de estos programas  (Versión probada de wine 1.9).


Ya no indicamos ninguna posibilidad para entornos arm donde no disponemos de esta opción.

Hubo un proyecto antiguo llamado DigiBand el cual era un simulador/juego de baterías en entornos libres, que podía funcionar con canciones con el formato DTX, este programa tiene varios inconvenientes.
\begin{itemize}
  \item En el 2005 fue la última vez que alguien modifico el código fuente.
  \item Emplea librerías que ya en 2005 estaban deprecated.
\end{itemize}

Se ha intentado compilarlo tanto en entorno x86-64, usando un fedora 24 para ello como en un entorno arm usando una Raspberry. Y no se ha podido compilar, tanto por las dependencias antiguas que tiene como por todos los cambios de librerías que se han sucedido en estos 10 años.


\subsubsection{Problemas con los otros juegos musicales similares}


Ahora vamos a mirar las otros juegos musicales para poder afianzar la base con la que trabajar.

Los juegos de \gls{Rock Band} salieron para consolas pero no llegaron a salir para PC, por lo que  ya no digamos plataformas en entornos libres.

Hay un juego que se considera el nuevo sucesor espiritual del \gls{Rock Band} para PC, que es el PhaseShift misma idea pero gráficos más actualizados, usando como base:

\begin{itemize}
  \item Windows XP/ Vista / 7
  \item DirectX 9.0c
  \item VC++ Redist
\end{itemize}

Y cuando se les pregunta a los autores de PhaseShift por MAC o linux, contestan:
\begin{itemize}
  \item Q. Will you add support for Mac / Linux
  \item A. We do not have the resources to develop native versions, but the game is now compatible with Wine / Crossover.
\end{itemize}

Por lo que se deduce es que se podría llegar a tener en entornos ``libres'' usando WINE por lo que no se tiene la opción de arquitecturas diferentes a x86.


El juego FoFiX como salio de un proyecto (Frets on fire) que era libre, no fue muy difícil modificarlo para que funcionar en entornos libres.
En entornos x86 no tiene mayor inconveniente el problema esta en los entornos arm que al no soler tener OpenGL, no funciona. Indicar que en el entorno de la Raspberry pi, tanto en la 2 como en la 3 activando el driver beta OpenGL, comienza a funcionar, pero no se llega a ver todo bien y todavía hay muchos flecos a resolver en el driver de OpenGL.


El juego Dance Dance Revolution como hemos comentado antes si que tiene una versión libre, el StepMania en esa versión le pasa lo mismo que al FoFiX en plataformas x86, funciona bien pero cuando nos pasamos a entornos arm es cuando hay problemas con toda la parte gráfica ya que emplea OpenGL para toda la parte gráfica.

Aunque existe un juego llamado PyDance que emplea librerías de muy bajo nivel, lo que hace que tenga menús muy simplificados y poca carga gráfica mientras se juega a DDR se puede hacer funcionar tanto en entornos x86 como arm sin necesidad de tener OpenGl. Eso si esta pensado para canciones de tipo DDR no DTXMANIA.  


\subsection{Raspberry}

Raspberry PI es un ordenador de placa reducida o (placa única) (SBC) de bajo coste, se podría decir que es un ordenador de tamaño reducido, del orden de una tarjeta de crédito, desarrollado en el Reino Unido por la Fundación Raspberry PI (Universidad de Cambridge) en 2011, con el objetivo de estimular la enseñanza de la informática en las escuelas, aunque no empezó su comercialización hasta el año 2012.

Aunque no se indica expresamente si es hardware libre o con derechos de marca, explican que disponen de contratos de distribución y venta con dos empresas, pero al mismo tiempo cualquiera puede convertirse en revendedor o redistribuidor de las tarjetas RaspBerry Pi, por lo que se entiende que es un producto con propiedad registrada pero de uso libre. De esa forma mantienen el control de la plataforma pero permitiendo su uso libre tanto a nivel educativo como particular.


En cambio el software sí es open source, siendo su sistema operativo oficial una versión adaptada de Debian, denominada RaspBian, aunque permite otros sistemas operativos, incluido una versión de Windows 10.

El concepto es el de un ordenador desnudo de todos los accesorios que se pueden eliminar sin que afecte al funcionamiento básico. Está formada por una placa que soporta varios componentes necesarios en un ordenador común y es capaz de comportarse como tal.

El diseño de la Raspberry Pi 1 u original incluye:

\begin{itemize}
  \item Un Chipset Broadcom BCM2835, que contiene un procesador central (CPU) ARM1176JZF-S a 700 MHz (el firmware incluye unos modos Turbo para que el usuario pueda hacerle overclock de hasta 1 GHz sin perder la garantía).
  \item Un procesador gráfico (GPU) VideoCore IV.
  \item Un módulo de 512 MB de memoria RAM (aunque originalmente al ser lanzado eran 256 MB).
  \item Un conector de RJ45 conectado a un integrado lan9512 -jzx de SMSC que nos proporciona conectividad a 10/100 Mbps
  \item 2 conexiones USB 2.0
  \item Una Salida analógica de audio estéreo por Jack de 3.5 mm.
  \item Salida digital de video + audio HDMI
  \item Salida analógica de video RCA
  \item Pines de entrada y salida de propósito general
  \item Conector de alimentación microUSB
  \item Lector de tarjetas SD
\end{itemize}


\subsubsection{Historia} 
Este proyecto fue ideado en 2006 pero no fue lanzado al mercado febrero de 2012. Ha sido desarrollado por un grupo de la Universidad de Cambridge y su misión es fomentar la enseñanza de las ciencias de la computación los niños. De hecho, en enero de este año Google donó más de 15.000 Raspberry Pi para colegios en Reino Unido. La Raspberry Pi, es una excelente herramienta para aprender electrónica y programación.

Los primeros diseños de Raspberry Pi se basaban en el microcontrolador Atmel ATmega644. Sus esquemas y el diseño del circuito impreso están disponibles para su descarga pública.

La fundación Raspberry Pi surge con un objetivo en mente: Desarrollar el uso y entendimiento de los ordenadores en los niños. La idea es conseguir ordenadores portables y muy baratos que permitan a los niños usarlos sin miedo, abriendo su mentalidad y educándolos en la ética del ``ábrelo y mira cómo funciona''. El ideólogo del proyecto, David Braven, un antiguo desarrollador de videojuegos, afirma que su objetivo es que los niños puedan llegar a entender el funcionamiento básico del ordenador de forma divertida, y sean ellos mismos los que desarrollen y amplíen sus dispositivos. El co-fundador de la fundación es Eben Upton, un antiguo trabajador de la empresa Broadcom, el cual es el responsable de la arquitectura de software y hardware de la raspberry pi.

Eben Upton, se puso en contacto con un grupo de profesores, académicos y entusiastas de la informática para crear un ordenador con la intención de animar a los niños a aprender informática como lo hizo en 1981 el ordenador Acorn BBC Micro.

La fundación da soporte para las descargas de las distribuciones para arquitectura ARM, Raspbian (derivada de Debian), RISC OS y Arch Linux; y promueve principalmente el aprendizaje del lenguaje de programación Python, y otros lenguajes como Tiny BASIC, C y Perl.

El primer prototipo basado en ARM fue montado en un paquete del mismo tamaño que una memoria USB. Tenía un puerto USB en un extremo y un puerto HDMI en el otro.

En agosto de 2011, se fabricaron cincuenta placas Alpha del modelo inicial, el Model A (o modelo A). En diciembre de 2011, 25 placas Beta del modelo B fueron ensambladas y probadas de un total de 100 placas vacías.

Durante la primera semana de diciembre de 2011, se pusieron a subasta diez placas en eBay. Debido al anticipado anuncio de puesta a la venta a final de febrero de 2012, la fundación sufrió colapso en sus servidores web debido a los refrescos de páginas desde los navegadores de gente interesada en la compra de la placa.

El primer lote de 10.000 placas se fabricó en Taiwán y China, en vez de Reino Unido, con esto se conseguía un abaratamiento en los costes de producción y acortar el plazo de entrega del producto, ya que, los fabricantes chinos ofrecían un plazo de entrega de 4 semanas y en el Reino Unido de 12. Con este ahorro conseguido, la fundación podía invertir más dinero en investigación y desarrollo.

Las primeras ventas comenzaron el 29 de febrero de 2012 (Modelo B). Las dos tiendas que vendían las placas, Premier Farnell y RS Components, tuvieron una gran carga en sus servidores inmediatamente después del lanzamiento. En los seis meses siguientes llegarían a vender  500.000 unidades.

El 16 de abril de 2012 los primeros compradores empezaron a informar que habían recibido su Raspberry Pi. El 22 de mayo de 2012 más de 20.000 unidades habían sido enviadas.

El 6 de septiembre se anunció que se llevaría la producción de placas al Reino Unido, a una fábrica de Sony y que en ella se producirían 30.000 unidades cada mes, y se crearían 30 nuevos puestos de trabajo.

El 4 de febrero de 2013, se lanzó el modelo A, que venía con solo 256Mb de RAM y sin puerto ethernet a un precio más asequible que el modelo B.

En diciembre de 2015 se pueden comprar modelos con mejores prestaciones; Raspberry Pi 2 Model B - Placa base (ARM Quad-Core 900 MHz, 1 GB RAM, 4 x USB, HDMI, RJ-45) de Raspberry Pi, manteniendo el precio de la Raspberry original.


En febrero de 2016 sale a la venta un nuevo modelo, la versión 3 con las siguientes características: ARM Quad-Core 1,2 GHz, 1 GB RAM, 4 x USB, HDMI, RJ-45 y una conectividad inalámbrica integrada de 802.11 b/g/n LAN y Bluetooth, se continua manteniendo el precio original.

\subsubsection{Hardware}
El modelo A solo tiene un puerto USB, carece de controlador Ethernet y cuesta menos que el modelo B, el cual tiene dos puertos USB y controlador Ethernet 10/100. En 2014 se lanzó el modelo Raspberry Pi 2 B. El modelo lanzado en 2015 es el Raspberry Pi Zero. Y en 2016 se ha lanzado el modelo Raspberry Pi 3 B.


A pesar que el Modelo A no tiene un puerto RJ45, se puede conectar a una red usando un adaptador USB-Ethernet suministrado por el usuario. Por otro lado, a ambos modelos se puede conectar un adaptador Wi-Fi por USB, para tener acceso a redes inalámbricas o internet. El sistema cuenta con 256 MB de memoria RAM en su modelo A, y con 512 MB de memoria RAM en su modelo B. Como es típico en los ordenadores modernos, se pueden usar teclados y ratones con conexión USB compatible con Raspberry Pi.

El Raspberry Pi no viene con reloj en tiempo real, por lo que el sistema operativo debe usar un servidor de hora en red, o pedir al usuario la hora en el momento de arrancar el ordenador. Sin embargo se podría añadir un reloj en tiempo real (como el DS1307) con una batería mediante el uso de la interfaz I2C.


La aceleración por hardware para la codificación de vídeo (H.264) se hizo disponible el 24 de agosto de 2012, cuando se informó que la licencia permitiría su uso gratuitamente; antes se pensó en anunciarlo cuando se lanzara el módulo de cámara.También se puso a la venta la capacidad para poder usar el codificación-decodificación de MPEG-2 y Microsoft VC-1. Por otro lado, se hizo saber que el ordenador soportaría CEC, permitiendo que pudiera ser controlado mediante un mando a distancia de televisión.

El 5 de septiembre de 2012, se anunció una revisión 2.0 de la placa, que ofrecía un pequeño número de correcciones y mejoras, como unos agujeros de montaje, un circuito para hacer reset, soporte para depuración JTAG, etc.

El 15 de octubre de 2012, la fundación anunció que todos los Raspberry Pi Modelo B serían enviados a partir de ese momento con 512 MB de RAM en vez de 256 MB.

El ``system on a chip'' (SoC) usado en la primera generación de la Raspberry Pi es equivalente más o menos a los chips usados en los smartphones viejos (como el iPhone, 3G, 3GS). La Raspberry Pi esta basada en el SoC de Broadcom BCM2835 , que incluye un procesador ARM1176JZF-S a  700 MHz, una cpu gráfica VideoCore IV (GPU), y RAM. 

La Raspberry Pi 2 tiene un Broadcom BCM2836 SoC  con un procesador quad-core ARM Cortex-A7 a 900 MHz de 32-bit, con 256 KB de cache L2  compartida .

La Raspberry Pi 3 tiene un Broadcom BCM2837 SoC  con un procesador quad-core ARM Cortex-A7 a 1.2 GHz de 64-bit, con 512 KB de cache L2  compartida .

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.5]{Imagenes/Raspberry_Pi_3_Model_B.png}
% Ponemos Leyenda al gráfico
\caption{Raspberry Pi 3 B}
\label{Raspberry Pi 3 B}
\end{center}
\end{figure}

\subsubsection{Software}
El Raspberry Pi usa mayoritariamente sistemas operativos basados en el núcleo Linux. Raspbian, una distribución derivada de Debian que está optimizada para el hardware de Raspberry Pi, se lanzó durante julio de 2012 y es la distribución recomendada por la fundación para iniciarse.

A la GPU se accede mediante una imagen del firmware de código cerrado, llamado blob binario, que se carga dentro de la GPU al arrancar desde la tarjeta SD. El blob binario está asociado a los drivers Linux que también son de código cerrado. Las aplicaciones hacen llamadas a las librerías de tiempo de ejecución que son de código abierto, y estas librerías hacen llamadas a unos drivers de código abierto en el kernel de Linux. La API del driver del kernel es específica para estas librerías. Las aplicaciones que usan vídeo hacen uso de OpenMAX, las aplicaciones 3D usan OpenGL ES y las aplicaciones 2D usan OpenVG; OpenGL ES y OpenVG hacen uso de EGL y éste último, del driver de código abierto del kernel.

El 24 de octubre de 2012, Alex Bradbury, director de desarrollo Linux de la fundación, anunció que todo el código del driver de la GPU Videocore que se ejecuta en ARM sería de código abierto, mediante licencia BSD modificada de 3 cláusulas. El código fuente está disponible en un repositorio de la fundación en GitHub.

El 5 de noviembre de 2012, Eben Upton anunció el lanzamiento del sistema operativo RISC OS 5 para Raspberry Pi a la comunidad, pudiéndose descargar la imagen de forma gratuita desde la web de la fundación. Su relación con la comunidad RISC OS se remontaba a julio de 2011, cuando habló en ella de una hipotética versión.

El 24 de noviembre de 2012, se anunció en la Minecon de París, el juego Minecraft: Pi Edition para Raspberry Pi, basado en la versión Minecraft: Pocket Edition para teléfonos inteligentes y tabletas.La descarga se hizo disponible de forma oficial y gratuita por primera vez el 12 de febrero de 2013 desde el blog del juego, como versión 0.1.1 alpha, junto a instrucciones para ejecutarlo en Raspbian Wheezy. Una de las características principales de este lanzamiento es poder interaccionar con el juego mediante programación, con la intención de motivar a los niños a aprender a programar.

El 25 de mayo de 2013, la fundación informó de que se estaba trabajando en una versión del servidor gráfico Wayland para Raspberry Pi, para sustituir al sistema de ventanas X. Con este cambio se lograría suavidad al usar la interfaz gráfica del escritorio, ya que el procesamiento lo realizaría la GPU Videocore y no la CPU, sin interferir en el renderizado 3D.

El 3 de junio de 2013, fue lanzado en la web de la fundación para su descarga la aplicación NOOBS (New Out of Box Software), utilidad que facilita la instalación de diferentes sistemas operativos para Raspberry Pi. Se distribuye en forma de archivo zip que se copia descomprimido a una tarjeta SD de 4 GB o superior, y una vez arrancada la placa con la tarjeta por primera vez, aparece un menú en que se da la opción de instalar una de las diferentes distribuciones en el espacio libre de la tarjeta de memoria, o acceder a internet con el navegador Arora integrado. 

El 26 de septiembre de 2013, se añadió a los repositorios de Raspbian una versión oficial de Oracle Java JDK ARM con soporte para coma flotante por hardware, que ofrece bastante más rendimiento que la versión OpenJDK ARM ya existente hasta ese momento y más compatibilidad con aplicaciones. También se anunció que esta versión de Oracle Java JDK se incluiría dentro de la distribución en futuras versiones de Raspbian.


\subsubsection{Accesorios}
\paragraph{Cámara}

 El 14 de mayo de 2013, la fundación y los distribuidores RS Components \& Premier Farnell/Element 14 lanzaron la cámara para la Raspberry Pi con una actualización del firmware para que funcionara. 
Se conecta al puerto CSI de la placa mediante un cable plano flexible. El precio es de unos 20\euro{}, puede capturar video a 1080p, 720p y 640x480p. Sus dimensiones son de 25 mm x 20 mm x 9 mm.
\paragraph{Gertboard}

Este accesorio aunque no es de la fundación, ha tenido el visto de bueno de ellos, diseña con propósitos para la educación, expande los GPIO para poder interactuar con LED's, switches, señales analógicas, sensores y otros dispositivos. También incluye un controlador opcional para Arduino para poder interaccionar con el Raspberry Pi.
 
\paragraph{Cámara de infrarojos}
A finales de octubre de 2013 se puso a la venta un módulo de cámara de infrarrojos, llamada la Pi NoIR.

\paragraph{HAT}

HAT (Hardware Attached on Top) , placas de expansión, junto al modelo B+, inspiradas en las placas de expansión del Arduino, el interface para las HAT fue definido por la fundación Raspberry Pi. Cada HAT tiene que tener una pequeña EEPROM( suelen llevar la CAT24C32WI-GT3) conteniendo los detalles importantes de la placa, de tal manera que el sistema operativo de la Raspberry Pi tiene el conocimiento del HAT, y de sus aspectos tecnicos importantes para el sistema operativo de como interactuar con el HAT.Las especificaciones mecanicas de un HAT, es que tiene que usar los cuatro agujeros en su formación rectangular.

De esta manera la fundación dejo como se podía ir ampliando el proyecto Raspberry.



Aunque hay muchas placas para expandir la Raspberry vamos a comentar brevemente tres que vemos muy interesante para este proyecto.

\paragraph{DAC}
Recordar que no es lo mismo cuando se pasa el sonido por el HDMI que si se conecta unos altavoces directamente a la Raspberry.

Mucha gente se quejaba de que el sonido no era de gran calidad cuando era la Raspberry la encargada de procesar el sonido para ello salieron varios HATs para que la Raspberry pudiera procesar sonido de alta calidad.

Estas soluciones suelen ser mejores que poner una tarjeta de sonido por USB ya que además de estar seguros que funcionara en la Raspberry, suelen emplear el protocolo I2S para reducir el uso de la CPU.

\paragraph{PianoHAT}

Aquí tenemos un HAT que integra 13 teclas en la disposición de un piano de una octava completa. Y 3 teclas más para modificar este piano.

Juntando esta HAT con una Raspberry se puede tocar el piano en la misma Raspberry. 

También usando Python se puede hacer que el este HAT saque comandos MIDI a través del USB y conectarlo a cualquier sintentizador. 

Todo abierto y documentado para modificarlo como uno quiera.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.5]{Imagenes/Piano_HAT.jpg}
% Ponemos Leyenda al gráfico
\caption{Piano HAT}
\label{Piano HAT}
\end{center}
\end{figure}



\paragraph{DrumHAT}

Basado en el éxito del PianoHat se decidieron a hacer lo mismo pero con una batería en vez de un piano de esta manera nació el DrumHAT.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=0.5]{Imagenes/Drum_HAT.jpg}
% Ponemos Leyenda al gráfico
\caption{Drum HAT}
\label{Drum HAT}
\end{center}
\end{figure}


\subsubsection{Comunidad}

La comunidad de Raspberry Pi fue descrita por Jamie Ayre de la compañía AdaCore ligada a FLOSS como una de las partes más excitantes del proyecto. El blogger de la comunidad Russell Davis, dijo que gracias a la fuerza de la comunidad, la fundación puede concentrarse en la documentación y la enseñanza.

Una serie de eventos llamados Raspberry Jam, dirigidos por Alan O’Donohoe han sido organizados en el Reino Unido, y en otras partes del mundo, para involucrar a la gente con la comunidad.

Desde mayo de 2012 es publicada mensualmente una revista gratuita llamada MagPi, que se dedica divulgar información acerca del Raspberry Pi, e incluye proyectos que se pueden desarrollar con él y cursos de programación de diferentes lenguajes. Es publicada mediante licencia Creative Commons BY-SA-NC.

El 2 de agosto de 2012, se añadió al foro oficial de la fundación los subforos en español, portugués y alemán (el de francés ya llevaba tiempo creado).

El 17 de diciembre de 2012, junto a la versión 2012-12-16-wheezy-raspbian de Raspbian, se lanzó la tienda de aplicaciones ``Pi Store'', que en el momento de salida incluía desde aplicaciones como LibreOffice o Asterisk a juegos como Freeciv o OpenTTD. En esta plataforma se puede poner a disposición de todos los usuarios de Raspbian, mediante moderación y posterior lanzamiento, contenidos gratuitos o de pago, como archivos binarios, código python, imágenes, audio o vídeo. Además se quiere incluir documentación acerca del Raspberry Pi como la revista MagPi y tutoriales de proyectos.

\subsubsection{Recepción e influencia}

El escritor sobre tecnología, Glyn Moody, describió el proyecto en mayo de 2011 como un ``potencial BBC Micro 2.0'', no para reemplazar a los ordenadores personales sino como algo suplementario. Alex Hope, coautor de Next Gen Report, sentía esperanzas de que el Raspberry Pi animaría a los niños a aprender a programar, en vez de a usar aplicaciones ya creadas. El coautor Ian Livingstone sugirió que la BBC podría involucrarse en el proyecto, con la posibilidad de hacerlo llamar ``BBC Nano''. Chris Williams que escribe en The Register, ve la inclusión de lenguajes de programación como Kids Ruby, Scratch y Basic como un ``buen comienzo'' para dar a los niños habilidades que necesitarán en el futuro, pero que habrá que ver cómo de efectivo será su uso. El Centro de la historia de la computación da un fuerte apoyo al proyecto y sugiere que podría ``marcar el comienzo de una nueva era''. Antes del lanzamiento del Raspberry Pi, la placa fue mostrada por el CEO de ARM, Warren East, en un evento en Cambridge, haciendo referencia a la filosofía de Google de mejorar la enseñanza de ciencias y tecnología de la computación en el Reino Unido.

Harry Fairhead sugiere que se tendría que dar más énfasis en mejorar el software educacional en el hardware actual, usando herramientas como Google App Inventor, para volver a enseñar programación en las escuelas, en vez de sacar nuevos sistemas. 


En octubre de 2012 el Raspberry Pi ganó el premio T3 ``Innovación del año''.

\subsubsection{SonicPi}

Aunque el formato MIDI es el más usado por los músicos me gustaría añadir un pequeño aporte, a nuevas formas de crear, editar y escuchar música en entornos libres.

Se ha creado el lenguaje musical SonicPi en el cual es más parecido a programar que a enfrentarse a una partitura clásica. El proyecto Raspberry Pi lo ha cogido como una de sus ramas para que los jóvenes aprendan música y por esto creo que merece un pequeño punto en este proyecto.


\subsubsection{Usos}

En enero de 2012, encuestas hechas en el Reino Unido acerca de la penetración en las aulas de Raspberry Pi concluyeron que por cada placa que había en un colegio público, había cinco en colegios privados. Por ello se espera que en un futuro empresas patrocinen la adquisición de placas en colegios públicos.

El CEO de Premier Farnell declaró que el gobierno de un país de medio oriente expresó interés en proveer una placa a cada chica estudiante, con el objetivo de mejorar sus expectativas de empleo en el futuro.

A finales de enero de 2013, se dio a conocer que Google, junto con la ayuda de otros 6 socios, repartiría 15.000 placas entre estudiantes del Reino Unido que mostraran motivación por las ciencias de la computación.


Visto todo esto vemos ahora podemos definir el proyecto en mejores condiciones.

\chapter{Proyecto de canciones DTXMANIA entorno libre}
\section{Idea Inicial}

La idea es hacer un reproductor de canciones del DTXMANIA, DTXMANIA HD y GITADORA pero en entornos libres, para ello se ha decidido usar la Raspberry pi 3 como principal plataforma arm con la distribución Raspbian y también la plataforma x86-64 con la distribución Fedora.

Para que el proyecto tenga más interés para los baterías reales este proyecto deberá mantener algunas de las principales características del DTXMANIA original, como poner conectar Baterías-MIDI y poder tocar con ellas.

Se podrá usar en arquitecturas x86 y arm, por lo que no deberíamos usar características especificas de una plataforma.

También se hará compatible con el Drum HAT de Pimoroni , para poder tener todo el proyecto conservando la filosofía de educación de la Raspberry pi.

De esta manera se alcanzaran varios objetivos.
\begin{itemize}
\item Con un precio reducido probar si el tocar la batería te gusta.
\item Dar una posibilidad a los baterías a usar estas en entornos abiertos, como simulación/juego.
\item Conseguir que la comunidad de los entornos libres continué creciendo.
\end{itemize}

El reproductor de DTXMANIA debería conservas algunas de sus principales características.


Muy importantes:
\begin{itemize}
  \item Poder conectar baterías-MIDI y configurando el reproductor usarlas.
  \item Poder configurar la sincronización de las notas.
  \item Poder configurar aspectos del reproductor para poder poner en automático algunas pistas por si la batería-MIDI no tuviera suficientes pads o por si no queremos tocar esa parte.
\end{itemize}

Importantes:
\begin{itemize}
  \item Tener temas de interfaz, por si el interfaz por defecto no gusta.
  \item Si una canción tiene varias dificultades poder escoger que dificultad sonara.
  \item Tener una puntuación para saber lo bien o mal que se ha tocado.
  \item Se tiene que poder modificar el uso del reproductor de tal manera que si nuestra batería-MIDI tiene muchos pads y pedales se tiene que poder dejar de tal manera que el reproductor nos obligue a tocar como si estuviéramos en una batería acústica.
\end{itemize}

Se tendrá que ver hasta que punto la Raspberry puede con toda la carga y en alta calidad de algunas canciones del DTXManiaHD.

\subsubsection{Entorno de desarrollo}
Pasamos a definir que entorno de desarrollo emplearemos para el proyecto.

\subsubsection{Parte física}
Como componentes físicos para poder probar que el proyecto es funcional, se tendrá que ver que es funcional en varias máquinas.
 
Para el proyecto se emplearan una Raspberry 3, como principal plataforma arm.

También el proyecto se probara sobre una distribución Fedora en arquitectura x86-64.

Se tendrá un drumHAT para extender la capacidad de las Raspberry y de esta manera tener una batería sin pedales en la Raspberry que se puede tocar con los dedos.

Como batería-MIDI se usara la Roland HD-1.

\subsubsection{Python3}

Se escoge Python3 como lenguaje para programar este proyecto y exponemos las ventajas y desventajas que nos aportara.

Es el principal lenguaje recomendado y apoyado por la fundación de Raspberry por su simplicidad, por lo que si lo escogemos continuaremos expandiendo la comunidad.

Como es un lenguaje interpretado, ya funcionara en plataformas x86 y arm entre otras sin tener que estar compilando para esa plataforma en concreto.

Como es interpretado en general sera más lento que si compilaramos para la plataforma en cuestión, como ademas la Raspberry no es que tenga mucha capacidad de procesador, se tendrá que ver que nivel de latencia tenemos entre pulsar un pad de la batería-MIDI y ver cuando lo detectamos y también ver a que nivel de sincronización podemos llegar a detectar entre cuando se tiene que tocar una nota y cuando se ha tocado realmente.

Recordar que python3 no es un lenguaje paralelo aunque tiene algunas librerías para poder ejecutar código en paralelo. Por lo que como la Raspberry modelo 2 y 3 ya tiene cuatro cores, seria interesante ya intentar integrar el paralelismo en parte del código para mejorar latencias y sincronismos.


Recordar que hay implementaciones alternativas de Python3 para que sea código compilado para la plataforma en concreta (JIT), por lo que estaría bien programar todo el código de tal manera que se pudiera usar tanto el interprete de Python3 como estas implementaciones, la más famosa de ellas es PyPy.


\subsubsection{Ninja-IDE}
Como IDE se usara el Ninja-IDE ya que nos ofrecerá una gran ventaja que se integrara con la Guiá de estilo python que emplearemos, esta guía esta como apéndice.

De esta manera mientras vamos escribiendo el código, mostrara como warnings si no cumplimos un PEP de python (buenas maneras en el código).


\subsection{Comparaciones funcionales Stepmania/DTXMania}

Como hemos observado que el pydance puede funcionar en una Raspberry cogeremos parte como base para nuestro proyecto, para ello compararemos primero las diferencias y las similitudes que podremos emplear, primero comparando los juegos originales, para luego comparar las versiones de ordenador.


\subsubsection{DDR/Drummania}
\paragraph{Similitudes generales en los dos juegos}
Como se ha comentado los dos juegos son juegos musicales donde en cada nota se mira la sincronización para dar una puntuación. Mientras esta sincronización continué bastante alta no hay problemas si baja mucho el juego te devuelve a la pantalla principal.

En los dos juegos buscaron una manera fácil de poner una dificultad a las canciones, en DDR se uso la idea de indicar los BPM (Beats per minute) e indicar además una dificultad en con un valor numérico del 1 al 100, en Drummania se indico la dificultad de la canción con un valor numérico también del 1 al 100.

En los dos juegos puede haber videos.

\paragraph{Diferencias en los dos juegos}
En DDR como se ha observado hay 4 \gls{Lanes} mientras que en la versión más básica del Drummania ya salio con 6 \gls{Lanes}.

En versiones avanzadas del Drummania (Gitadora) recordar que hay \gls{Lanes} que pueden ser dobles, el hihat es el mejor ejemplo ya que se tiene que tocar o cerrado o abierto, para no tener otro lane se muestra en el mismo (ya que nunca se toca el hihat al mismo tiempo cerrado y abierto).

El DDR se puede juntar a otras maquinas DDR de la misma versión para poder jugar 2 personas al mismo tiempo o un modo especial de 1 jugador bailando en las 2 máquinas.

El Gitadora en cambio se puede juntar con los GuitarFreaks para tocar varias personas al mismo tiempo una canción.

El DDR por ser un juego de baile tiene sentido tener que estar manteniendo los pies en alguna posición en concreto, cosa que en una batería no tiene sentido mantener alguna baqueta en contacto con el pad.

En el DDR no suena nada cuando se esta bailando bien, mientras que en el Drummania cuando se toca se escucha la batería y cuando no se toca solo se escucha el resto de la música.

\subsubsection{StepMania/DTXMania}
En las versiones libres como ya son simuladores de los juegos originales tienen otras similitudes que las pasaremos a comentar a continuación.

En las versiones libres para que sea más fácil su aprendizaje hay una opción para ignorar la barra de vida y de esta manera poder practicar las canciónes, también para poder aprender alguna canción existe la opción de modificar la velocidad de la canción (no es lo mismo que la sincronización).

En los dos juegos hay opción de modificar toda la interfaz mediante temas.

También se puso el detalle de tener canciones con varios niveles de dificultad, que es la misma música pero una mayor complejidad para tocarla, ejemplo fácil para entenderlo es que modo fácil es tocar un ritmo con 4 \gls{Lanes} y ya  poder ``pasarte'' la canción pero en un nivel de dificultad mayor tener que usar los 7 \gls{Lanes} al completo. 


\subsection{pydance}
Ahora detallaremos de la implementación libre del DDR el pydance, para tenerla en cuenta como base en nuestro proyecto. Ya que esta implementada de tal manera que funciona directamente en la Raspberry.

\url{https://icculus.org/pyddr/index.php}

Ya en la página oficial del proyecto indica que se ha realizado con python, Pygame , libsdl y Vorbis.

Explicaremos brevemente las tres librerías que acabamos de nombrar:

\subsubsection{Pygame}

Pygame es un conjunto de módulos del lenguaje Python que permiten la creación de videojuegos en dos dimensiones de una manera sencilla. Está orientado al manejo de sprites.

Gracias al lenguaje, se puede prototipar y desarrollar rápidamente. Esto se puede comprobar en las competiciones que se disputan online, donde es cada vez más usado. Los resultados pueden llegar a ser profesionales.

También puede utilizarse para crear otros programas multimedia o interfaces gráficas de usuario.
Se basa en las librerías libsdl.


\subsubsection{libsdl} 

Simple DirectMedia Layer (SDL) es un conjunto de bibliotecas desarrolladas en el lenguaje de programación C que proporcionan funciones básicas para realizar operaciones de dibujo en dos dimensiones, gestión de efectos de sonido y música, además de carga y gestión de imágenes. Fueron desarrolladas inicialmente por Sam Lantinga, un desarrollador de videojuegos para la plataforma GNU/Linux.

Pese a estar programado en C, tiene wrappers a otros lenguajes de programación como C++, Ada, C\#, BASIC, Erlang, Lua, Java, Python, etc. También proporciona herramientas para el desarrollo de videojuegos y aplicaciones multimedia. Una de sus grandes virtudes es el tratarse de una biblioteca multiplataforma, siendo compatible oficialmente con los sistemas Microsoft Windows, GNU/Linux, Mac OS y QNX, además de otras arquitecturas y sistemas como Sega Dreamcast, GP32, GP2X, etc.

La biblioteca se distribuye bajo la licencia LGPL, que es la que ha provocado el gran avance y evolución de SDL.

Aunque a partir de la versión 2.0 esta librería se encuentra bajo la Licencia ZLib

\subsubsection{Ogg Vorbis} Ogg vorbis forma parte del proyecto Ogg y fue llamado Ogg Vorbis o tan sólo ogg por ser el códec más comúnmente encontrado en el contenedor Ogg.

Vorbis es un códec de audio perceptivo de fines generales previsto para permitir flexibilidad máxima del codificador, permitiéndole escalar competitivamente sobre una gama excepcionalmente amplia de bitrates.

Aun cuando el algoritmo de compresión con pérdida produce una menor cantidad de información, es un procedimiento de codificación que tiene como objetivo eliminar una cierta cantidad de información considerada como irrelevante para disminuir el volumen de datos. Esta idea fue utilizada anteriormente por ejemplo en la compresión de mp3.

En la escala de nivel de calidad/bitrate (CD audio o DAT-rate estéreo, 16/24 bits) se encuentra en la misma liga que MPEG-2 y Musepack (MPC) y comparable con AAC en la mayoría de bitrates. Similarmente, el codificador 1.0 puede codificar niveles de calidad desde CD audio y DAT-rate estéreo hasta 48kbps sin bajar la frecuencia de muestreo. Vorbis también está pensado para frecuencias de muestreo bajas desde telefonía de 8kHz y hasta alta definición de 192kHz, y una gama de representaciones de canales (monoaural, polifónico, estéreo, cuadrafónico, 5.1, ambisónico o hasta 255 canales discretos).

Ogg Vorbis es totalmente abierto y libre de patentes; la biblioteca de referencia (libVorbis) se distribuye bajo una licencia tipo BSD por lo que cualquiera puede implementarlo ya sea tanto para aplicaciones propietarias como libres. Aplicaciones de streaming audio como Spotify utilizan el formato Ogg en versión premium.


\subsubsection{Código de pydance}

También observamos cosa que esta muy bien que puede coger varios formatos ya que son muy parecidos, 3 \gls{Lanes} (DDR Solo beginner), 4 \gls{Lanes} (DDR), 5 \gls{Lanes} (Pump It Up), 6 \gls{Lanes} (DDR Solo), 8 \gls{Lanes} (Technomotion), 9 \gls{Lanes}, Dance ManiaX, EZ2 Dancer, EZ2 Real, y Parapara-style

Por lo que estaría muy bien poder hacer lo mismo en nuestro proyecto, y coger los cuatro grandes estilos de juegos musicales para una batería-MIDI, el DTXMania y el DTXManiaHD como principales y si se puede intentar soportar el Rockband y Rockband Pro. Se habría ganado muchos enteros, el detalle sera cambiar el estilo del Rockband que esta orientado hacia un juego, hacia el estilo del DTXMania que es un simulador.

Si miramos las versiones que emplea son Python 2.4 y Pygame 1.8.1 , por lo que esta empleando las versiones de libSDl y de Ogg que estaban enlazadas en ese momentos con esas librerías.

Actualmente estamos en la versión Python 2.7.11 (2015-12-05) y las versiones de Python 3 son Python Python 3.4.4 (2015-12-21) y 3.5.1 (2015-12-07) considerándose la versión beta.

Se aconseja ya no programar en Python 2 a no ser que se tenga mucho código en él.

Mientas que pygame a continuado avanzando y esta en la versión 1.9.2

En su manual \url{https://icculus.org/pyddr/manual.php} indica cosas que el pydance no puede hacer por lo que las tendremos que tener en cuenta, solo exponemos las generales que nos pueden afectar, no diremos ninguna en referencia a los juegos DDR.

\begin{itemize}
  \item Reproducir MP3, indican que algunos se pueden reproducir pero otros dan fallos, aconsejan pasar estos a .ogg o a .wav.
  \item Algunos videos no funcionan.
\end{itemize}

Como podemos observar son fallos fácilmente derivados de DRM.

Otro detalle muy interesante del manual es que indica los archivos que puede reproducir e indica que se ha creado un formato que no tendrá problemas.

\subsection{DTXMania}
Ahora nos fijaremos en el DTXMania y DTXManiaHD su uso y configuración, para tenerlo en cuenta en nuestro proyecto.

\subsubsection{Configuraciones} 
Un detalle que ya hemos ido comentado es que el DTXMania aunque salio al inicio para las baterías Yamaha de la serie DTX, ya que su programador tenia una de ellas, la gente fue pidiendo para que cogiera baterías-MIDI en general y que no implementara detalles de las Yamaha.

Para ello se tuvo que dar la opción de poder configurar cada \gls{Lanes} con una señal MIDI.

Con esto se consiguió que las baterías-MIDI con suficientes \gls{Pads}, pudieran jugar al DTXMania.

Una opción que se implemento en los inicios fue que su pudiera tocar independiente de la barra de vida para convertirlo en un ``medidor'' de lo bien o mal que se tocaba una canción, justo con esto se añadió la opción de tener que tocar la canción exactamente como estaba escrita en el archivo o dejar la libertad de poder tocar cualquier \gls{Pads} y que no fuera considerado un fallo.

Una opción interesante que añadió el programador del DTXMania, fue como su batería-MIDI en el hihat tenia la opción de dar dos señales, según tuviera pulsado el pie izquierdo, añadió la opción de que en algunos \gls{Lanes} se pudieran poner dos señales distintas, para ello el .dtx tenia que definir por separado esos dos sonidos diferentes, esto que a los baterías les gusto mucho ya que les obligaba a tocar como se hace en una batería acústica, a la gente que jugaba con las baterías del Rockband no les gusto ya no tenían esa posibilidad para ello el programador del DTXMania dio la posibilidad de configurar estos \gls{Lanes} ``dobles'' con la misma señal, de esta manera sí tu batería era más simple se podía continuar jugando y la única diferencia es que visualmente la nota que bajaba era distinta y cuando pulsabas sonaba también distinto.

Poco a poco la gente con baterías-MIDI más profesionales fue viendo que esto casi era lo que estaban buscando pero tenían un problema principal, como sus baterías-MIDI tenían muchos \gls{Pads} y algunos con varias señales integradas en un mismo pad, cuando configuraban el DTXMania para poder usarlo con una canción, les molestaba mucho que aunque ellos sabían que tenían que tocar un pad, el DTXMania les obligaba a tocar solo una zona, ya que si tocaba la otra zona el DTXMania se lo ponía a fallo, para ello se tuvo que dar la opción de poder tocar varias señales para un lane, de esta manera ellos si conocían la canción y tenían más \gls{Pads} podían configurar varios de ellos y tocarlo exactamente igual que con una batería acústica.


A partir de estos primeros años los ``grandes'' añadidos fue ir añadiendo \gls{Lanes} pero de tal manera que se podía configurar para juntarlos en un lane y dejarlo como en las versiones más antiguas de esta manera se tenia contento a los baterías y a los jugadores con sus controles básicos.

Cuando llego por fin el DTXManiaHD además de actualizar las resoluciones empleadas, aquí se rompió un poco la compatibilidad hacia atrás por lo siguiente, el DTXManiaHD emulaba la máquina DrumManiaXG y como cambiaron el mueble físico de la máquina ya por definición se paso a 9 \gls{Lanes}, pero hay un pequeño conflicto, se pusieron dos pedales, por el derecho no hay problema ya que siempre es el bombo, pero el izquierdo dependiendo de la canción cumple la función de abrir o cerrar el hihat o de doble bombo.

En el DTXMania original como no tenia posibilidad de doble bombo lo que se hizo fue con la posibilidad de poner varias señales en la misma lane, la gente configuraba el doble bombo en la lane correspondiente, cierto es que no obligaba a usar los pasos correctos mientras se marcaran en el momento correcto, no le importaba que señal le venia. No es lo mismo Derecha-Derecha-Izquierda que Izquierda-Derecha-Derecha. Ahora en el DTXManiaHD si que se codifica que pie se tiene que usar.

El problema esta cuando se coge un archivo codificado del DTXMania en el DTXManiaHD, las bases son las mismas pero puede existir el siguiente problema.

Si es una canción con bombo simple no hay problema el DTXManiaHD la pone en el pedal derecho y el resto de los \gls{Lanes} donde correspondan.
 Pero si es una canción con doble bombo, las opciones que existen serian:
  Duplicar el lane y ponerlo tanto en el izquierdo como en el derecho, ya que no podemos saber en que lane exacta debería ir, pero no podemos dejar el modo exacto ya que a no ser que diéramos a los dos pedales al mismo tiempo, siempre se detectaría un fallo.
  
  Poner el lane del bombo como esta codificado y configurar el lane del pedal derecho con dos señales tanto la del pedal izquierdo como la del derecho, aquí salta otro problema se acaba de duplicar la entrada del pedal izquierdo  por lo que cuando se toca el pedal izquierdo para abrir el hihat, también suena el pedal derecho, cosa que a un batería no le gusta ya que en una batería acústica no funciona de esta manera y también se pierde la opción del modo exacto, por que en algunas canciones se tocaría el pedal izquierdo y como no hay lane en esos momentos en el pedal derecho nos marcaría un fallo.
  
  La opción que tomo el programador fue comentarlo y continuar manteniendo dos programas, la idea era que la gente fuera pasando las codificaciones al DTXManiaHD.



\subsubsection{Menús fuera de la parte de tocar la batería}
Una vez configurada la batería-MIDI todos los menús estaban pensados de tal manera que con los pads se podía navegar por todo el programa.


Un detalle que gusto bastante a la hora de navegar por las canciones es que los usuarios metian las canciones en una carpeta especifica y ya el reproductor miraba recursivamente todas estas carpetas.

Para tener agrupadas las canciones se añadió la posibilidad de poner un pequeño fichero de configuración en las carpetas para modificar varias cosas tanto el nombre que salia en el menú, tener una imagen para esa carpeta, y ya una opción muy poco usada fue que se podía configurar toda una carpeta con opciones de sincronización propios que eran más prioritarios que la configuración del DTXMania, de esta manera era muy típico tener una carpeta con ritmos de practica con necesidad de tocarlos con un mayor sincronismo y luego ya poder tocar las canciones más tranquilo sin tener que estar modificando todo el tiempo las configuraciones.

\subsubsection{Menús en el juego}

Existía en el DTXMania la opción de poner todo el tema en negro, para aunque se quería tener unos menús coloridos, a la hora de tocar que toda esa interfaz gráfica no molestara a la hora de tocar la batería-MIDI, las tres opciones grandes eran menú completo, menú negro pero con video o menú negro sin video.

\section{Formatos a nivel básico de las canciones en juegos musicales}


\subsection{FoFiX / PhaseShift}

Ahora miraremos el formato que ha empleado FoFiX y el PhaseShift para sus canciones con parte de batería para ver tanto la dificultad de integrarlo en el proyecto como sus ventajas/desventajas.

Si cogemos una canción del FoFiX que tenga parte de batería observaremos que en su directorio hay varios archivos.

Los más importantes son el song.ini, el notes.mid los .ogg, primero miraremos el song.ini

\begin{Verbatim}[frame=single]
[song]
artist = Daisuke Ishiwatari
name = Holy Orders (Be Just or Be Dead)
album = Guilty Gear X (Heavy Rock Tracks)
delay = 0
year = 2001
diff_guitar = 5
diff_bass = 4
diff_guitar_coop = -1
diff_rhythm = -1
diff_drums = 4
diff_vocals = -1
diff_keys = 5
diff_bass_real = -1
diff_guitar_real = -1
diff_dance = -1
diff_bass_real_22 = -1
diff_guitar_real_22 = -1
diff_drums_real_ps = -1
diff_drums_real = 4
diff_vocals_harm = -1
diff_band = 4
multiplier_note = 116
pro_drums = True
genre = Metal
song_length = 191193
charter = GhostByob
banner_link_a = http://jcharting.wix.com/jrockband
link_name_a = J-Rock Band Project site
icon = jrb
\end{Verbatim}

Igual que en otros formatos vemos que en este formato hay un archivo donde indica la dificultad de la canción, en este caso para varios instrumentos, una duración de la canción y detalles como autor o titulo de la canción.

En el notes.mid esta la notación musical de esta canción  para que el programa la interprete en notas que tiene que pulsar el jugador, si miramos un poco más a fondo este .mid lo que han realizado es separar la canción en varias pistas que con sus nombres podemos deducir para que son, ejemplo:

\begin{itemize}
\item PART DRUMS - Notación para la batería.
\item PART BASS - Notación para el bajo.
\item PART GUITAR - Notación para la guitarra.
\item PART VOCALS - Notación para la voz.
\item EVENTS - Eventos asociados al juego.
\item BEAT - Ritmo que ha de marcar el juego, se podría entender como los BPM o puntos de sincronización para que todo suene en el mismo momento.
\end{itemize}


El song.ogg que es obligatorio es el archivo musical donde tiene que ir la voz, el teclado y los instrumentos que no están definidos como tocarlos en esta canción.

Para los demás disponemos de las siguientes posibilidades:


\begin{itemize}
\item guitar.ogg - La guitarra en la canción.
\item rhythm.ogg - El bajo en la canción
\item drums.ogg - La batería en la canción.
\item preview.ogg - Es la canción que se tocara en el menú de selección
\end{itemize}

Vemos que este formato ha usado el midi adaptándolo a las necesidades del juego, lo bueno es que se puede coger este midi ponerlo en un sintetizador y sonaría la canción, recordar que el midi ``no tiene voz humana'', en el sentido de que el midi se define en base a bancos de sonido e indicamos que banco ha de sonar y en que nota.

En este formato para simplificarlo no han definido los bancos de sonido de los instrumentos si no que usan estos .ogg, como se han incluido estos .ogg que sonaran todos (menos el preview) y el del instrumento que estamos tocando, lo único que ocurre cuando se falla la nota es que bajan el volumen momentáneamente del ogg de nuestro instrumento.


Pero el mayor problema es el siguiente, la batería tiene muchos \gls{Pads} por lo que no es raro tener que pulsar dos o tres \gls{Pads} al mismo tiempo, sí nos dejamos alguno sin tocar ese en particular no tendría que sonar, pero los demás si, como el sonido del instrumento se lo hemos indicado en un .ogg lo único que se hace es bajar momentáneamente el sonido de este .ogg pero bajamos el sonido de todo el instrumento.


Como ventajas indicar que es relativamente fácil pasar cualquier canción ya que solamente poniendo el .ogg de la canción y haciendo un midi con la notas de la batería ya lo tendríamos, si queremos hacerlo mejor tendríamos que tener dos .ogg uno para la canción sin la batería y otro para la batería de la canción.


\subsection{MIDI}

Hemos observado que es muy correcto coger el MIDI como formato de notación para nuestras canciones, aunque en esta parte tendremos que hacer un pequeño inciso.

El formato MIDI recordar que para que fuera un formato pequeño tanto en memoria usada como en cpu, lo habitual es que un instrumento solo tenga un sample de sonido y según la nota modificar ese sample mientras suena.

Recordar que MIDI a pasado varias implementaciones, en su primera especificación ya en el canal 10 que es donde esta asignada la batería o percusión, tiene 8 posibles voces las cuales son distintas no como otros instrumentos, por lo que tocar el bombo ya es diferente en sonido que tocar el hihat o el snare. Esta primera implementación ya dicta cuales son estos 8 sonidos, en un sintetizador clásico:

\begin{itemize}
\item 113 Tinkle Bell
\item 114 Agogo
\item 115 Steel Drums
\item 116 Woodblock
\item 117 Taiko Drum
\item 118 Melodic Tom
\item 119 Synth Drum
\item 120 Reverse Cymbal
\end{itemize}

Por lo que vemos que estos sonidos no son los típicos de una batería de rock con múltiples piezas, aunque si se modifica el sintetizador tanto se puede modificar los samples, como muchos otros detalles.

En la especificación ``General MIDI level 2'' en el canal 10 ya hay 128 voces disponibles.

Aquí es cuando vemos la problemática de usar el MIDI clásico para usarlo directamente en un simulador de una batería de 9 \gls{Lanes}.

El MIDI 1.0 se queda justo en sonidos, cogiendo el MIDI 2.0 tendríamos el siguiente problema, como hay 128 voces disponibles, quien haya creado la canción habrá usado la voz más cercana al instrumento que tiene que sonar, por lo que en nuestro simulador tendríamos varias opciones.

\begin{itemize}
\item Identificar solo 9 sonidos de estos 128 sonidos y asignarlos a nuestros lanes, y para que todo suene el resto de sonidos sintentizarlos vía MIDI, puede pasar que en la canción muchos sonidos los tendría que estar haciendo el batería y no sonando automáticamente.

\item Hacer una relación de estos 128 sonidos a 9 lanes, lo que nos pasaría ahora es que muchas veces coincidirían varios sonidos en el mismo lane y no sabríamos que sonido tendríamos que reproducir cuando se tocara el pad asociado(sobre todo cuando no hay nada en el lane)
\end{itemize}

Para ello como ya veremos más adelante el DTXMania implementa al mismo tiempo la parte de reproducción de un sintetizador y nos obliga a detallar parte de esta información en el formato.


\subsection{pyDance}
Cogiendo el formato especifico del pydance, que ya esta un poco saneado comparando con los del DDR clásicos, podremos ver algunas de las características de los formatos, en juegos musicales que ha realizado Konami.

Para ello ya en la página web hay canciones para bajar.


\url{https://icculus.org/pyddr/download.php}

Ya podemos ver que una canción esta separada en varios archivos.

Un .ogg que como hemos comentado sera la canción para que se escuche por los altavoces.

Dos ficheros de imágenes un Background y un Banner.

Y el fichero que más nos preocupa que es un fichero .dance.

Abriendo el fichero forkbomb.dance, que es el más sencillo, ya vemos que tiene un preámbulo donde indica datos de la canción:


\begin{Verbatim}[frame=single]
filename forkbomb.ogg
title Forkbomb 
subtitle pydance training song
artist Pajama Crisis
author P2E and piman
banner forkbomb-banner.png
background forkbomb-bg.jpg
cdtitle pydance.png
bpm 136.0
end
\end{Verbatim}

Donde vemos que se indica varios datos de la canción.

\begin{itemize}
\item filename - Donde pone el archivo musical de la canción.
\item title - Titulo de la canción.
\item subtitle - Subtitulo de la canción.
\item artist - Artista de la canción.
\item author - El autor de la canción en pydance.
\item banner - Imagen que se empleara en el menú de navegación de archivos.
\item background - Imagen que se empleara ya cuando se esta jugando como fondo de pantalla.
\item cdtitle - Imagen para el menú de navegación de archivos.
\item bpm - Beats per minute de la canción, muy importante ya que nos definirá lo rápido que va la canción, recordar que los bpm es una unidad empleada para medir el tempo en música. Equivale al número de pulsaciones que caben en un minuto.
\item end - Finaliza la zona del archivo para datos genéricos.
\end{itemize}


Ahora mostramos el principio de esta canción
\begin{Verbatim}[frame=single]
SINGLE
BEGINNER 0
R
D 8
L 7 Welcome to the pydance beginner tutorial.
L 6 (instructions will be here!)
D 6
L 7 See the platform under your feet?
D 6
L 7 When moving arrows cross over the ones at the top....
D 6
L 6 ....you hit corresponding arrows on the platform.
D 8
L 7 So, get ready to tap the left arrow..
D 3.75
L 7 ...Now!
D 0.25
h 1000
\end{Verbatim}


Quitamos toda la parte de avisos al jugador ya que en el DTXMania no existe y vemos que queda algo parecido a lo siguiente:

\begin{Verbatim}[frame=single]
SINGLE
BEGINNER 0
h 1000
o 0001
o 0110
q 1000
q 0001
q 1000
q 0001
q 1000
q 0001
q 0010
q 1000
q 0100
q 0001
q 0010
q 1000
q 0100
q 0010
q 0001
end
\end{Verbatim}

Hay algunos datos más de la canción pero más referidos a como esta escrita la canción, por lo que esto se puede entender como el nivel de dificultad.

Vemos que juntando los bpm y esta especie de partitura se comienza a entender lo que seria una versión simplificada del DTXMania.

\subsection{DTXMania}
Ahora para comenzar y antes de explicar todos los aspectos del formato DTXMania.

Haremos lo mismo con una canción simple sin aprovechar todos los detalles del formato, y luego ya cogeremos las especificaciones del formato en sí.

Usamos un .dtx que es una partitura para practicar ritmos simples y no una canción en sí, ponemos solo una parte del fichero, ya que luego pasaremos a las especificaciones completas del formato.

La idea inicial seria que indicando el tempo de la canción y poniendo una ``partitura'' en los lanes, ya se tendría lo que seria un canción del DTXMania básica.

Como antes ya vemos que se puede subdividir el fichero en dos grandes partes un preámbulo de datos y lo que seria la notación musical.

En la primera parte ya podemos observar dos cosas importantes:

\begin{Verbatim}[frame=single]
; Created by DTXCreator 019

#TITLE: Shuffle
#PANEL: Simple Shuffle
#BPM: 60.00
#DLEVEL: 45


#WAV01: bass_rock3.XA
#WAV02: snare_ambient.xa
#WAV03: snare_tap.xa	;Snare Tap
#WAV04: ride_rock.XA	;Ride - Hvy
#WAV05: ride_light.XA	;Ride - Light
#WAV06: count1.xa
#WAV07: count2.xa
\end{Verbatim}



\begin{itemize}
\item Con el punto y coma indicamos que son comentarios que el DTXMania ignora.
\item y si usamos la almohadilla es un comando para que el DTXMania lo interprete.
\end{itemize}

vemos que se define:


\begin{itemize}
\item ; Created by DTXCreator 019  - Indica el programa que se ha usado para crear esta ``partitura''
\item \#TITLE: Shuffle - Titulo de la canción
\item \#PANEL: Simple Shuffle - Subtitulo de la canción.
\item \#BPM: 60.00 - BeatsPerMinute de la canción
\item \#DLEVEL: 45 - Dificultad de la canción
\end{itemize}

Y otra parte donde define los sonidos que empleara en los lanes.


Vemos que va asignando archivos .xa, estos archivos para definir los de una manera rápida se puede decir que son archivos de sonido codificados en menor calidad, ya que están pensados para ser pequeños tanto en tiempo como en tamaño.


Aquí uno de los grandes problemas de este reproductor en entornos libres, este formato de sonido es un formato japones muy poco usado y casi sin documentación pero se ha mantenido desde los inicios del DTXMania, que se uso para que que no ocupara tanto los samples de los sonidos de la batería, recordar que el DTXMania original es de cerca de 1999, y tanto la memoria para poner samples de gran calidad en la RAM del ordenador como para luego bajar las canciones de Internet eran cuestiones a tener en cuenta.


Más adelante haremos una pequeña sección de como tratar este formato en entornos libres.

Y luego ya una parte de la notación musical:

\begin{Verbatim}[frame=single]
#00061: 06070707
#00113: 01010101
#00116: 040000040005040000040005
#00161: 06070707
#00112: 00020002
#00216: 040000040005040000040005
#00261: 06070707
#00213: 01010101
#00212: 00020002
#00316: 040000040005040000040005
#00361: 06070707
#00313: 01010101
#00312: 00020002
#00461: 06070707
#00416: 040000040005040000040005
#00413: 01010101
\end{Verbatim}

Para entenderla mejor vamos a separarla, por datos tal y como los interpreta el DTXMania

\begin{Verbatim}[frame=single]
#000 61: 06 07 07 07

#001 13: 01 01 01 01#001 16: 04 00 00 04 00 05 04 00 00 04 00 05
#001 61: 06 07 07 07
#001 12: 00 02 00 02

#002 16: 04 00 00 04 00 05 04 00 00 04 00 05
#002 61: 06 07 07 07
#002 13: 01 01 01 01
#002 12: 00 02 00 02

#003 16: 04 00 00 04 00 05 04 00 00 04 00 05
#003 61: 06 07 07 07
#003 13: 01 01 01 01
#003 12: 00 02 00 02

#004 61: 06 07 07 07
#004 16: 04 00 00 04 00 05 04 00 00 04 00 05
#004 13: 01 01 01 01
\end{Verbatim}

Se definen los tres primeros números como números en sucesión que se tocaran en orden,(el número del compas) tendrá un tiempo de duración según los bpm que le hemos indicado antes, para el ejemplo supongamos cuatro segundos.

Los segundos números son los lanes del DTXMania y por último los números son los sonidos que hemos definido, que tenemos que tocar repartidas equitativamente en estos cuatro segundos, por lo que la primera línea:

\begin{Verbatim}[frame=single]
#000 61: 06 07 07 07
\end{Verbatim}

El DTXMania lo que interpreta es que nos pondría en el lane asociado al canal 61, supongamos hihat el sonido 6 una vez y el sonido 7 tres veces. Por tanto mostraría cuatro barras bajando por ese lane espaciadas 1 segundo entre ellas y si pulsamos en orden correcto, escucharíamos el count1.xa una vez y el count2.xa tres veces.

Como idea básica ya tenemos lo que es el formato DTXMania/DTXManiaHD.


\chapter{Posibles configuraciones en el DTXMania}
Ahora vamos a mirar que se podía configurar en el DTXMania para indicar si lo tendremos que implementar, indicamos que es interesante o lo ignoraremos ya que no esta enfocado para la parte de simulación de batería.

Para ello nos fijamos en las opciones que se indica en la página web \url{http://www.dtxmania.net/wiki.cgi?page=qa_options_e}

También indicar que ya cogeremos el interfaz de gitadora ya que se ha hecho un gran trabajo de limpieza comparado con el DTXManiaHD.

Para ello separaremos en tres tipos las configuraciones de interfaz.

\begin{itemize}
  \item Configuraciones a implementar
  \item Configuraciones para mejorar en un futuro
  \item Configuraciones que se escapan al objetivo del proyecto
\end{itemize}

y también las diferenciaremos en dos grandes grupos de interfaz y de uso
\section{Configuraciones de Interfaz a implementar}

\subsection{DARK}
Dan las opciones de OFF, todo se vera.
Half donde no se vera el wallpaper, los \gls{Lanes} coloreados se verán en negro y la barra de vida tampoco se vera
Full donde además desaparecen los iconos de los instrumentos.

Esta opción también se podría indicar como a mejorar en un futuro, ya que se implementa el estilo Full, por ser la más empleada, junto a half ya que  tiene menos elementos en pantalla, y de esta manera tener una interfaz más limpia.


\subsection{Autoplay}
En el DTXMania se podía configurar cada lane como AUTO, de esta manera el DTXMania se haría cargo de tocar el sonido cuando hiciera falta sin aumentar la puntuación, ni bajar la barra de vida, esto era muy útil para no tener que tocar el bombo que al principio es lo más difícil y preocuparse solamente del ritmo de las baquetas, y además ofrecía la posibilidad de en baterías con menos pads poder jugar ignorando algunos lanes.


\subsection{ScrollSpeed}
Esta es una opción obligatoria a implementar ya que esta es la velocidad con que se mide la sincronización a mayor velocidad pongamos más precisos tenemos que ser.

\subsection{Tight}
Marca un miss si no hay \gls{Chips} en el lane concreto que se haya tocado, con esta opción nos obliga a tocar lo que muestra el DTXMania, es una opción que estaría bien implementar en un futuro pero entra en conflicto con el número de \gls{Pads} que se tenga en la bateria-MIDI y que versión de canción estamos tocando, esto se detallara más adelante.

\subsection{InputAdjust}
Ajusta el tiempo de entrada para modificar el posible lag algunas baterías-MIDI, es una opción interesante pero no la veo obligatoria.

\subsection{PreviewSoundWait}
Se puede configurar el tiempo cuando comenzaran a sonar la música de preview de las canciones en el menú de selección, esta opción la dejamos como opcional para un futuro.

\subsection{Fullscreen}
Opción que se dejara para poder escoger si la aplicación funciona en fullscreen o en modo ventana.


\section{Configuraciones de Interfaz interesantes para un futuro}


\subsection{Sudden}
Quita los \gls{Chips} de los \gls{Lanes} hasta que están justo encima de las barras de esta manera obliga al batería a saberse la canción de memoria. 


\subsection{Hiden}
Quita los \gls{Chips} cuando están a punto de caer en la zona de hit, desaparecen de esta manera el batería tiene que tocar de oído y no estar pendiente de las marcas visuales.

\section{Configuraciones de Interfaz que se escapan al proyecto}

\subsection{ComboPosition}
Donde estará el marcador de combo, encuentro que no hace falta implementarlo ya que se limpio la interfaz en el Gitadora.

\subsection{Reverse}
Las notas en vez de ir de arriba a abajo van al revés, no veo el intereses en implementar esta opción, ya que en entornos abiertos suele haber bastantes opciones para girar la pantalla.

\subsection{Position}
Indica donde saldrán las notas de juicio (Perfect, Great, Good, Miss) con la limpieza de la interfaz del Gitadora no veo la necesidad de implementarlo.


\subsection{Guitar/Bass}
El DTXMania tenia la opción de tocar la guitarra o el bajo estilo Konami, son opciones que para el batería no tienen sentido.


\section{Configuraciones de uso a implementar}
Ahora aquí están las opciones de como se podía comportar el DTXMania cuando ya nos ponemos a tocar una canción, indicaremos las más importantes.

\subsection{Drums Key Assign}
Opción indispensable para poder asignar teclas/\gls{Pads} a los \gls{Lanes}.

\subsection{HH Group}
Opción con cuatro modalidades que configuran la manera de trabajar en los \gls{Lanes} del hihat, esta opción es para la gente que tiene baterías-MIDI simples con menos \gls{Pads} que los \gls{Lanes} en la canción.
\begin{itemize}
  \item HH-0 Opción en donde todos los \gls{Lanes} son independientes.
  \item HH-1 El lane Left Cymbal se integra en los lanes HiHat cerrado/abierto de esta manera hemos quitado un lane.
  \item HH-2 El lane asignado al hihat cerrado o abierto se puede tocar indistintamente.
  \item HH-3 Los tres lanes anteriores se pueden tocar indistintamente.
\end{itemize}


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=1.0]{Imagenes/HH_group.png}
% Ponemos Leyenda al gráfico
\caption{Grupo HH}
\label{Grupo HH}
\end{center}
\end{figure}

Obligatoria. Ya se detallara como se ha resuelto esto en el proyecto.

\subsection{HH Priority}
Aquí definimos que ha de sonar cuando tenemos \gls{Lanes} (HH-1, HH-2 o HH-3) integrados el Chip que esta en la canción o el pad que hemos tocado.

Obligatoria.

\subsection{FT Group}
Opción con dos modalidades que configuran la manera de trabajar en los \gls{Lanes} del tom de la izquierda, esta opción es para la gente que tiene baterias-MIDI simples con menos \gls{Pads} que los \gls{Lanes} en la canción.
\begin{itemize}
  \item FT-0 Opción en donde todos los \gls{Lanes} son independientes.
  \item FT-1 Los dos \gls{Lanes} anteriores se pueden tocar indistintamente.
\end{itemize}


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=1.0]{Imagenes/FT_group.png}
% Ponemos Leyenda al gráfico
\caption{Grupo FT}
\label{Grupo FT}
\end{center}
\end{figure}

Obligatoria. Ya se detallara como se ha resuelto esto en el proyecto.


\subsection{FT Priority}
Aquí definimos que ha de sonar cuando tenemos \gls{Lanes} (FT-1) integrados el Chip que esta en la canción o el pad que hemos tocado.

Obligatoria.Ya se detallara como se ha resuelto esto en el proyecto.


\subsection{CY Group}
Opción con dos modalidades que configuran la manera de trabajar en los \gls{Lanes} del platillo de la derecha, esta opción es para la gente que tiene baterías-MIDI simples con menos \gls{Pads} que los \gls{Lanes} en la canción.
\begin{itemize}
  \item CY-0 Opción en donde todos los \gls{Lanes} son independientes.
  \item CY-1 Los dos \gls{Lanes} anteriores se pueden tocar indistintamente.
\end{itemize}

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=1.0]{Imagenes/CY_group.png}
% Ponemos Leyenda al gráfico
\caption{Grupo CY}
\label{Grupo CY}
\end{center}
\end{figure}

Obligatoria. Ya se detallara como se ha resuelto esto en el proyecto.

\subsection{CY Priority}
Aquí definimos que ha de sonar cuando tenemos \gls{Lanes} (CY-1) integrados el Chip que esta en la canción o el pad que hemos tocado.

Obligatoria. Ya se detallara como se ha resuelto esto en el proyecto.



\section{Configuraciones de uso para un futuro}

\subsection{BGA}
Opción para activar o desactivar las animaciones de Back ground, no la encuentro muy importante.


\subsection{FillIn}
Opción para añadir efectos gráficos cuando se da a una nota en el momento justo.


\subsection{DebugInfo}
Para mostrar información de frames per second, tiempo trasncurrido y total de la canción.


\subsection{HitSound}
Esta opción que activa o desactiva el sample configurado en cada lane, la apuntamos para un futuro ya que se suele emplear para cuando el batería ha de escuchar el resto del grupo y no lo que esta tocando él.

\subsection{SaveScore}
Opción para guardar la puntuación si es la mejor que hemos realizado hasta la fecha, esta opción seria interesante implementarla en un futuro ya que nos hace ver la evolución que se va teniendo a medida que se va tocando la batería, aunque seria más interesante poder tener todo un historial para poder analizar la mejora, y donde solemos fallar.


\subsection{D-MinCombo}
A partir de que número de combo se muestra el numero de combo actual, opción que ya que no  parece muy complicada de implementar la dejamos como opcional para un futuro.

\section{Configuraciones de uso que no se implementaran}

\subsection{AVI}
Para ver los videos o desactivar esta opción, la considero que se escapa al objetivo del proyecto ya que la Raspberry con tema de codecs puede tener mucha problemática, y los problemas relacionados con los DRM.

\subsection{Guitar/Bass}
El DTXMania tenia la opción de tocar la guitarra o el bajo estilo Konami, son opciones que para el batería no tienen sentido.

\subsection{StageFailed}
Es una opción que se tendría que mantener para respetar la dualidad juego/simulador si la activamos se comporta como un juego y si baja mucho la barra de vida, sale al menú de selección de canciones.

La ignoramos ya que no estamos centrando en el DTXMania como simulador/entrenador más que como juego.

\subsection{BGMSound}
El DTXMania se podía configurar de tal manera que no había música de fondo y de esta manera solo se escuchaba la batería, es una opción que no suele tener mucho sentido ya que la mayoría de baterías-MIDI tiene una salida de altavoces donde se escucha la batería en sí.



\section{Otras configuraciones}
Recordar que también existía la opción de poniendo un archivo en los directorios de las canciones se podía configurar dos añadidos.

Un archivo box.def 

\begin{Verbatim}[frame=single]
#TITLE: FROM DTX Collection
#ARTIST: FROM
#COMMENT: Dazzling floor-tom sequences.

#PREIMAGE: preimage.jpg  (or #PREMOVIE: premovie.avi)
#PREVIEW: preview.wav
#FONTCOLOR: #FFFFFF
#PERFECTRANGE: 34        (Release 068 (080427) or later)
#GREATRANGE: 67          (Release 068 (080427) or later)
#GOODRANGE: 84           (Release 068 (080427) or later)
#POORRANGE: 117          (Release 068 (080427) or later)
\end{Verbatim}

Se podía obtener varios beneficios:

\begin{itemize}

\item Tener una imagen y información para el directorio de algunas canciones.
\item Una sincronización especifica para todo un directorio, de esta manera era muy típico tener una carpeta con ritmos básicos para practicar.
\end{itemize}

Seria interesante en un futuro analizar estos archivos.

\chapter{Formato xa}
Como ya hemos comentado anteriormente el formato xa es un formato de sonido que usaron en BandJAM (programa japones de música, hace mucho en desuso) pero desde el inicio del DTXMania se ha usado este formato hasta la actualidad.

Para ello el autor del DTXMania contacto con el autor original para usar este formato, añadió una pequeña documentación en ingles y no ha habido cambios desde entonces.

Las fuentes de este formato están disponibles en \url{http://www.dtxmania.net/wiki.cgi?page=qa_utility_e}

Más concretamente donde se indica donde se puede bajar el xadec.dll asociado a este formato
E indica:

``The original one is made by Shinichi Nakamoto (the author of BandJAM), and I (yyagi and staff) add English docmentations.''

Aquí ya nos indica que esta librería es para uso del formato xa, usado en GDAC2 DTXC y DTXMania.Aunque solo hemos pasado por encima del formato del DTXMania ya hemos podido observar que es un archivo de texto, pero para dar facilidad a los músicos para que usaran este formato hay herramientas para creación de canciones en el formato DTXMania, esto sale de la idea de este proyecto. Pero estas utilidades para crear canciones también usan este .dll.

\section{Problemas}

Si nos fijamos que hizo el único programa que existe para entornos libres, que actualmente no se puede compilar ya que usaba librerías que actualmente están deprecated, el Digiband mencionado anteriormente nos fijamos que dentro de su código existen zonas del código que se compilaran dependiendo de la plataforma linux o Windows.

Dentro del Digiband en el archivo decodexa.C nos encontramos el siguiente código.


\begin{lstlisting}[language=C, frame=single]  
/*Oh... nothing like using a library that you have no idea how it works
 and no idea what to do with the data it gives you and the only documentation 
 you have is a example program.
 Well at least this way I was able to 'hack' it and figure out how it works by
 poking its header file.  Thank you bandjam.net for allowing public use of the 
 codec.  It's just to bad the codec has a round about usage.
*/
#ifndef LINUX
bool decodexa(char soundfile[300])
\end{lstlisting}

Por lo que se podía decodificar estos archivos si se estaba en Windows pero no en Linux.

Si se mira la documentación que se puso en aquellos tiempos para poder compilar y crear el xadec.dll se observa lo siguiente:

\begin{lstlisting}[language=C, frame=single]  

#ifndef		_XADEC_H_
#define		_XADEC_H_

/*-------------------------------------------------------------*/
#include	<windows.h>
#include	<windowsx.h>
#include	<mmsystem.h>

/*--------------------------------------------------------------*/
#define		_XAID (ULONG)(('1'<<24)|('D'<<16)|('W'<<8)|'K')
/*--------------------------------------------------------------*/
typedef struct _XASTREAMHEADER {
	UCHAR *pSrc;
	ULONG nSrcLen;
	ULONG nSrcUsed;
	UCHAR *pDst;
	ULONG nDstLen;
	ULONG nDstUsed;
} XASTREAMHEADER;

typedef struct _XAHEADER {
	ULONG id;
	ULONG nDataLen;
	ULONG nSamples;
	USHORT nSamplesPerSec;
	UCHAR nBits;
	UCHAR nChannels;
	ULONG nLoopPtr;
	SHORT befL[2];
	SHORT befR[2];
	UCHAR pad[4];
} XAHEADER;

typedef HANDLE HXASTREAM;
\end{lstlisting}

Donde el autor emplea código asociado a la plataforma Windows para definir bastantes cosas de este formato, ya que aunque se podría pensar que solo poniendo los tamaños correctos se podría compilar, también usa detalles internos del Windows para tener detalles del sonido.

Esto se miro para hacer que el reproductor de DTXMania en entornos libres, funcionara indistintamente de los formatos internos del DTXMania pero tal y como se ha mostrado no queda bien integrar formatos cerrados en entornos libres.

\section{Solución aportada al proyecto}

Si nos fijamos en las utilidades para crear canciones con el formato DTXMania, nos damos cuenta que nos obligan a tener este xadec.dll y también indican que podemos tener la utilidad xa.exe para poder transformar de .wav a .xa.

El formato DTXMania desde los inicios acepta .xa o .wav indistintamente lo que antes por consumo de memoria a la hora de reproducir la canción y por tamaño a la hora de pasarlo vía Internet aconsejaba usar los .xa.

Para no perder todas las canciones que si que tienen un o varios .xa lo que se ha comprobado es que esta utilidad para transformar de wav a xa, también puede reconvertirlos.

Aquí volvemos a tener un pequeño problema esta utilidad evidentemente esta pensada para Windows. Lo bueno es que al ser tan simple (es una utilidad vía linea de comandos), se ha probado mediante wine y ha funcionado.

Por lo que con un pequeño script, podemos pasar de canciones DTX ``no libres'' a canciones totalmente ``libres''.


\begin{lstlisting}[language=bash, frame=single]
find . -type f -iname *.dtx -exec sh -c 'iconv -f $(file -bi "$1" |sed -e "s/.*[ ]charset=//") -t utf-8 -o converted "$1" && mv converted "$1"' -- {} \;
find . -iname '*.xa' -execdir wine ../xa122/xa.exe -d -u '{}' \;
find . -iname '*.dtx' -execdir sed -i -e 's/.xa/.wav/g' '{}' \; 
find . -iname '*.dtx' -execdir sed -i -e 's/.XA/.wav/g' '{}' \;
find . -iname '*.dtx' -execdir sed -i -e 's/\\/\//g' '{}' \;
find . -type f -iname "*.mp3" -exec bash -c 'FILE="$1"; ffmpeg -i "${FILE}"  -acodec libvorbis "${FILE%.mp3}.ogg";' _ '{}' \;
find . -iname '*.dtx' -execdir sed -i -e 's/.mp3/.ogg/g' '{}' \; 
\end{lstlisting}

\begin{itemize}
  \item Convertir los ficheros .dtx desde su codificación de origen a UTF-8 
  \item Pasamos el programa xa de tal manera que convierta todos los .xa a .wav, con el comando find ya coge tanto los .xa como los .XA
  \item Ahora transformamos donde apunta los archivos dtx de estos .xa a .wav
  \item Por si han usado mayúsculas también cambiamos de .XA a .wav
  \item Transformar los caracteres de directorio de windows al de linux
  \item Convertir los ficheros de .mp3 a .ogg, y canviar los .dtx en consecuencia
\end{itemize}


Recordar que esto rompe un poco el espíritu del proyecto ya que esta transformación solo la podemos hacer o en un Windows o con este script en un linux x86, luego una vez transformado si que funcionaria en cualquier plataforma tanto x86 como arm.

\chapter{Formato DTXMania al completo}

Ahora pasamos a hacer una lista de las especificaciones formales dentro del formato DTXMania, para ello vamos a la página web \url{http://dtxmania.net/wiki.cgi?page=qa_dtx_spec_e}

\section{Estructura básica}

Como ya hemos visto anteriormente la estructura básica de un archivo .dtx se compone de dos parte cabecera y objetos.

En la cabecera ira la información genérica de la canción y en la parte de los objetos toda la notación musical.


Todos los comandos se definen en lineas.
\begin{itemize}
  \item DTXMania ignora todas las lineas que no comienzan por \#
  \item DTXMania ignora las lineas que no tengan un descriptor definido.
\end{itemize}

Los comentarios dentro de los DTX son a partir del carácter ; hasta el final de la línea.

Se aconseja que no se usen a mitad de la linea ya que antiguamente un creador de dtx no lo soportaba por lo que se podía tener problemas de abrir archivos .dtx en ese creador y que hubiera problemas.

Los formatos de sonido soportados son .wav, .xa, .mp3 y .ogg, ya hemos comentado como trataremos estos .xa y los .mp3 que nos podrían causar algún problema ya aconseja el propio autor del DTXMania por tema de licencias usar el .ogg antes que el .mp3.

Los ficheros de imágenes soportados por el DTXMania son el .bmp, .png y .jpg, con estos no tendremos ningún problema.

Los ficheros de video indica que soporta tanto los .VFW (video for Windows) o AVI , no es el objetivo principal de este proyecto el tratar ficheros de video.

Ahora vamos a detallar todos los comandos documentados para nuestro reproductor de .dtx, también se separa en tres grandes bloques: a implementar, detallar para un futuro o  no implementar por salir de la idea del proyecto.
\section{Cabecera}

Si ponemos zz lo que se define es decimal más letras en mayúsculas por lo que tenemos las siguientes posibilidades (01-ZZ) 

\section{Comandos en cabecera a implementar}

\subsubsection{\#TITLE}
\#TITLE <song title>

\subsubsection{\#PANEL}
\#PANEL <comments on playing screen>

Es un comentario que se vera con un scroll mientras se juega la canción, se suele usar en las canciones para entrenamiento indicar como se tienen que tocar.

Si no existe este parametro se usa \#TITLE

\subsubsection{\#DLEVEL}
\#DLEVEL <level value>

Dificultad de la canción en batería.

\subsubsection{\#BPM}
\#BPM <the value of BPM>

El valor del BPM al inicio de la canción, se puede usar decimales.
\subsubsection{\#BPMzz}
\#BPMzz <the value of BPM>

Posible valor de BPM, durante la canción se modificara mediante el canal 08 apuntando al valor de la ``nota de cambio'' zz.¡

\subsubsection{\#BASEBPM}
\#BASEBPM <the value of BASEBPM>

El valor base de las BPM al cual se añadirán o restaran valores para modificar los BPM durante la canción.


\subsubsection{\#PREIMAGE}
\#PREIMAGE <preview image filename>

Imagen que se mostrara en la pantalla de selección.

\subsubsection{\#WAVzz}
\#WAVzz (WAV, MP3, XA or OGG) filename>


Define el sonido del banco zz. Para que nuestro reproductor del DTXMania sea lo más libre posible recomendamos solamente WAV o OGG.

Cada canal de batería tiene dos-polifonias posibles.


\section{Comandos en cabecera para un futuro}

Define el nombre de la canción.
\subsubsection{\#ARTIST}
\#ARTIST <artist name>

Define el nombre del artista.

\subsubsection{\#GENRE}
\#GENRE <genre name>

Define el genero de la canción.

\subsubsection{\#COMMENT}
\#COMMENT <comments of yours>

Pone un comentario.

\subsubsection{\#STAGEFILE}
\#STAGEFILE <now loading image filename>
Se puede usar archivos en BMP, JPEG o PNG. Y se mostraran en el momento de cargar la canción.


\subsubsection{\#BACKGROUND}
\#BACKGROUND <wallpaper filename>

Wallpaper que se usara en la canción.


\subsubsection{\#WALL}

\#WALL <wallpaper filename>

Lo mismo que background.

\subsubsection{\#PREVIEW}
\#PREVIEW <preview sound filename>

La música que sonara como muestra en el menú de selección.


\subsubsection{\#BMP}
\#BMP <BGA image file>

Pone la imagen de fondo inicial.


\subsubsection{\#SOUND\_NOWLOADING}
\#SOUND\_NOWLOADING <nowloading sound filename>

Define el sonido que se escuchara mientras estamos en la pantalla de ``now loading''.


\subsubsection{\#SOUND\_STAGEFAILED}
\#SOUND\_STAGEFAILED <stage failed sound filename>

Define el sonido que se escuchara mientras estamos en la pantalla de ``stage failed''.

\subsubsection{\#SOUND\_FULLCOMBO}
\#SOUND\_FULLCOMBO <full combo sound filename> 

Define el sonido que sonara si hacemos un full combo.

\subsubsection{\#RESULTIMAGE}
\#RESULTIMAGE <result screen image filename>

Imagen que se mostrara al final de la canción.
Si no esta definido se usara \#PREIMAGE.
También se puede usar \#RESULTIMAGE\_xx que puede cambiar la imagen resultante dependiendo de que rango se obtenga al tocar la canción.

\begin{Verbatim}[frame=single]
#PREIMAGE resimage0.jpg
#RESULTIMAGE_A resimage1.jpg
#RESULTIMAGE_D resimage2.jpg

;Si tu rango es...
; -SS, S or A: resimage1.jpg 
; -B, C or D: resimage2.jpg 
; -E: resimage0.jpg 

\end{Verbatim}


\subsubsection{\#RESULTIMAGE\_xx}
\#RESULTIMAGE\_xx <result screen image filename>

Mirar \#RESULTIMAGE

\subsubsection{\#RESULTSOUND}
\#RESULTSOUND <result screen sound filename>

Sonido que se usara en la pantalla de resultados.


\subsubsection{\#RESULTSOUND\_xx}
\#RESULTSOUND\_xx <result screen sound filename>

Sonido que se usara dependiendo del rango obtenido, para el uso mirar la sección RESULTIMAGE.


\subsubsection{\#VOLUMEzz}
\#VOLUMEzz <volume percentage>

Ajusta el volumen en el banco de sonido zz.

\subsubsection{\#PANzz}
\#PANzz <panning position parameter>

Ajusta el posicionamiento del stereo en el banco de sonido zz, el uso va de -100 a 100.


\subsubsection{\#SIZEzz}
\#SIZEzz <chip display size percentage>

Sirve para definir el tamaño de las notas en el canal zz. Puede ser útil para mostrar visualmente que las notas aunque esten en el mismo lane, tienen volumen distinto o realmente se tendria que tocar con varios instrumentos.

\subsubsection{\#BMPzz}
\#BMPzz <image filename>

Define la imagen que se empleara para el chip del canal zz. 




\section{Comandos en cabecera que no se implementaran}

\subsubsection{\#GLEVEL}
\#GLEVEL <level value>

Dificultad de la canción en guitarra.

\subsubsection{\#BLEVEL}
\#GLEVEL <level value>

Dificultad de la canción en bajo.

\subsubsection{\#PREMOVIE}
\#PREMOVIE <preview movie filename>

Video que se pondría en el menú de selección. No es el objetivo del proyecto manejar ficheros de video.

\subsubsection{\#HIDDENLEVEL ON}
\#HIDDENLEVEL ON

Pone la dificultad como ??. 


\subsubsection{\#BACKGROUND\_GD}
\#BACKGROUND\_GD <wallpaper filename>

Wallpaper que se usara en el modo guitarra.


\subsubsection{\#RESULTMOVIE}
\#RESULTMOVIE <result movie filename>

La película que se vera cuando se acaba la canción. 

\subsubsection{\#RESULTMOVIE\_xx}
\#RESULTMOVIE\_xx <result movie filename>

La película que se vera dependiendo del rango.


\subsubsection{\#MIDINOTE}
\#MIDINOTE <ON|OFF>

Se puede usar para que salga en el canal 10 de MIDI-OUT. Lo que se esta tocando. No se implementara ya que las dos principales baterías-MIDI que se han tomado por defecto en este proyecto ya tienen formas de tener MIDI-OUT.

\section{Objetos}
Descripción de los objetos


\subsubsection{\#nnncc object list}
Se define la notación :

\begin{itemize}
  \item nnn Compas número nnn en decimales (000-999)
  \item cc El canal en hexadecimal (01-FF)
  \item object list - lista de objetos
\end{itemize}

\subsubsection{Formato de lista de objetos}
Se define la lista de objetos como donde y que \gls{Chips} están una barra y un canal distribuidos uniformemente en la barra.
Cada objeto esta definido como una expresión de 2 dígitos en 36-decimales (números y letras) por lo que cada objeto va entre (00-ZZ).

El objeto 00 esta definido como el silencio, y los demás objetos tendrán su banco de sonido asociado mediante el comando en cabecera de \#WAVzz

Para entender esto lo mostraremos con un ejemplo,definiremos la siguiente partitura:


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=5.0]{Imagenes/explicacion-lista-objetos.jpg}
% Ponemos Leyenda al gráfico
\caption{Explicación lista objetos}
\label{Explicación lista objetos}
\end{center}
\end{figure}


\begin{Verbatim}[frame=single]
  #WAV01 hihat.wav
  #WAV02 snare.wav
  #WAV03 bass.wav

  #00111 0101010101010101
  #00112 00020002
  #00113 0300000303000000
\end{Verbatim}

Vamos a separar explicar cada línea.

\begin{Verbatim}[frame=single]
"#00111 0101010101010101" -> "#00111 01 01 01 01 01 01 01 01"
\end{Verbatim}

Significa que en el primer compás (001), en el canal (11) que es el del hihat ponemos ocho objetos distribuidos uniformemente de tipo (01) que también se ha definido como el sonido hihat.wav. 

De la misma manera:

\begin{Verbatim}[frame=single]
"#00112 00020002" -> "#00112 00 02 00 02"
\end{Verbatim}

Significa que en el primer compas (001), en el canal (12) definido como el snare ponemos cuatro objetos distribuidos uniformemente (00 02 00 02).


\begin{Verbatim}[frame=single]
"#00113 0300000303000000" -> "#00113 03 00 00 03 03 00 00 00"
\end{Verbatim}

Significa que en el primer tiempo (001) en el canal (13) bass, ponemos la siguiente lista de objetos (03 00 00 03 03 00 00 00).

Se puede insertar los caracteres \_\_ que no afectan a la semántica pero pueden ayudar a la lectura humana de la partitura.

\begin{Verbatim}[frame=single]
  #00111 01010101_01010101     / or 01010101_01010101
  #00112 0002_____0002         / or 00__02___00__02__
  #00113 03000003_03000000     / or 03000003_03000000
\end{Verbatim}

Si existe varias lista sobre el mismo tiempo y el mismo canal se mezclaran.

Ejemplo:


\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=5.0]{Imagenes/particion_varias_listas.jpg}
% Ponemos Leyenda al gráfico
\caption{Explicación varias lista objetos }
\label{Explicación varias lista objetos}
\end{center}
\end{figure}

\begin{Verbatim}[frame=single]
  #00112 02020202_02020202_00000000_00000000   -> primera parte (dieciséis notas)
  #00112 000000___000000___020202___020202     -> siguiente parte (tripletas)
  #00113 03_______03_______03_______03
\end{Verbatim}

No se permitirá en este proyecto la mezcla en el mismo lane y mismo canal ya que no esta definido que hacer si se mezclan varias notas, y no es una opción muy usada en los .dtx.

\section{Canales definidos por el DTXMania}

Ahora definiremos los canales tal y como están definidos en el DTXMania, para ello se usara la misma manera de seperarlos en tres tipos: canales a implementar, canales para un futuro y canales que se escapan al objetivo del proyecto.



\section{Canales a implementar}

\subsection{01 - BGM Back chorus}
Canal empleado para los coros este canal es polifónico, se podrían emplear los canales de 61 al 92 pero esas son monofónicas.

\subsection{03 - BPM}
Se cambiara el número de beats por minuto, esta especificado en hexadecimales (01-FF)
Pensar que este valor se añade a la BASEBPM

\begin{Verbatim}[frame=single]
  #BPM 220
  #BASEBPM 200

  #03103 0042
\end{Verbatim}

Al principio, BPM=220.
A partir del compás 31, 03 mitad de la barra se cambiar los BPM a 266 
(42 hexadecimal = 66 + 200)

Esto es lo indicado en la documentación se ha probado y lo que realmente se tiene que hacer es, si esta en la primera nota del compás cambiar los BPM del compás actual y si no cambiar los BPM para el siguiente compás.


\subsection{08 - Extended tempo(BPM)}
En el canal 03 se ha definido el tempo como un objeto directo, que se tenia que sumar a un valor base, aquí se define el tempo con los valores zz.

Se suele usar el canal 03 para BPM enteros y para BPM reales se usa este canal.

\begin{Verbatim}[frame=single]
#BPM 123.45
#BPM01 234.56
#00303 00007000
#00603 00010000
\end{Verbatim} 

BPM=123.45 Desde el principio de la canción hasta el tercer compás
y segundo beat.
BPM=112.00 desde el tercer tiempo, tercer beat. 
(112 decimals = 70 hexadecimals)
BPM=234.56 desde el sexto tiempo segundo beat hasta el final de la canción
En caso de BASEBPM=0


Esto es lo indicado en la documentación se ha probado y lo que realmente se tiene que hacer es, si esta en la primera nota del compás cambiar los BPM del compás actual y si no cambiar los BPM para el siguiente compás.


\subsection{11-1A - Notas de la batería}
Estos canales son los que pondrán los \gls{Chips} que veremos, los canales y los \gls{Lanes} están relacionados de la siguiente manera:


\begin{Verbatim}[frame=single]
11 = HiHatClose
12 = Snare
13 = BassDrum
14 = HighTom
15 = LowTom
16 = Cymbal
17 = FloorTom
18 = HiHatOpen
19 = RideCymbal
1A = LeftCymbal (DTXMania Release 064b061229 or later)
1F = Fill sound drums
\end{Verbatim} 

No se implementara el canal 1F e indicar también que se tiene que implementar los canales 1B y 1C para tener compatibilidad con las canciones del gitadora, esto no esta en ninguna documentación.

El canal 1B es para el pie izquierdo para el doble bombo y el 1C también para el pie izquierdo para el sonido del hihat.

\subsection{61-62- Sonidos en autoplay}
Canales que están definidos en autoplay, se usan para poner sonidos adicionales.

\section{Canales a implementar en un futuro}

\subsection{02 - BAR length}
Este canal controla la longitud de la barra.
El valor puede ser decimal o flotante, pensar que se cambia la longitud de toda la barra.


 \begin{itemize}
   \item Valor de 1 es el de defecto es equivalente a un ritmo 4/4.
   \item 0.75 significaría un ritmo 3/4
   \item 1.0625 significaría un ritmo 17/16.
 \end{itemize}

\begin{Verbatim}[frame=single]
  #01902 0.75
  #01911 010101
  #01912 010101010101010101
\end{Verbatim}

Este valor se mantiene, hasta que haya otro cambio o final de la canción.

\begin{figure}[H]
% Centramos la figura
\begin{center}
% Incluimos el gráfico y definimos el ancho y alto
\includegraphics[scale=1.0]{Imagenes/canal_reducido.png}
% Ponemos Leyenda al gráfico
\caption{Explicación barra reducida}
\label{Explicación barra reducida}
\end{center}
\end{figure}


\subsection{04 - BGA}
Canal donde se define el BackGround Animation.

\subsection{07 - BGA/ 2 capa}
Muy parecido al canal 04 pero con dos capas.

\subsection{31-3A - Drums invible object}
Este canal se emplea para que cuando se falle el chip de un canal de batería suene este sonido definido aquí, tienen una relación directa con los canales de la batería.

\begin{Verbatim}[frame=single]
31 = HiHatClose
32 = Snare
33 = BassDrum
34 = HighTom
35 = LowTom
36 = Cymbal
37 = FloorTom
38 = HiHatOpen
39 = RideCymbal
3A = LeftCymbal (DTXMania Release 059 or later)
\end{Verbatim}

\subsection{50 - BAR line}
Aunque los tiempos son manejados internamente por el DTXMania se puede hacer que se vean los BAR line en la canción explícitamente.

\subsection{51 - Beat Line}
Aunque los tiempos son manejados internamente por el DTXMania se puede hacer que se vean los beats en la canción explícitamente.

\subsection{53 - Fill in}
Define una zona 01 al inicio 02 al final, para escuchar el sonido de ánimos cuando se comienza un combo o se acaba.

\subsection{55-59,60 - BGA / capas}
Lo mismo que el canal 04, pero más capas para poder definir varios fondos.


\subsection{63-69, 70-79,80-89,90-92 - Sonidos en autoplay}
Canales que están definidos en autoplay, se usan para poner sonidos adicionales.

\subsection{B1-B9, BC No-chip default sound}
Parecido a los canales 31-3A
Aquí se define que suena si no hay chip, pero este canal se puede ir definiendo hasta el final de la canción. por lo que se puede ir modificando estos sonidos.

\begin{Verbatim}[frame=single]
B1 = HiHatClose
B2 = Snare
B3 = BassDrum
B4 = HighTom
B5 = LowTom
B6 = Cymbal
B7 = FloorTom
B8 = HiHatOpen
B9 = RideCymbal
BC = LeftCymbal (DTXMania Release 059 or later. Note: it's NOT BA!)
\end{Verbatim}

\subsection{C1 [BEAT-line shifting]}
La linea de BEAT comenzara en ese BAR donde se haya definido en este canal C1 con el valor 02, no afecta al siguiente BEAT.

\subsection{C2 [hide BEAT/BAR lines]}
Se puede ocultar los chips para ello hay que poner el valor 02 en este canal. Para volverlos a mostrar hay que poner el valor 01.

\subsection{C4, C7, D5-D9, E0 [Swapping BGA bitmap] }
Canales para ir cambiando la imagen de fondo.


\section{Canales que no se implementaran}

\subsection{00}
Tempo esta obsoleto.

\subsection{05 - Extend object}
No implementado en el DTXMania.

\subsection{06 - Cambiar la animación de MISS}
No implementado en el DTXMania.

\subsection{09-10 - Reservados por BMS}
Reservado para otros juegos musicales.

\subsection{20-29 y 2F- Notas de la guitarra}
Estos canales son para la guitarra

\subsection{30 - flow-speed drums}
No estaba soportado por el DTXMania por lo que nosotros tampoco lo implementaremos.

\subsection{40 - Reservado por BMS}
Reservado para otros juegos musicales.

\subsection{41-46 Invisible object for the 2nd player}
No implementado en DTXMania.

\subsection{47-49 - Reservado por BMS}
Reservado para otros juegos musicales.

\subsection{52 - MIDI drum chorus}
Para enviar la nota a través de canal MIDI-10.

\subsection{54 - Playback movie}
Para ver una película especificada en \#AVIzz.


\subsection{93-99 - Reservados}
Reservados.

\subsection{A0-A7 - Bass notes}
Canales para el bajo, no lo tendremos en cuenta.

\subsection{A8 - Wailing (Bass)}
Canal para el bajo, no lo tendremos en cuenta.

\subsection{AF - Wailing sound (Bass)}
Canal para el bajo, no lo tendremos en cuenta.

\subsection{BA - No chip default sound (guitar)}
Canal para la guitarra, no lo tendremos en cuenta.

\subsection{BB - No chip default sound (bass)}
Canal para el bajo, no lo tendremos en cuenta.



\section{Comentarios sobre el proyecto}
Ahora que ya comprendemos como funciona un .dtx, en el proyecto, dejaremos en la salida del terminal todos los objetos que no se han implementado, tanto objetos o canales de esta manera si un .dtx no suena correctamente se podra observar que caracteristicas esta intentando usar y no están implementadas.

Recordar que también se tendrá que mirar el formato .dtx usado en las canciones del dtxmaniahd y gitadora, ya que se ha ido ampliando el formato, y no se ha ido ampliando la documentación en ingles, ya se han implementado dos canales que no estaban en la documentación original.

\chapter{Especificaciones generales de diseño}
\section{Consideraciones generales a python3}
Se ha escogido python y la versión python3 más concretamente para este proyecto, ya que es un lenguaje interpretado y gracias a ello al sin tener que recompilar se tendrá el proyecto tanto en las plataformas x86 como en las plataformas ARM (se tendrá para otras plataformas pero no estará probado).

Ya que python es un lenguaje que tiene muy buen control sobres listas y diccionarios intentaremos integrar esta control en el proyecto principalmente para dos objetivos al mismo tiempo:

 \begin{itemize}
   \item Al usar los iterators para recorrer estas listas el código es más rápido.
   \item Lectura y mantenimiento del código se hace muy fácil.
 \end{itemize}

  Para mantener este segundo punto de manera integrada en todo el proyecto, las variables de tipo lista siempre comenzaran sus nombres como:

\begin{lstlisting}
    list_
\end{lstlisting}
  
  
Y las variables de tipo diccionario empezaran por:

\begin{lstlisting}
    dict_
\end{lstlisting}
 
 Se emplearan listas cuando el orden importe, y diccionarios cuando no, de esta manera siempre tendremos las colecciones de objetos iguales colocados y para los diccionarios la llave que emplearemos sera el nombre de la lane asociada de esta manera estará optimizado para su uso.
 
 Python3 es un lenguaje que depende mucho de las librerías a usar.
 
 En este proyecto se usaran qt5 para sonidos y animaciones, ya que comparando con pygame esta segunda librería al ser de más bajo nivel para implementar menús, botones, el programador lo tiene que hacer todo él.
 
 Entonces se tendrá que usar otra librería para juntar el MIDI con python, viendo las posibilidades se ha optado por rtmidi2 que mediante Cython, dejar usar los comandos de la librería rtmidi de C dentro de python.


Se empleara como IDE el Ninja-IDE principalmente por un motivo, que ya comprueba casi todos los PEP de python por lo que si el código no tiene ningún warning seguramente se acerca bastante a la idea del zen de python.

Se escogerá la versión de python 3.4 debido a que es la soportada en las principales distribuciones en la raspberry.

\subsection{Configuraciones en disco duro}
Como en este proyecto no hay necesidad de unas guardar unas configuraciones muy complicadas se ha optado por usar la librería de python configparser.

\subsection{Cython y rtmidi2}
Observando las librerías disponibles para tratar el MIDI en python3 se observo que existen solamente dos grandes librerias en python, pygame y rtmidi

Para pygame si todos los elementos gráficos están siendo tratados en qt5 se tendría el problema de que gestor de ventanas tendría prioridad a la hora de coger los eventos del teclado o ratón, para evitar estos problemas y además tener un entorno gráfico acelerado si en la plataforma existe la compatibilidad con OpenGL, se ha optado por usar la librería rtmidi2.

Es una librería basada en Cython ( que es la manera que tiene python de llamar a posibles librerías en C) el detalle es que esta librería es muy poco usada por lo que habitualmente se tendrá que descargar, tanto la librería en C, como compilar para el python: Cython y rtmidi2.
 
La gran ventaja de usar este estilo de librerías es que al estar a tan bajo nivel son muy rápidas y se consume poca memoria ya que casi no hay aumento de memoria comparado con las librerías en C.


\section{Gráficos en qt5}
Una de las grandes ventajas de emplear Qt5 como la base para los gráficos es que en todos los menús, podemos separar la parte gráfica de la parte funcional, para ello tenemos los archivos .ui, que mediante el creador que da Qt, podemos definir de manera gráfica todos los elementos que tendrán nuestras ventanas, botones , imágenes, y luego mediante un sistema de eventos y señales podremos darlos una funcionalidad.

Todos los ficheros .ui estarán en una carpeta llamada ui, dentro del código fuente.

Cada vez que se quiera hacer un cambio gráfico en el proyecto se tendrá que generar los .py asociados a estos .ui mediante pyuic5 de esta manera en entornos de poco recursos se optimizara ya que estos python ya estarán generados, como buena practica de programación se aconseja no tocar estos ficheros generados por Qt, por lo que se tendrá que tener clases que se deriven de estos python generados.

\section{Animaciones en qt5}
Qt tiene todo un motor para hacer sus animaciones, dentro de los widgets gráficos, tanto pueden ser animaciones secuenciales como paralelas entre ellas, nosotros siempre emplearemos las paralelo.


Recordar que python es interpretado y tiene un garbaje collector por lo que tendremos que tener especial cuidado en no dejar de apuntar a los objetos que estan vivos, aunque sea de las librerias de Qt, ya que si el garbage collector de python elimina esa porción de memoria podemos tener problemas gráficos.

El mismo Qt5 indica que sus timers y animaciones son aproximadas, en el aspecto que depende de la CPU su buen funcionamiento, siempre entendiendo que el refresco gráfico tiene que tener la CPU libre.

Como python3 tiene el GIL, Global Interpreter Lock, se entiende que aunque hay llamadas a otras librerías que si que podrían estar en otros threads, no es así, si no que para evitar fallos de concurrencia solo hay 1 thread vivo y se va cambiando. Si queremos tener un python realmente paralelo se debería cambiar de interprete.

Esto nos obliga a dejar la CPU libre para que Qt pueda tratar las animaciones ya que sino nunca se dibujarían ya que se entiende que se esta haciendo algo más importante.

Por lo que entonces hay que entender que cuando indicamos a Qt para que python deje la CPU cierto tiempo libre, este tiempo puede no ser exacto, esto se puede notar que en el algunas canciones con muchas notas y mucha velocidad, se ven pequeñas diferencias visuales entre notas. A nivel de sonido y de comprobación de sincronización esto no afecta ya que esta lógica se hará mediante python por lo que al tener más prioridad el tiempo sera correcto.

\section{Sonidos en qt5}
Comentar que qt5, nos da la facilidad de reproducir sonidos, pero tendremos que tener en cuenta si son .ogg o .wav ya que Qt5, no los trata igual,
ya que uno tiene que descomprimir el archivo y reproducir mientras que el otro es más rápido.

Para un mejor funcionamiento del programa todos los sonidos los pondremos en un banco de memoria, para de esta manera una vez ya comenzada la reproducción del .dtx solo tener que reproducir el sonido sin tener que hacer la carga a memoria.
\chapter{pyDTX}
\section{Ideas generales}
Ahora que tenemos definido el lenguaje a usar, las librerías que emplearemos y el formato .dtx podemos pasar a comentar las ideas generales, para efectuar el proyecto.
\section{Pantalla principal}
Se trabaja con un Main Aplication dentro de Qt5, pondremos un MainWindow ya que usaremos entorno gráfico, en este MainWindow crearemos un stackedwidget, dentro del cual ya crearemos unos widgets independientes, de esta manera aumentamos el tiempo inicial pero luego como ya esta todos los menús creados ahorramos en tiempo de computación. Como todos los widgets son bastante independientes seria muy fácil coger este código y modificarlo para otros proyectos de estilo musical, o modificar los gráficos manteniendo la estructura y lógica de python.

Dentro de este stackwidget creamos los siguientes widgets:

 \begin{itemize}
   \item Widget Inicial
   \item Widget para configurar bateria-MIDI
   \item Widget para configurar pyDTX
   \item Widget Pantalla Navegación
 \end{itemize}
 
\section{Pantalla Inicial}
Aquí este es un widget muy básico donde se pondran cuatro botones centrados, estos botones activaran el widget correspondiente de esta manera podemos cambiar de widgets.


Qt5 se encargara automáticamente de que solo el widget actual reciba los eventos de teclado y ratón.

Este widget tiene una imagen de fondo dependiendo de la configuración del pydtx, aquí decir que se hará mediante .css ya que es lo más independiente del sistema y es lo que aconseja Qt5 actualmente, para imágenes que se conocen en tiempo de desarrollo, ya que se deja que los usuarios puedan crear sus propios temas.

\section{Pantalla configuración batería-MIDI}
Esta pantalla como idea básica seria definir las posibles teclas, para cada lane de este pyDTX.

Como pantalla de configuración se tiene que leer el fichero de configuración, poner los elementos gráficos en concordancia y un posible de botón para guardar para todos estos valores gráficos transformarlos en un fichero de configuración.

Además se podrá definir los lanes que configuraremos en Auto para que el mismo pyDTX, haga sonar todos los chips asociados a este lane pero continúen siendo visuales.

En esta pantalla ya ponemos dos cosas relacionadas con la batería-MIDI, la primera un botón para poder ver cuantos instrumentos-MIDI esta viendo el sistema operativo para poder configurar el que queremos usar para tocar los .dtx

Y para que sea más cómodo un botón para pulsarlo y poder tocar la bateria-MIDI y que en la pantalla se pueda ver que nota asociada esta emitiendo la bateria-MIDI.

\subsection{MIDI} 
Ahora haremos una pequeña introducción a la comunicación MIDI enfocada a instrumentos-MIDI puros.

En la comunicación MIDI de un instrumento, hay mensajes diferenciados en 3 tipos:

\begin{itemize}
   \item Nota-on
   \item Variación de nota
   \item Nota-off
 \end{itemize}
 
 
y en cada mensaje hay la nota en sí, y su volumen.
 
Lo habitual es una Nota-on, y luego al cabo de X tiempo dependiendo del instrumento un Nota-off, ya dependiendo del instrumento se puede meter una variación de la nota.

Estos mensajes según el instrumento puede ser múltiples, ya que ese instrumento esta pensado para estar sonando varias notas al mismo tiempo, esto se suele determinar por el instrumento en sí  o por limitaciones del sintetizador MIDI que normalmente tienen un limite de notas al mismo tiempo.

En el proyecto por rapidez y por como suele funcionar una batería, solo miraremos los mensajes tipo Nota-on.

Cada Intrumento-MIDI no emite sonidos, emite estos mensajes y es el sintetizador MIDI que teniendo sus bancos de sonidos configurados, puertos y notas es el encargado de crear los sonidos.

Pensar que este pyDTX, es un sintetizador enfocado a estos instrumentos-MIDI más estilo baterías y a estos ficheros .dtx como partitura.

\subsection{Configuración MIDI en pyDTX}
Aquí uno de los primeros problemas con el MIDI y su tratamiento.

Gracias a usar las librerías Qt, estas mismas librerías se encargan de que los eventos del teclado y ratón solo disparen los objetos gráficos visibles, pero si queremos implementar eventos MIDI, el programa tiene que saber que widget esta activo o solo implementar la escucha de los mensajes MIDI en el reproductor.

La manera que se ha resuelto es que cada vez que estamos en un widget que tiene que escuchar los mensajes MIDI, se tiene que tener una función que se llame al entrar en el widget como seria el caso del reproductor de los .dtx, pensar que los widgets están creados todos al inicio para mejorar la fluidez del programa. En este widget se ha resuelto esta problemática con un botón que es el que activa el escuchar los mensajes-MIDI y lo tenemos que desactivar siempre cuando volvemos al menú principal.


\subsection{Baterías-MIDI y Lanes}
Aunque lo mejor seria que el número de Lanes visuales de los .dtx a tratar fueran los mismos que el número de Notas MIDI a configurar. ya que se podría hacer una relación uno a uno. Se tiene que tratar varios casos distintos bastantes comunes.

El número de lanes que se trata como lanes visuales son 12. Aunque visualmente solo tenemos 9 columnas visuales ya que hay lanes que comparten columna visual para saber que instrumento exacto se debería tocar en una batería concreta se diferencia los chips por color.

La lista completa de los lanes visuales tratados es la siguiente:

\begin{itemize}
   \item 1A Left Cymbal
   \item 11 Hi Hat Close
   \item 18 Hi Hat Open
   \item 1C Left Bass Drum
   \item 1B Hi Hat Foot
   \item 12 Snare
   \item 14 High Tom
   \item 13 Right Bass Drum
   \item 15 Low Tom
   \item 17 Floor Tom
   \item 16 Cymbal
   \item 19 Ride Cymbal
 \end{itemize}

Ahora convendría hacer un pequeño repaso de como se fue ampliando los 6 lanes iniciales del .dtx hasta los 12 actuales.

Ya que incluso la maquina actual del gitadora solo tiene 9 pads, (7 pads y doble pedal)

Los primeros cambios ya fue separa el Hi-hat en posición abierto o cerrado, dependiendo del número de pads de la batería-MIDI y su capacidad, se necesitaría tocar de manera distinta o solo era una marca visual de que son notas distintas, como nunca se puede tocar el hi-hat al mismo tiempo en abierto y en cerrado se puso en la misma columna visual.

El siguiente cambio fue añadir el lane 1A y ya se quedo que el lane antiguo de platillo lane 16 seria el platillo derecho y este nuevo lane 1A se utiliza para el platillo izquierdo. Muy parecido a lo que se hizo en el HiHat, gente que tenia pads con varias zonas de golpeo para que se les indicara cuando se tenia que tocar el platillo en la zona alta o en la zona más cercana al borde pidieron en el platillo derecho mantener el antiguo y este nuevo lane. Como esto no es muy común tener baterías-MIDI con esta prestación, se dejo puesto solo para el platillo derecho para el izquierdo no se diferencia, y seran los creadores de los .dtx los que decidirán si implementar esta diferencias para saber más exactamente como tocar la batería.
 En otros .dtx se emplea para tener sonidos de 3 platillos. Se ha decidido que los lanes 16 y 19 compartan columna pero se indique con dos colores distintos que lane se debería tocar. (No esta contemplado el caso de que haya al mismo tiempo dos notas simultaneas para estos dos lanes)

 
Cuando salio el gitadora se amplio la máquina árcade con pie izquierdo y pie derecho para ello se insertaron los Lane 1B y el 1C que serian los dos para el pie izquierdo, tanto para el hi-hat como para el doble bombo, como no es habitual tener una batería-MIDI con triple pedal y ya que lo más común es tocar canciones con doble bombo o usar el pie izquierdo para el Hi-hat, aunque a nivel visual comparten la misma posición y en el gitadora comparten color, se ha decidido igual que en el caso anterior hacer que las notas visualmente serán de colores distintos para las canciones donde si que hay tanto doble bombo como hi hat, saber visualmente que son notas distintas y si se tiene una batería-MIDI tocar igual que en una batería acústica con estas características.
 
\subsubsection{Pocos Pads para muchos lanes} 

Ya que hay multitud de baterías-MIDI en el mercado se ha de tratar dos principales problemas:

Cuando hay menos pads que lanes o al revés y los dos casos tienen sus complicaciones.

El primer caso se solventa dejando que se pueda configurar una Nota-MIDI en múltiples lanes, esto complica saber la sincronización de cuando se nota esta nota-MIDI con los lanes asociados. Ya que esta configuración obliga a que no se pueda saber si se pulsa una nota-MIDI a que lane concreta se tendría que comprobar, para ello se tendrá que comprobar en todos los lanes asociados, y como suponemos la mejor sincronización posible solo se pondrá a hit el mejor tiempo de todos los lanes asociados, también hay que tener cuidado ya que hay canciones donde puede ser que se tengan que tocar estos dos lanes simultáneamente, y si hemos configurado estas dos lanes en la misma nota-MIDI cuando pulsamos serán dos hits.

\subsubsection{Muchos Pads para pocos lanes}

El otro caso es tener una batería-MIDI muy completa, y querer usarla para tocar los .dtx, si solo se puede configurar una nota-MIDI para varios lanes, esto obliga al batería a tener que ser muy exacto ya que todos los pads con zonas múltiples, solamente se deberían tocar en una zona concreta, la solución más simple es dejar que en cada lane, se puedan configurar dos notas-MIDI al mismo tiempo.

\subsubsection{Casos especiales por respetar los dos al mismo tiempo}

Estos casos independientemente tienen su sentido pero el tener que respetar los dos al mismo tiene una serie de ventajas y de desventajas.

La desventaja clara es que nos complican el comprobar la sincronización entre tocar notas-MIDI y su relación con los chips de la partitura.

La ventaja de tener estas opciones además de las comentadas es que con el mismo programa no tendremos problemas a la hora de poner canciones del dtxmania original, dtxmaniaHD o del gitadora, ya que el principal inconveniente era el doble bombo, si se tiene una batería-MIDI con el doble bombo. 
Se puede configurar de la siguiente manera: el hihat y el bombo izquierdo se configuran en el pie izquierdo, pero además este pie izquierdo se puede poner también en el bombo derecho, con esto se ha conseguido que en la misma configuración poder llamar a canciones antiguas del dtxmania original, con doble bombo y se puede tocar con los dos pies, aunque no se respeta izquierda o derecha ya que esta asociado al mismo lane y debe ser el que toca saber que pie debería ser tocado. 

Con la misma configuración si la usamos para un dtx del dtxmaniaHD o del gitadora como estos ya diferencia pie izquierdo y derecho, la podemos usar y el pydtx indicara visualmente que pie se debería tocar, aunque con esta configuración en concreto se puede tocar el lane del bombo derecho correctamente o usar el pie izquierdo. Por lo que se observa que no hay manera de respetar todos los casos y obligar al mismo tiempo que la pulsaciones en los pads sean las que tendrían que ser en una batería acústica.

\section{Pantalla configuración pyDTX}
En este widget se configura los valores por defectos del pyDTX.

Ya se tienen en cuenta el directorio de los temas gráficos.

El directorio inicial donde se comprobaran los subdirectorios para seleccionar las canciones de dtx, detallar que por comodidad si queremos ir a un directorio superior de este directorio inicial volveremos a ir al menú principal.

Aunque se dejara cambiar la velocidad de sincronización antes de reproducir cualquier canción, aquí se podrá tener una velocidad por defecto para ya tenerla configurada cada vez que se arranque el pyDTX. Para tener claro que relación hay entre esta velocidad, que es el tiempo que tardara un chip en recorrer la pantalla desde el punto más alto a la parte inferior, y los tiempos de sincronización se pondrán unas indicaciones en pantalla para saber los margenes que es aplicaran para las posibles sincronizaciones Perfect, Great, Good y Poor.

También se podrá seleccionar si para las animaciones de los chips gráficos durante la reproducción de la canción usaremos OpenGL, ya que esto es una asignatura pendiente en muchas plataformas arm y si obligamos a usar OpenGL, como se crean todas los widgets al inicio para mejorar los tiempos, el programa fallaría sin ni siquiera ver la pantalla de inicio (de todas maneras se puede cambiar el fichero de configuración ya que es un fichero de texto con extensión .ini)
 
\section{Pantalla Navegación}
El widget que se empleare para seleccionar la canción a reproducir.

Se dividirá en tres grandes partes, información de la canción actualmente seleccionada, una botonera para cambiar entre canciones o directorios, y una lista de los directorios y canciones del directorio seleccionado actualmente.
\subsubsection{Información de la canción}
Sera una columna a la izquierda donde se pondrá la información de la canción seleccionada, hay espacio para una imagen de visualización y varias textos (etiquetas gráficas en Qt5) para indicar autor de la canción, dificultad y una de información extra.

Se tendrá en cuenta cada vez que se cambie el directorio o la canción seleccionada actualizar estos cuatro elementos gráficos automáticamente.

\subsubsection{Lista de las canciones y directorios actuales}
Se obtendra la información de todos los subdirectorios que estén dentro del directorio actual de canciones, cuando se crea el widget sera del directorio indicado en la configuración.

Aquí para una mayor comodidad en la navegación se entenderá que un directorio que tenga un set.def o un único .dtx ya podemos entender que este directorio contiene al menos una canción.

Si solo hay un .dtx es tan sencillo como obtener la información del .dtx y ponerlo en la lista de selección, y si tiene un set.def obtener la información de los posibles cinco labels y de sus cinco posibles .dtx asociados.

Esta parte por lo que se ha comentado sera la encargada de tener una lista de las posibles selecciones, cada ítem de esta lista sera uno de los siguientes:


\begin{itemize}
   \item Si dentro del directorio hay un set.def, obtendremos en una lista de 5 elementos, las 5 posibles etiquetas de estos elementos y la información de los .dtx asociados.
   \item Si no tiene un set.def buscaremos .dtx dentro del directorio y el primero que encontremos obtenemos la información de esta canción (la información para los 4 elementos gráficos)
   \item Si es un directorio sin set.def o .dtx, guardaremos su path.
 \end{itemize}
 
 
De esta manera tendremos una lista con toda la información del directorio actual ya guardada en memoria para no tener que estar pidiendo la información al sistema operativo, mientras que no nos movamos de directorio.

\subsubsection{Botonera para cambio de directorios o seleccionar canciones}
En esta parte tendremos los botones para realizar acciones sobre la canción seleccionada , velocidad de sincronización o sobre los directorios.

Comentar que no siempre veremos todos los botones ya que es más intuitivo si los botones que no tienen sentido, los escondemos y solo mostramos los que si que pueden realizar acciones sobre el directorio o canción seleccionada.

El primero y más sencillo es el de ir a un nivel de directorio superior, si lo usamos y estamos en directorio configurado como directorio de las canciones volveremos al menú principal, si no subiremos un nivel el path de directorio y volveremos a crear toda la lista de directorios y canciones del directorio actual.

Ponemos dos botones para subir o bajar en la lista de directorios/canciones, ya que de esta manera se deja abierto la manera de seleccionar estos directorios, se dejara seleccionar vía ratón pero también se puede seleccionar vía teclado, mediante la tabulación entre botones, recordar que de esta manera sera sencillo hacer que una batería-MIDI simule estas ordenes si solo dejáramos la vía del ratón, se debería cambiar mucho código para que funcionara mediante la batería-MIDI.

Abajo de todo también existen dos botones y un elemento gráfico para variar la velocidad de sincronización actual. De esta manera no tenemos que cambiar la configuración cada vez.

Se creara un botón para reproducir la canción actual, este botón solo se mostrara en el caso de que estemos seleccionando un directorio que no tiene un set.def y al menos tiene un .dtx, cuando se pulsa empezaremos a reproducir la canción con la velocidad de sincronización actual.

Se creara un botón para cambio de directorio, solo se mostrara si estamos seleccionado un directorio sin set.def o .dtx, si se pulsa cambiaremos de directorio y se tendrá que rehacer toda la lista de posibles directorios/canciones

También tenemos cinco posibles botones para los directorios que tienen un set.def, como el programa original no indicaba nada en las canciones que hay por internet estos cinco posibles .dtx tienen un orden pero dependía del creador de los .dtx y del set.def cuantos y como se empleaban estas cinco posibilidades, en cada una de estas posibilidades se puede apuntar a un .dtx y poner un texto para información, además de la información que tiene el .dtx.

Para ello cuando se crea la información de un directorio con un set.def se obtendrá toda la información disponible e indicar también la información que no hemos podido obtener, para mostrar los botones que tienen asociada información.

Se actualiza la información mostrada de la canción con el primer botón que tiene asociada información.
 
Aquí se ha tenido que usar una opción del Qt5 para cuando hay focus en uno de estos botones ya que se tiene que hacer acciones extras, que es actualizar toda la información mostrada de la canción seleccionada.

Esto se ha realizado de esta manera para integrar el uso del ratón y del teclado o posible batería-MIDI ya que si solo se tiene en cuenta el ratón siempre se pulsaba directamente los botones y no se podía ver la información de los .dtx, o se tendría que haber puesto dos botones más para poder navegar entre los posibles .dtx de un set.def, se ha preferido para simplificar el menú mediante esta reprogramación de los eventos si hay focus en uno de estos botones, poner la información del .dtx relacionado.

\section{Reproducción de la canción}

\subsection{Inicialización básica y detalles de Qt5}
El widget donde reproduciremos la canción seleccionada, sera un widget gráfico ya que sera el encargado de tener los lanes visuales y dentro de ellos los chips visuales, además del widget de puntuación.

Este widget gráfico ya estará creado, y según la configuración usaremos OpenGl o no, lo seguro es que desactivamos las opciones del qt5 de las barras de scroll de un QgraphicsView, ya que por defecto si se añaden elementos gráficos en los limites de la visión, aparecerían barras de scroll para poder ver todo.

Otra cosa a evitar es el evento resiseEvent, ya que si se redimensiona la pantalla, se ha pensado que siempre estaremos usando la misma resolución interna, de esta manera sera el Qt5 el encargado de mantener la relación de aspecto.

No podemos inicializar nada más ya que dependemos de la canción seleccionada y del tiempo de sincronización.

\subsection{Inicialización con una canción}
Llamamos al reproductor con un .dtx concreto y una velocidad de sincronización.

Leemos los ficheros de configuración, para ya tenerlos en memoria.

Como toda la parte gŕafica sera mediante Qt5, creamos una scene e iremos añadiendo todos los elementos gráficos a esta scene para que Qt5 los pueda tratar.

Ahora pasamos a configurar el teclado y el instrumento MIDI.

\subsection{Teclado}
\subsubsection{Configurar teclado}
Creamos un diccionario donde guardaremos la relación de teclas con su lane correspondiente.


Recorriendo todas las lanes visuales, miramos si la lane esta configurada sin automático, si fuera de esta manera miramos su tecla asociada y entonces la añadimos a este diccionario de teclas. 

\subsubsection{evento de teclado}
Configurando el evento keyPressEvent de Qt5, cuando se pulse una tecla lanzara este evento.

Se comprueba si es la tecla especial Escape, si fuera esta se tiene que dejar de reproducir sonidos y volver a el menú de selección de canciones.

Si no fuera así, comprobamos que tecla se ha pulsado y si esta en el diccionario de teclado que hemos configurado, deberemos coger el tiempo actual y comprobar la puntuación en el lane asociado, esto se explicara más concretamente cuando definamos los lanes visuales que funciones tienen.

\subsection{MIDI}
\subsubsection{Configurar MIDI}
Creamos un diccionario donde guardaremos las notas midis y la lista de sus lanes correspondientes.

Recorriendo todas las lanes visuales, si la lane esta configurada sin automático, si fuera de esta manera miramos su dos posibles MIDI y entonces los añadimos a este diccionario de MIDI, cuidado ya que una nota MIDI puede activar múltiples lanes, por eso son listas dentro de un diccionario y no un diccionario simple.
\subsubsection{Evento MIDI}
Mediante rtmidi2 definimos una función que se dispara cada vez que vea un evento MIDI, del instrumento MIDI que esta en la configuración.

Cuando se dispara este evento es comprobar el tipo de mensaje MIDI que tiene, los eventos tipo '153' Note-On serán los que se traten.

Si fuera de esta manera, miramos si esta nota esta definida dentro de nuestro diccionario.

Aquí hay que tener mucho más cuidado que con el teclado ya que hay dos posibles casos:
Que haya solamente un lane asociado a esta nota-midi por lo que es lo mismo que el caso con el teclado o, puede ser que haya varios lanes asociados a esta nota-midi por lo que se tendrá que hacer una doble pasada sobre los lanes asociados: una primera para obtener el tiempo menor comparando con el tiempo actual, para saber a que lanes iría esta nota, y luego ya ir a los lanes y marcarlos como hit, recordar que pueden existir notas en varios lanes en el mismo tiempo. 
\subsection{Lanes}
 Una vez configurados los métodos de entrada teclado y midi. Pasamos a crear los lanes automáticos y visuales.

\subsection{Ideas básicas de los lanes}
Entendemos un lane como una lista de chips, los lanes los separaremos en dos grandes grupos lanes auto y lanes visuales, los cuales tendran asociados chips auto y chips visuales, pasamos a describir los chips por que son más sencillos y luego describimos los lanes.

\subsubsection{Chips Auto}
Creamos una clase Chip Auto.

Los chips auto son los chips que tendrán los lanes automáticos puros, que son los que se emplean para o poner la música de fondo o para ir añadiendo sonidos en la canción, ejemplo clásico metrónomo para canciones de practica.

Un chip auto se puede entender como una nota (un sonido que estará en un banco de sonidos definido en el dtx) y un tiempo donde debería ser tocada.

Crearemos dos funciones en esta clase para leer el tiempo y su nota en sí.

\subsubsection{Chips Visuales}
Creamos una clase que se extiende de QGrapchicsWidget, para que Qt5 pueda manejar toda la parte gráfica y le pondremos los mismos datos y funciones que la clase Chip Auto.

Esta clase es un tipo de Chip pero visual, donde además de la información anterior tenemos que poner si el chip ya ha sido pulsado, una animación, un color de chip, una posición en pantalla.

Los datos de color y posición son dependientes del lane donde esta este chip.

Las funciones que tendremos que definir además de las de un chip auto son:


paint: función que usara Qt5 para pintar este chip en concreto donde indicamos que pinta un rectangulo, con un color.

animar: función donde creamos una propiedades de animación para que qt5 lo trate, básicamente es poner un chip, arriba de la pantalla y posición horizontal de la lane donde estamos e indicamos que tiene que acabar esta animación en la misma posición horizontal pero abajo de la pantalla, indicando que tiene que tardar el tiempo de sincronización.

Esta función tiene que devolver la animación en si ya que sera la scene de Qt5 donde se tiene que tratar.

\subsubsection{Lanes Auto}
Creamos un clase lane Auto donde tiene dos datos una lista de chips, y un banco de sonidos.

Las funciones asociadas a esta clase son las siguientes:

insertar\_chip: Para poder insertar chips en la lista de chips.

insertar\_sonidos: Para poder insertar todo el banco de sonidos en el la lane auto.

reproducir: Donde se buscara el primer chip de la lista y mirando su tiempo si es igual o menor al tiempo actual, se tiene que reproducir su nota asociada y eliminar este chip.

\subsubsection{Lanes visuales}
Extendiendo la clase de Lane Auto definimos la clase Lane visual la idea es tener un lane donde tendremos una lista de chips y una función para reproducir los sonidos por si esta configurado como automático, pero tendremos que añadir toda la información gráfica y funciones para comprobar la puntuación según el sincronismo.

Los datos de un lane visual son los de un lane automático y además color, posición horizontal y el tiempo de sincronización, de este calculamos el tiempo máximo a mantener una nota en memoria, ya que una nota que ya ha pasado su tiempo donde tendría que haber sido tocada y el margen de puntuación poor, esa nota es un miss y la podemos olvidar ya que no tiene que ser tratada.


Además de funciones para leer datos del estilo leer\_color y leer\_pos.

Hay tres funciones para estos lanes visuales.

comprobar\_y\_poner\_hit:

Función para buscar la nota más cercana al tiempo actual, y ponerla a hit, se devolverá la diferencia del tiempo actual al tiempo de la nota, para poder puntuar.

comprobar\_tiempo:

Función que se usara para cuando una nota-midi esta en varios lanes visuales, comprobamos en la lista la nota más cercana al tiempo actual y se devolverá el tiempo de diferencia de esta manera podremos saber el lane donde esta la nota más cercana.


eliminar\_nota\_antigua:

Con el tiempo actual se comprueba si la primera de la lista ya ha superado su tiempo y el tiempo de margen de hasta una nota en calificación poor, quitamos esta nota si ha superado este tiempo. Y devolvemos true si se ha eliminado una nota que no haya sido pulsada, esto es para poder indicar a la puntuación que hay una nota más en miss.

\subsubsection{Reproducir una canción}
Ahora que ya los hemos definido podemos indicar tranquilamente que creamos los lanes automáticos, 01, 61 y 62, que son los lanes automáticos más comunes en los .dtx. y los ponemos en un diccionario de lanes automáticos.

Creamos los lanes visuales 11, 12 , 13, 14, 15,16,17,18,19 ,1A, 1B y 1C con sus colores y posiciones, siempre mirando si en la configuración esta puesto como lane automático, si fuera de esta manera además de en el diccionario de lanes visuales, se tendría que añadir también al diccionario de lanes automáticos.


Ponemos el número de compases a cero, y vamos a obtener la información básica del .dtx

En esta primera pasada obtenemos los siguientes datos:

Todos los bancos de sonidos que están definidos como ordenes WAVxx, si el sonido es un .ogg o un .wav crearemos un banco de sonido con un reproductor asociado al tipo del sonido de esta manera cuando tengamos que reproducir el sonido ya estará cargado en memoria y preparado.

Todos la información de los posibles cambios de BPM en la canción y de los BPM por defecto.

Obtenemos la información del nombre de la canción que lo ponemos en el widget de la puntuación.

Iremos tratando la información de los compases poco a poco para ello primero obtendremos sus notaciones, en que lane son estas notas y en que compás.

Como todas las notaciones deberían estar colocadas por compás y no hace falta que estén ordenadas por lane, lo que haremos mientras recorremos todas las notaciones en el archivo .dtx es lo siguiente, si es un compás mayor que el actual ponemos en esta lista en el sitio del compás un diccionario con la key 'lanes' vaciá, y luego insertamos los datos en el compás, y en este diccionario ya ponemos usando la lane como key, las notaciones u ordenes sin tratar todavía, también recordar que en los ficheros .dtx se pueden saltar compases ya que no hay ninguna nota en esos compases, pero nosotros ya creamos en esta lista de compases, en esos compases vacíos un compás vacío, que internamente tendrá una key 'lanes' pero no llegara a tener notaciones internas.

Ahora ya tenemos una lista de compases y en cada compás un diccionario con una key 'lanes' que es un diccionario con las notaciones separadas por lanes.


Ahora creamos la puntuación.
\subsubsection{Puntuación}
Usamos un widget por comodidad, donde tendremos los siguientes datos:

Datos visuales:
Titulo de la canción
Número de notas en perfect
Número de notas en great
Número de notas en good
Número de notas en poor
Número de notas en miss
Número de notas en combo
Número de notas máximas en combo

Datos a guardar en este widget:
Los tiempos de margenes calculados a partir del tiempo de sincronización.


Con las siguientes funciones:

comprobar\_puntuacion:
Con el tiempo de margen que nos pasan, miramos los tiempos de sincronización y actualizamos los datos en consecuencia.

actualizar\_puntuacion:

Actualizaremos los elementos gráficos.

aumentar\_miss: 
Función que se empleara cuando hay una nota que eliminamos por tiempo, ya directamente sabemos que es un miss.
\subsubsection{Continuamos actualizando los compases}
Insertamos los bancos de sonidos en sus lanes.

Ahora se tiene que poner en todos los compases sus tiempos, para ello iremos recorriendo la lista y con cuidado si hay una nota en los lanes 03 o 08 ya que estos modifican los BPM de la canción; lo más habitual es que se cambie al inicio del compás o justo en la última nota del compás para el compás siguiente, se ha implementado tanto el lane 03 como el 08, ya que aunque parece que se quiere dirigir el formato hacia cambios absolutos, para tener retrocompatibilidad se ha implementado los cambios de BPM con sumas o restas al BPM actual, para ello en el diccionario que es el compás actual ahora añadimos dos keys, que son la key 'bmp' asociada al bmp del compás actual y la key 'tiempo' que es el tiempo donde se debería iniciar el compás.

Ahora tenemos que recorrer otra vez la lista de compases y ahora podemos coger todas las notaciones de los lanes y compases, y separarlos en notas con un tiempo, quitando las notas 00 que son silencios en los .dtx.

Creamos un evento para salir del reproductor cuando se acabe el tiempo de la canción más el doble tiempo de sincronización, para tener un poco de margen extra.

Iniciamos el control del tiempo, ya que se tiene todos los datos ya tratados para comenzar la canción reproducción del .dtx.

Animamos el primer compás, lo quitamos de la lista de compases, y pasamos al bucle principal de la reproducción, usando un timer de Qt5.


\subsubsection{Animar un compás}
Para animar un compás en la reproducción de un .dtx, se cogera a animar, y el tiempo actual.

Para animar el compás actual lo que se tiene que hacer es repasar todos sus lanes, mirar la primera nota para cada uno de esos lanes y si su tiempo es menor que el tiempo actual, la quitamos del compás a animar y lo pasamos a su lane correspondiente modificando el tiempo de esta nota, sumando el tiempo de sincronización, pensar que se estará animando este compás mientras no se pase de su tiempo.

Hay que separar las notas en dos grandes grupos:

Las que  están en lanes puros automáticos (01,61 y 62).

Y las notas para los lanes visuales, en este caso se tendrá que crear una nota visual con sus propiedades gráficas dependiendo del lane y añadirla a la scene asociada al Qt5.

Si fuera una nota no asociada a ningún lane implementado sacamos esta información en el terminal.

\subsubsection{Bucle principal de la reproducción}
En el bucle principal de la reproducción se tiene que hacer varias cosas:

Coger el tiempo actual, continuar animando el compás actual, ya que puede tener todavía notas a animar.

Comprobamos que no estamos en el tiempo del siguiente compás. Si fuera de esta manera actualizamos el compás actual y lo quitamos de la lista de compases.

Se da la orden de reproducción en todos los lanes auto, tanto los puramente auto como los configurados por el usuario.

Se comprueba que no tenemos que eliminar ninguna nota por tiempo, en los lanes visuales.

Y volvemos a usar un timer de Qt5 para hacer una parada en la CPU y que Qt5 pueda actualizar todos los elementos gráficos y después se volverá a llamar a este bucle principal.

\chapter{Detalles de implementación}
\section{Transformar .dtx a .dtx libre}

La idea es bajarse canciones de internet y ejecutando alguno de los dos scripts de transformar a .dtx libre estos se encargaran de varias tareas:

\begin{itemize}
   \item Codificar los .dtx en utf-8
   \item Transformar los .xa a wav
   \item Transformar los .mp3 a .ogg
   \item Cambiar internamente los .dtx apuntando a estos archivos en formatos libres
 \end{itemize}

Se dan dos posibles scripts ya que hay .dtx que tienen los sonidos .xa o .wav dentro de una subcarpeta para mejorar la estructura de ficheros.


\section{DRUM-HAT MIDI}

Se ha conseguido un código independiente que si esta en cpu al mismo tiempo, que el pyDTX, el Drum-HAT emite señales MIDI que se pueden tratar.

\section{pyDTX}

Se ha configurado un script de python con la opción de optimización, para que se mejore en lo posible la ejecución, viendo las ideas generales, el mayor problema de este proyecto es el buen uso de los timers y de la capacidad de la cpu para reproducir los simultáneamente todos sonidos en los lanes, de esto se encargara las librerías Qt5, en segundo plane queda el tema gráfico que también se encarga el Qt5 y puede limitar el uso del proyecto.

Son las librerias Qt5 que según su código y sistema operativo donde se esta ejecutando y daran acceso a la pantalla y al sonido. 

Se ha implementado el control MIDI vía Cython por lo que esta bastante optimizado.

La programación se ha realizado de tal manera que siempre el sonido tiene prioridad, sobre los gráficos.

\section{Instalación}

\subsection{Fedora 25 - x86_64}
En una distribución fedora 25 se ha probado con las siguientes instrucciones:

\begin{lstlisting}
    sudo dnf install alsa-lib-devel  
    sudo dnf install python3-Cython 
    sudo dnf install rtmidi-2*
    sudo dnf install rtmidi-devel-
    sudo dnf install redhat-rpm-config  
    sudo dnf install gcc-c++
    sudo pip3 install rtmidi2
\end{lstlisting}

\subsection{Raspberry3 - armv7}

En la raspberry3 en la distribución Raspbian y ubuntu

\begin{lstlisting}
  sudo apt-get install librtaudio-dev
  sudo apt-get install librtmidi-dev
  sudo apt-get install librtmidi2
  sudo pip3 install Cython  (20 minutos...)
  sudo pip3 install rtmidi2
  sudo apt-get install libqt5multimedia5
  sudo apt-get install libqt5multimedia5-plugins
  sudo apt-get install python3-pyqt5
  sudo apt-get install python3-pyqt5.qtmultimedia
  sudo apt-get install python3-pyqt5.qtopengl  
\end{lstlisting}

Detalle que para que funcione en raspbian tenemos que llamar al pulseaudio, y si queremos usar el drumHat al mismo tiempo, también tendremos que llamar a nuestro programa MIDI-out-DrumHat, si queremos emplear el DrumHat como instrumento MIDI.

En la raspberry funciona pero el sonido se entrecorta, ya que no tiene suficiente potencia, como es puede observar el código esta funcionando por lo que cuando salga o la raspberry más potente, se pueda usar pypy3 con las librerías qt5 o se tenga un kernel en arm64 posiblemente funcionara correctamente.







\chapter{Posibles mejoras en el futuro}

Cuando se actualice la versión de python en las distribuciones de la raspberry, se podría actualizar la manera de revisar los ficheros existentes en los directorios de las canciones, fue un gran cambio en el paso a pyhton 3.5 pero no se ha usado en este proyecto para no dejar a las grandes distribuciones de raspberry colgadas.

El siguiente gran cambio en python 3.6 seria actualizar la manera de ver las notas ya que se actualizo la manera de entender los números ya que se contempla a partir de esa versión poner el carácter guión bajo para una mejor lectura de los números: 1\_000\_000 ahora se acepta como número y esta característica se podría emplear para limpiar la parte de coger objetos y notas de un .dtx.

Ampliar las ordenes del .dtx y los lanes implementados para tener un mayor porcentaje de compatibilidad con los .dtx que hay en internet.
-------------------

Obligatorios TODO

Apuntar posibles ODROID DAC más rápidos que la raspberry puede que si, aunque con el código como esta ahora no funciona pero en un x86 no hay problema

Importantes TODO
TODO¿? comprobar Limpiar canciones de practicas


Futuros TODO
TODO¿? Controlar navegacion al menos con drum-midi
TODO Hiscores¿?
TODO Animacion para cuando se toca se ayuda visual para perfect,good
TODO segundo background para las configuraciones
TODO Analizar los .box
TODO No analizo si en el .dtx hay doble linea para el mismo compas y lane
TODO cuenta Compases auto, este casi seguro lo dejo apuntado y no lo hago


TODO a poner en la documentación...


Comentar pygame , pyqt, tkinter y por que hemos ido menús a pyqt y ya veremos que hacemos en el juego en si.


Cuidado en linux ubuntu es donde me funciona actualmente medianamente bien, comentar los motivos


Comentar timer + animaciones 
1) opción ningún timer y hacer una animación enorme
Comentar que primera implementación que fue muy justa era animar cada nota independientemente y en la raspberry al no tener opengl y cpu más lenta no era la solución mas optima.
2) opción todo en timer y solo existirán las animaciones para cada nota  
Luego la opción de crear timers para cada nota independiente, se observo que si se ponían todas las animaciones como independiente para cada nota, dependía de la cpu la exactitud de la animación, en un juego de control musical tenemos que evitar eso

3) opción timer para siguiente compas (solo 1 timer activo cada vez hay que reiniciarlo) hacer animación un bloque, para lane....
  Si el tiempo de la nota al caer era un poco grane y pàra ver la animación correcta se mezclaban las animaciones de los chips no habían acabado por los margenes,..... mirar si se puede dejar medianamente bien estoy en ello....
  


Por fin veo el motivo los timer de pyqt primero e interesante no bloquean (eso esta muy bien) pero no son exactos y depende MUCHO de cpu por eso creo que voy a hacer solo 1 timer para siguiente "tick" tendré mejor control de que hay en pantalla

QML quick2 ¿funciona en raspbian?  actualmente,....

Comentar cambio en el apéndice para nombre de modulos, ya que sino rompe mucho con qt5.... hablarlo antes.

ademas de comentar lo de utf-8 pensar que el puñetero wine tiene problemas donde se ejecute para encontrar los archivos .xa (se tiene que ejecutar donde estan los .xa)

Comentar los detalles estilos algunos labels no todos, canciones con espacios en su nombre, ya no digamos .mp3

lanes 6X auto seguro que son .wav (por ejemplos que he mirado los 0X o wav o ogg)

ffmpeg -i "Maroon 5 - This Love.mp3" -acodec libvorbis "Maroon 5 - This Love.ogg"; 

Canciones con Barra \ / estilo windows no linux

canciones con notas no escritas en el .dtx 

set.def sin los dos puntos que definen l3Label: o l3file:

set.def que apuntan a archivos inexistentes...

Detalle de los lanes en auto mediaplayer para los .ogg .mp3, y los lanes visuales son soundeffect para menos lag y mas rapido todo...

-------------------------------------
\appendix


\chapter{Código fuente}
\section{Transformar .dtx a .dtx libre}

\lstinputlisting[language=bash]{../Transformar-DTX-a-DTX-libre/Transformar-dtx-a-dtxlibre.sh}

\section{DRUMHAT en instrumento midi}

\lstinputlisting[language=Python]{../MIDI-out-DrumHat/MIDI-out-DrumHat.py}
\section{pyDTX}

No se indica el código fuente generado desde los .ui

\subsection{ChipAuto.py}

\lstinputlisting[language=Python]{../src/pyDTX/ChipAuto.py }

\subsection{Chip.py}

\lstinputlisting[language=Python]{../src/pyDTX/Chip.py }

\subsection{LaneAuto.py}

\lstinputlisting[language=Python]{../src/pyDTX/LaneAuto.py }

\subsection{LaneVisual.py}

\lstinputlisting[language=Python]{../src/pyDTX/LaneVisual.py }

\subsection{main.py}

\lstinputlisting[language=Python]{../src/pyDTX/main.py }

\subsection{UtilidadesDTX.py}

\lstinputlisting[language=Python]{../src/pyDTX/UtilidadesDTX.py }

\subsection{MyMainWindowQt5.py}

\lstinputlisting[language=Python]{../src/pyDTX/MyMainWindowQt5.py }

\subsection{MyWidgetConfigurarDrum.py}

\lstinputlisting[language=Python]{../src/pyDTX/MyWidgetConfigurarDrum.py }

\subsection{MyWidgetConfigurarDTX.py}

\lstinputlisting[language=Python]{../src/pyDTX/MyWidgetConfigurarDTX.py }

\subsection{MyWidgetNavegacion.py}

\lstinputlisting[language=Python]{../src/pyDTX/MyWidgetNavegacion.py }

\subsection{MyWidgetPuntuacion.py}

\lstinputlisting[language=Python]{../src/pyDTX/MyWidgetPuntuacion.py }

\subsection{ReproductorDTX.py}

\lstinputlisting[language=Python]{../src/pyDTX/ReproductorDTX.py }


\chapter{Guía de estilo python}
Aquí esta la guía de estilo que se utilizara durante todo el proyecto para escribir código, ya que de esta manera tanto la lectura, como el mantenimiento del código sera mucho más sencillo.
Uno de los grandes problemas de python es que no se esta obligado a seguir un estilo de programación, a la hora de escribir código se puede generar verdaderos desastres y si encima se junta que se puede crear variables en tiempo de ejecución y en mitad del código, mejor no pensar en las barbaridades con las que uno se puede encontrar.

Para ello se va a exponer las normas que se usaran para generar código python.

Una de las ideas es que el código se suele leer mucho más de lo que se escribe. Las guías de estilo que proporciona este documento están dirigidas a mejorar la legibilidad del código y hacerlo consistente a lo largo del amplio espectro del código python. Como dice el Zen de python, ``La legibilidad cuenta''.
Una guía de estilo nos ayuda a lograr consistencia. Ser consistente con esta guía de estilo es importante.
La consistencia dentro de un proyecto es aún más importante. La consistencia dentro de un módulo o función es la más importante.

Dos buenas razones para romper una regla en particular son:

\begin{enumerate}
\item Que al aplicar la regla el código se haga menos legible, incluso para alguien que esté acostumbrado a leer código que sigue las normas.
\item Para ser consistente con código relacionado que también la rompe (quizás por razones históricas) -- aunque esto también es una oportunidad de arreglar el desaguisado de otra persona (al más puro estilo XP).
\end{enumerate}

\section{Formateo del código}
\subsection{Indentación}
Usa 4 espacios por cada nivel de indentación

\subsection{Tamaño máximo de línea}
Limita todas las líneas a un máximo de 79 caracteres.

\subsection{Líneas en blanco}
Separa las funciones no anidadas y las definiciones de clases con dos líneas en blanco.

Las definiciones de métodos dentro de una misma clase se separan con una línea en blanco.

Se pueden usar líneas en blanco extra (de forma reservada) para separar grupos de funciones relacionadas. Las líneas en blanco se pueden omitir entre un grupo de funciones con una sola línea (por ejemplo, con un conjunto de funciones sin implementación).

Usa líneas en blanco en las funciones, de forma limitada, para indicar secciones lógicas.

\subsection{Codificación de caracteres}

Usaremos UTF-8

\subsection{Imports}
\begin{itemize}
\item Normalmente los imports deberían colocarse en distintas líneas, por ejemplo:
Sí:
\begin{lstlisting}
    import os
    import sys
\end{lstlisting}
No:
\begin{lstlisting}
    import sys, os2
\end{lstlisting}
aunque también es correcto hacer esto:
\begin{lstlisting}
    from subprocess import Popen, PIPE
\end{lstlisting}
\item Los imports se colocan siempre en la parte superior del archivo, justo después de cualquier comentario o cadena de documentación del módulo, y antes de las variables globales y las constantes del módulo.

Los imports deberían agruparse siguiendo el siguiente orden:
\begin{itemize}
\item   1. imports de la librería estándar
\item   2. imports de proyectos de terceras partes relacionados
\item   3. imports de aplicaciones locales/imports específicos de la librería
\end{itemize}
Deberías añadir una línea en blanco después de cada grupo de imports.

Si es necesario especificar los nombres públicos definidos por el módulo con \_\_all\_\_ esto debería hacerse después de los imports.

\item Es muy desaconsejable el uso de imports relativos para importar código de un paquete. Utiliza siempre la ruta absoluta del paquete para todos los imports

\item Cuando importes una clase de un módulo, normalmente es correcto hacer esto
\begin{lstlisting}
          from myclass import MyClass
          from foo.bar.yourclass import YourClass
\end{lstlisting}
      Si esto causa colisiones de nombres con objetos locales, utiliza en su lugar
\begin{lstlisting}
          import myclass
          import foo.bar.yourclass
\end{lstlisting}
      y usa ``myclass.MyClass'' y ``foo.bar.yourclass.YourClass'' en el código
\end{itemize}

\subsection{Espacios en blanco en expresiones y sentencias}
Evita espacios en blanco extra en las siguientes situaciones:
\begin{itemize}
\item Inmediatamente después de entrar en un paréntesis o antes de salir de un paréntesis, corchete o llave.

Sí:
\begin{lstlisting}
    spam(ham[1], {eggs: 2})
\end{lstlisting}
No:
\begin{lstlisting}
    spam( ham[ 1 ], { eggs: 2 } )
\end{lstlisting}
\item Inmediatamente antes de una coma, punto y coma, o dos puntos:

Sí:
\begin{lstlisting}
    if x == 4: print x, y; x, y = y, x
\end{lstlisting}
No:
\begin{lstlisting}
    if x == 4 : print x , y ; x , y = y , x
\end{lstlisting}
\item Inmediatamente antes de abrir un paréntesis para una lista de argumentos de una llamada a una función:

Sí:
\begin{lstlisting}
    spam(1)
\end{lstlisting}
No:
\begin{lstlisting}
    spam (1)
\end{lstlisting}
\item Inmediatamente antes de abrir un paréntesis usado como índice o para particionar ( \emph{slicing}):

Sí:
\begin{lstlisting}
    dict['key'] = list[index]
\end{lstlisting}
No:
\begin{lstlisting}
    dict ['key'] = list [index]
\end{lstlisting}
\item Más de un espacio alrededor de un operador de asignación (u otro operador) para alinearlo con otro.

Sí:
\begin{lstlisting}
    x = 1
    y = 2
    long_variable = 3
\end{lstlisting}
No:
\begin{lstlisting}
    x             = 1
    y             = 2
    long_variable = 3
\end{lstlisting}
\end{itemize}
\subsection{Otras Recomendaciones}
\begin{itemize}
\item Rodea siempre los siguientes operadores binarios con un espacio en cada lado: asignación (=), asignación aumentada (+=, -= etc.), comparación (==, <, >, !=, <>, <=, >=, in, not in, is, is not), booleanos (and, or, not).
\item Usa espacios alrededor de los operadores aritméticos:

Sí:
\begin{lstlisting}
    i = i + 1
    submitted += 1
    x = x * 2 - 1
    hypot2 = x * x + y * y
    c = (a + b) * (a - b)
\end{lstlisting}
No:
\begin{lstlisting}
    i=i+1
    submitted +=1
    x = x*2 - 1
    hypot2 = x*x + y*y
    c = (a+b) * (a-b)
\end{lstlisting}
\item No uses espacios alrededor del signo '=' cuando se use para indicar el nombre de un argumento o el valor de un parámetro por defecto.

Sí:
\begin{lstlisting}
    def complex(real, imag=0.0):
        return magic(r=real, i=imag)
\end{lstlisting}
No:
\begin{lstlisting}
    def complex(real, imag = 0.0):
        return magic(r = real, i = imag)
\end{lstlisting}
\item Generalmente se desaconsejan las sentencias compuestas (varias sentencias en la misma línea).

Sí:
\begin{lstlisting}
    if foo == 'blah':
        do_blah_thing()
    do_one()
    do_two()
    do_three()
\end{lstlisting}
Preferiblemente no:
\begin{lstlisting}
    if foo == 'blah': do_blah_thing()
    do_one(); do_two(); do_three()
\end{lstlisting}
\item Aunque a veces es adecuado colocar un if/for/while con un cuerpo pequeño en la misma línea, nunca lo hagas para sentencias multi-clausula.

Preferiblemente no:
\begin{lstlisting}
    if foo == 'blah': do_blah_thing()
    for x in lst: total += x
    while t < 10: t = delay()
\end{lstlisting}
Definitivamente no:
\begin{lstlisting}
    if foo == 'blah': do_blah_thing()
    else: do_non_blah_thing()

    try: something()
    finally: cleanup()

    do_one(); do_two(); do_three(long, argument,
                                list, like, this)

    if foo == 'blah': one(); two(); three()
\end{lstlisting}
\end{itemize}
\section{Comentarios}
Los comentarios que contradicen el código son peores que no tener ningún comentario. ¡Manten siempre como prioridad el mantener los comentarios actualizados cuando cambies el código!

Los comentarios deberían ser frases completas. Si un comentario es una frase o sentencia, la primera palabra debería estar en mayúsculas, a menos que sea un identificador que comience con una letra en minúsculas (¡nunca alteres el identificador sustituyendo mayúsculas o minúsculas!).

Si un comentario es corto, se puede omitir el punto al final. Los comentarios de bloque generalmente consisten en uno o más párrafos construidos con frases completas, y cada frase debería terminar con un punto.
\subsection{Comentarios de bloque}
Los comentarios de bloque generalmente se aplican al código que se encuentra a continuación, y se indentan al mismo nivel que dicho código. Cada línea de un comentario de bloque comienza con un \# y un único espacio (a menos que haya texto indentado dentro del comentario).

Los párrafos dentro de un comentario de bloque se separan por una línea conteniendo un único \#.
\subsection{Comentarios en línea}
Utiliza comentarios en línea de forma moderada.

Un comentario en línea es un comentario que se encuentra en la misma línea que una sentencia. Los comentarios en línea deberían separarse por al menos dos espacios de la sentencia que comentan. Deberían comenzar con un \# y un espacio.

Los comentarios en línea son innecesarios y de hecho sólo sirven para distraer si indican cosas obvias. No hagas cosas como esta:
\begin{lstlisting}
    x = x + 1                 # Incrementa x
\end{lstlisting}
Aunque a veces, algo como esto puede ser de utilidad:
\begin{lstlisting}
    x = x + 1                 # Compensa por el borde
\end{lstlisting}
\section{Cadenas de Documentación}
\begin{itemize}
\item Escribe docstrings para todos los módulos, funciones, clases, y métodos públicos. Los docstrings no son necesarios para métodos no públicos, pero deberías tener un comentario que describa lo que hace el método. Este comentario debería aparecer antes de la línea "def".
\item Es importante notar, que el \verb@"""@ que finaliza un docstring de varias líneas debería situarse en una línea separada, y preferiblemente precederse por una línea en blanco, por ejemplo:

\begin{lstlisting}
    """Return a foobang

    Optional plotz says to frobnicate the bizbaz first.

    """
\end{lstlisting}
\item Para cadenas de documentación de una línea, es adecuado mantener el '''''' de cierre en la misma línea.
\end{itemize}
\section{Convenciones de nombres}
Las convenciones de nombres de la librería de python son un pequeño desastre, así que nunca conseguiremos que sea completamente consistente -- aún así, aquí tenéis los estándares de nombrado recomendados en la actualidad. Los nuevos módulos y paquetes (incluyendo los frameworks de terceras personas) deberían acomodarse a estos estándares, pero donde exista una librería con un estilo distinto, se prefiere la consistencia interna.
\subsection{Descriptivo: Estilos de Nombrado}
Hay un montón de estilos de nombrado distintos. Ayuda el poder reconocer qué estilo de nombrado se utiliza, independientemente de para lo que se utilice.

Podemos encontrarnos con los siguientes estilos de nombrado más comunes:
\begin{itemize}
\item b (una sola letra en minúsculas)
\item B (una sola letra en mayúsculas)
\item minúsculas
\item minúsculas\_con\_guiones\_bajos
\item MAYÚSCULAS
\item MAYÚSCULAS\_CON\_GUIONES\_BAJOS
\item PalabrasEnMayusculas (CapWords o CamelCase). Algunas veces también se llaman StudlyCaps.
Nota: Cuando se usan abreviaturas en CapWords, mantén en mayúsculas todas las letras de la abreviatura. Por lo tanto HTTPServerError es mejor que HttpServerError.
\item Mayusculas\_Con\_Guiones\_Bajos
\end{itemize}
También existe un estilo en el cuál se utiliza un prefijo único corto para agrupar nombres relacionados de forma conjunta. Esto no se suele utilizar mucho en Python, pero se menciona con el objeto de que el texto sea lo más completo posible. Por ejemplo, la función os.stat() devuelve una tupla cuyos elementos tradicionalmente han tenido nombres como st\_mode, st\_size, st\_mtime y similares. (Esto se hace para enfatizar la correspondencia con los campos de la estructura de la llamada a sistema POSIX, lo cual es de utilidad para los programadores que están familiarizados con ella.)

La librería X11 utiliza una X inicial para todas sus funciones públicas. En Python, este estilo generalmente se considera innecesario porque los atributos y métodos se preceden por el objeto al que pertenecen, y los nombres de funciones se preceden del nombre del módulo.

Además se reconocen las siguientes formas especiales usando guiones bajos al inicio o final del nombre (generalmente estos se pueden combinar con cualquier convención de capitalización):
\begin{itemize}
\item \_guion\_bajo\_al\_inicio : indicador débil de ``uso interno''. Por ejemplo ``from M import *'' no importa objetos cuyos nombres comiencen con un guión bajo.
\item guion\_bajo\_al\_final\_ : usado por convención para evitar conflictos con palabras clave de Python, por ejemplo
\begin{lstlisting}
    Tkinter.Toplevel(master, class_='ClassName')
\end{lstlisting}
\item \_\_doble\_guion\_bajo\_al\_inicio : cuando se use para nombrar un atributo de clase, invoca la característica de "planchado de nombres" (dentro de la clase FooBar, \_\_boo se convierte en \_FooBar\_\_boo; ver abajo).

\item \_\_doble\_guion\_bajo\_al\_inicio\_y\_fin\_\_ : objectos "mágicos" o atributos que viven en espacios de nombres controlados por el usuario. Por ejemplo \_\_init\_\_, \_\_import\_\_ o \_\_file\_\_. Nunca inventes nombres como estos; utilizalos sólo como están documentados.
\end{itemize}
\subsection{Prescriptivo: Convenciones de Nombrado}
\subsubsection{Nombres a Evitar}
Nunca utilices los caracteres ``l'' (letra ele minúscula), ``O'' (letra o mayúscula), o ``I'' (letra i mayúscula) como nombres de variables de un solo carácter.

En algunas fuentes, estos caracteres son indistinguibles de los numerales uno y cero. Cuando estés tentado de usar ``l'', utiliza una ``L'' en su lugar.
\subsubsection{Nombres de Paquetes y Módulos}
Los módulos deberían tener nombres cortos formados en su totalidad por letras minúsculas. Se puede utilizar guiones bajos en el nombre del módulo si mejora la legibilidad. Los paquetes Python también deberían tener nombres cortos formados de letras minúsculas, aunque se desaconseja el uso de guiones bajos.

Dado que los nombres de los módulos se mapean a nombres de archivos, y algunos sistemas de ficheros no diferencian entre mayúsculas y minúsculas y truncan los nombres largos, es importante que los nombres de los módulos que se elijan sean suficientemente cortos -- esto no es un problema en Unix, pero puede ser un problema cuando el código se porta a versiones antiguas de Mac o Windows, o a DOS.

Cuando un módulo de extensión escrito en C o C++ tenga un módulo Python asociado que proporcione una interfaz de más alto nivel (por ejemplo, más orientado a objetos), el módulo C/C++ debería comenzar con un guión bajo (por ejemplo \_socket).
\subsubsection{Nombres de Clases}
Casi sin excepciones, los nombres de clases usan la convención CapWords. Las clases de uso interno tienen además un guión bajo al principio del nombre.

\subsubsection{Nombres de Excepciones}
Dado que las excepciones deberían ser clases, se aplica la convención relativa al nombrado de clases. De todas formas, deberías usar el sufijo ``Error'' en los nombres de las excepciones (si la excepción es realmente un error).
\subsubsection{Nombres de Variables Globales}
(Esperamos que estas variables estén destinadas a ser usadas sólo dentro de un módulo.) Las convenciones son prácticamente las mismas que para las funciones.

Los módulos diseñados para ser utilizados usando ``from M import *'' deberían usar el mecanismo \_\_all\_\_ para prevenir que se exporten variables globales, o bien usar la convención antigua de añadir un guión bajo como prefijo a dichas variables globales (puede que quieras hacer esto para indicar que estas variables son ``variables no públicas del módulo'').
\subsubsection{Nombres de Funciones}
Los nombres de funciones deberían estar en letras minúsculas, con palabras separadas mediante guiones bajos según sea necesario para mejorar la legibilidad.

Sólo se acepta capitalizaciónMezclada en contextos en los que ya se trate del estilo principal (por ejemplo threading.py), para mantener la compatibilidad hacia atrás.
\subsubsection{Argumentos de funciones y métodos}
Utiliza siempre 'self'  como primer argumento de los métodos de instancia.

Utiliza siempre 'cls'  como primer argumento de métodos de clase.

Si el nombre de un argumento de una función colisiona con una palabra reservada, generalmente es mejor añadir un guión bajo al final del nombre en lugar de usar una abreviatura o modificar la grafía. Por lo tanto ``print\_'' se considera mejor que ``prnt''. (Quizás utilizar sinónimos sea una forma incluso mejor.)
\subsubsection{Nombres de métodos y variables de instancia}
Utiliza las reglas de los nombres de funciones: minúsculas con palabras separadas por guiones bajos cuando sea necesario para mejorar la legibilidad.

Utiliza guiones bajos al inicio sólo para métodos no públicos y variables de instancia.

Para evitar colisiones de nombres con subclases, utiliza dos guiones bajos al principio del nombre para invocar las reglas de planchado de nombres de Python.

Python une estos nombres con el nombre de la clase: si la clase Foo tiene un atributo llamado \_\_a, no se puede acceder utilizando Foo.\_\_a. (Un usuario insistente podría acceder utilizando Foo.\_Foo\_\_a.) Generalmente, sólo se debería usar un doble guión al inicio para evitar conflictos de nombres con atributos en clases diseñadas para que se herede de ellas.

Nota: existe controversia sobre el uso de \_\_nombres (ver debajo)
\subsubsection{Diseñar para la herencia}
Decide siempre si los métodos y variables de instancia de una clase (llamados de forma colectiva ``atributos'') deberían ser públicos o no públicos. Si dudas, elige que sea no público; es más sencillo convertirla en público más tarde que hacer no público un atributo que antes era público.

Los atributos públicos son aquellos que esperas que sean utilizados por los clientes de tu clase, y para los cuales te comprometes a evitar cambios que provoquen incompatibilidades hacia atrás. Los atributos no públicos son aquellos que no están destinados a que sean utilizados por terceras personas; no ofreces ninguna garantía de que los atributos no públicos no vayan a cambiar o a eliminarse.

No utilizamos el término ``privado'' aquí, dado que ningún atributo es realmente privado en Python (sin un trabajo añadido generalmente innecesario).

Otra categoría de atributos son aquellos que son parte de la ``API de las subclases'' (a menudo llamado ``protected'' en otros lenguajes). Algunas clases se diseñan para que se herede de ellas, bien para extender o bien para modificar aspectos del comportamiento de la clase. Cuando se diseña una clase de esta forma, es necesario tomar algunas decisiones explícitas sobre qué atributos van a ser públicos, cuáles son parte de la API de la subclase, y cuáles están pensados para ser utilizados exclusivamente dentro de la clase actual.

Teniendo esto en cuenta, aquí están las líneas a seguir:
\begin{itemize}
\item Los atributos públicos no deberían tener guiones bajos al inicio del nombre.
\item Si el nombre de tu atributo público colisiona con el de una palabra reservada, añade un único guión bajo al final del nombre del atributo. Esto es preferible a abreviar o cambiar la grafía de la palabra.

Nota 1: Ver la recomendación anterior para métodos de clase.
\item Para campos públicos simples, es mejor exponer sólo el nombre del atributo, sin complicaciones de métodos para accederlos y modificarlos (accessors y mutators). Ten en cuenta que Python proporciona una forma sencilla de modificarlo, en caso de que dentro de un tiempo lo necesites. En ese caso, utiliza propiedades para ocultar la implementación funcional con una sintaxis simple de acceso a atributos de datos.

Nota 1: Las propiedades sólo funcionan en las nuevas clases.

Nota 2: Intenta mantener el comportamiento funcional libre de efectos colaterales, aunque funcionalidad colateral como el cacheo generalmente es aceptable.

Nota 3: Evita usar propiedades para realizar operaciones que requieran de grandes cálculos; el utilizar la notación de atributos hace que la persona que accede al atributo piense que el acceso es (relativamente) barato en tiempo computacional.
\end{itemize}
\section{Recomendaciones para la programación}
\begin{itemize}
\item El código debería escribirse de forma que no pusiera en desventaja otras implementaciones de Python (PyPy, Jython, IronPython, Pyrex, Psyco, y similares).

Por ejemplo, no te apoyes en la eficiencia de la implementación de la concatenación de cadenas con a+=b o a=a+b en CPython. Estas órdenes se ejecutan más lentamente en Jython. En partes de la librería en las que el rendimiento sea importante, se debería utilizar en su lugar la forma ''.join(). Esto asegura que el tiempo necesario para la concatenación es del mismo orden en diferentes implementaciones.

\item Las comparaciones con  \emph{singletons} como None siempre deberían llevarse a cabo con 'is' o 'is not', nunca con operadores de igualdad.

También es importante tener cuidado con escribir ``if x'' cuando lo que realmente queríamos decir es ``if x is not None'' -- por ejemplo, cuando comprobemos si a una variable o argumento que tiene como valor por defecto None se le ha dado otro valor. ¡El otro valor podría tener un tipo (como un contenedor) que podría ser falso en un contexto booleano!

\item Utiliza excepciones basadas en clases.

Los módulos o paquetes deberían definir sus propias clases excepción específicas para el dominio del problema, las cuales deberían heredar de la clase Exception. Incluye siempre una cadena de documentación para la clase. Por ejemplo:
\begin{lstlisting}
    class MessageError(Exception):
        """Base class for errors in the email package."""
\end{lstlisting}
En este caso se aplican las convenciones de nombrado de las clases, aunque deberías añadir el sufijo ``Error'' a las clases excepción, si la excepción se trata de un error. Las excepciones que no sean errores, no necesitan ningún sufijo especial.

\item Cuando lances una excepción, utiliza ``raise ValueError('mensaje')'' en lugar de la forma antigua ``raise ValueError, 'mensaje'''.

Se prefiere la forma con paréntesis porque cuando los argumentos de la excepción son largos o incluyen formateo de cadenas, no necesitas usar caracteres para indicar que continúa en la siguiente línea gracias a los paréntesis. La forma antigua se eliminará en Python 3000.
\item Cuando captures excepciones, menciona excepciones específicas cuando sea posible en lugar de utilizar una clausula 'except:' genérica.

Por ejemplo, utiliza:
\begin{lstlisting}
    try:
        import platform_specific_module
    except ImportError:
        platform_specific_module = None
\end{lstlisting}
Una cláusula 'except:' genérica capturaría las excepciones SystemExit y KeyboardInterrupt, complicando el poder interrumpir el programa usando Control-C, y pudiendo ocultar otros problemas. Si quieres capturar todas las excepciones relativas a errores en el programa, utiliza 'except Exception:'.

Una buena regla a seguir es limitar el uso de las claúsulas `except' genéricas a dos casos:
\begin{itemize}
\item Si el manejador de la excepción imprimirá o registrará el traceback; de esta forma al menos el usuario sabrá que ha ocurrido un error.
\item Si el código tiene que realizar algún trabajo de limpieza, pero en ese caso tenemos que hacer que la excepción se propague hacia arriba usando 'raise'. La construcción `try...finally'  es una mejor forma de tratar con este caso.
\end{itemize}
\item Adicionalmente, para todas las clausulas try/except, es necesario limitar la clausula `try' a la mínima expresión de código necesaria. De nuevo, esto se hace para evitar ocultar bugs.

Sí:
\begin{lstlisting}
    try:
        value = collection[key]
    except KeyError:
        return key_not_found(key)
    else:
        return handle_value(value)
\end{lstlisting}
No:
\begin{lstlisting}
    try:
        # ¡Demasiado amplio!
        return handle_value(collection[key])
    except KeyError:
        # También capturará la excepción KeyError lanzada por handle\_value()
        return key_not_found(key)
\end{lstlisting}
\item Utiliza métodos de cadenas en lugar del módulo string.

Los métodos de las cadenas son siempre mucho más rápidos y comparten la misma API con las cadenas unicode. Ignora esta regla si es necesaria compatibilidad hacia atrás con versiones de Python anteriores a la 2.0.

\item Utiliza ''.startswith() y ''.endswith() en lugar del particionado de cadenas para comprobar prefijos y sufijos.

startswith() y endswith() son más limpios y menos propensos a errores. Por ejemplo:

Sí:
\begin{lstlisting}
    if foo.startswith('bar'):
\end{lstlisting}
No:
\begin{lstlisting}
    if foo[:3] == 'bar':
\end{lstlisting}
\item Las comparaciones del tipo de objeto siempre deberían utilizar isinstance() en lugar de comparar tipos directamente.

Sí:
\begin{lstlisting}
    if isinstance(obj, int):
\end{lstlisting}
No:
\begin{lstlisting}
    if type(obj) is type(1):
\end{lstlisting}

\item Para secuencias, (cadenas, listas, tuplas), aprovecha el que las secuencias vacías son equivalentes al falso booleano.

Sí:
\begin{lstlisting}
    if not seq:
    if seq:
\end{lstlisting}
No:
\begin{lstlisting}
    if len(seq)
    if not len(seq)
\end{lstlisting}
\item No compares valores booleanos con True o False usando ==

Sí:
\begin{lstlisting}
    if greeting:
\end{lstlisting}
No:
\begin{lstlisting}
    if greeting == True:
\end{lstlisting}
Peor:
\begin{lstlisting}
    if greeting is True:
\end{lstlisting}
\end{itemize}

\chapter{GNU GENERAL PUBLIC LICENSE}

\begin{center}
GNU GENERAL PUBLIC LICENSE
\end{center}
            
\begin{center}
Version 3, 29 June 2007
\end{center}


 \begin{center}
 Copyright (C) 2007 Free Software Foundation, Inc. <\url{http://fsf.org/}>
 \end{center}

 Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.


\url{http://www.gnu.org/licenses/gpl-3.0.html}



\printnoidxglossaries

\chapter {Bibliografía}
\begin{thebibliography}{99}
\bibitem{Not so short Latex} The Not So Short Introduction to LATEX: \url{tobi.oetiker.ch/lshort/lshort.pdf}
\bibitem{Wikipedia} Wikipedia: \url{www.wikipedia.es}
\bibitem{Guias de estilo python} Guia estilo python : \url{http://mundogeek.net/traducciones/guia-estilo-python.htm}
\bibitem{Proyecto DTXMANIA} Proyecto DTXMania: \url{https://osdn.jp/projects/dtxmania/}
\bibitem{Pineado Drum HAT} Pineado Drum HAT : \url{https://pinout.xyz/pinout/drum_hat}
\end{thebibliography}


\end{document}
